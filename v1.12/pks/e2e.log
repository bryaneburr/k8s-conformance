Jan 15 22:22:28.594: INFO: Overriding default scale value of zero to 1
Jan 15 22:22:28.594: INFO: Overriding default milliseconds value of zero to 5000
I0115 22:22:29.105536      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-736916119
I0115 22:22:29.106007      15 e2e.go:304] Starting e2e run "0aedfe7f-1914-11e9-993a-025056003018" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547590948 - Will randomize all specs
Will run 188 of 1814 specs

Jan 15 22:22:29.249: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 22:22:29.252: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 15 22:22:29.267: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 15 22:22:29.293: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 15 22:22:29.293: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Jan 15 22:22:29.293: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 15 22:22:29.300: INFO: e2e test version: v1.12.1
Jan 15 22:22:29.302: INFO: kube-apiserver version: v1.12.4
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:22:29.302: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
Jan 15 22:22:29.387: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jan 15 22:22:29.404: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h4pll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0b8ab08f-1914-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:22:29.532: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018" in namespace "e2e-tests-projected-h4pll" to be "success or failure"
Jan 15 22:22:29.544: INFO: Pod "pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 12.332489ms
Jan 15 22:22:31.549: INFO: Pod "pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016498022s
Jan 15 22:22:33.553: INFO: Pod "pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020969271s
Jan 15 22:22:35.558: INFO: Pod "pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02551433s
STEP: Saw pod success
Jan 15 22:22:35.558: INFO: Pod "pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:22:35.561: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:22:35.580: INFO: Waiting for pod pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018 to disappear
Jan 15 22:22:35.585: INFO: Pod pod-projected-configmaps-0b8b6f42-1914-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:22:35.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h4pll" for this suite.
Jan 15 22:22:41.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:22:41.650: INFO: namespace: e2e-tests-projected-h4pll, resource: bindings, ignored listing per whitelist
Jan 15 22:22:41.697: INFO: namespace e2e-tests-projected-h4pll deletion completed in 6.108432429s

• [SLOW TEST:12.395 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:22:41.700: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-xhv7t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:22:41.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-xhv7t" for this suite.
Jan 15 22:22:47.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:22:48.015: INFO: namespace: e2e-tests-services-xhv7t, resource: bindings, ignored listing per whitelist
Jan 15 22:22:48.031: INFO: namespace e2e-tests-services-xhv7t deletion completed in 6.123574058s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.331 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:22:48.033: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-5r4wv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-99x6
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:22:48.309: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-99x6" in namespace "e2e-tests-subpath-5r4wv" to be "success or failure"
Jan 15 22:22:48.312: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.119617ms
Jan 15 22:22:50.315: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00624857s
Jan 15 22:22:52.319: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010309291s
Jan 15 22:22:54.324: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014941168s
Jan 15 22:22:56.329: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.020205082s
Jan 15 22:22:58.333: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 10.024460849s
Jan 15 22:23:00.337: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 12.028413192s
Jan 15 22:23:02.341: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 14.031777456s
Jan 15 22:23:04.345: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 16.035973119s
Jan 15 22:23:06.348: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 18.039000711s
Jan 15 22:23:08.351: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 20.042663498s
Jan 15 22:23:10.354: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 22.045653794s
Jan 15 22:23:12.357: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 24.048653063s
Jan 15 22:23:14.363: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 26.054302936s
Jan 15 22:23:16.370: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Running", Reason="", readiness=false. Elapsed: 28.061028254s
Jan 15 22:23:18.378: INFO: Pod "pod-subpath-test-configmap-99x6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.069167071s
STEP: Saw pod success
Jan 15 22:23:18.378: INFO: Pod "pod-subpath-test-configmap-99x6" satisfied condition "success or failure"
Jan 15 22:23:18.385: INFO: Trying to get logs from node b660f798-38a0-4e83-a501-5381799304ec pod pod-subpath-test-configmap-99x6 container test-container-subpath-configmap-99x6: <nil>
STEP: delete the pod
Jan 15 22:23:18.406: INFO: Waiting for pod pod-subpath-test-configmap-99x6 to disappear
Jan 15 22:23:18.410: INFO: Pod pod-subpath-test-configmap-99x6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-99x6
Jan 15 22:23:18.410: INFO: Deleting pod "pod-subpath-test-configmap-99x6" in namespace "e2e-tests-subpath-5r4wv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:23:18.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5r4wv" for this suite.
Jan 15 22:23:24.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:23:24.503: INFO: namespace: e2e-tests-subpath-5r4wv, resource: bindings, ignored listing per whitelist
Jan 15 22:23:24.521: INFO: namespace e2e-tests-subpath-5r4wv deletion completed in 6.105579585s

• [SLOW TEST:36.488 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:23:24.524: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-qsxvf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 15 22:23:34.796: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:23:34.806: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 22:23:36.806: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:23:36.811: INFO: Pod pod-with-poststart-http-hook still exists
Jan 15 22:23:38.806: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 15 22:23:38.811: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:23:38.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-qsxvf" for this suite.
Jan 15 22:24:00.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:00.910: INFO: namespace: e2e-tests-container-lifecycle-hook-qsxvf, resource: bindings, ignored listing per whitelist
Jan 15 22:24:00.936: INFO: namespace e2e-tests-container-lifecycle-hook-qsxvf deletion completed in 22.120194035s

• [SLOW TEST:36.413 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:24:00.937: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-gctlx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-42293701-1914-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:24:01.166: INFO: Waiting up to 5m0s for pod "pod-configmaps-4229cbee-1914-11e9-993a-025056003018" in namespace "e2e-tests-configmap-gctlx" to be "success or failure"
Jan 15 22:24:01.171: INFO: Pod "pod-configmaps-4229cbee-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 5.487016ms
Jan 15 22:24:03.176: INFO: Pod "pod-configmaps-4229cbee-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009581801s
Jan 15 22:24:05.181: INFO: Pod "pod-configmaps-4229cbee-1914-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014973752s
STEP: Saw pod success
Jan 15 22:24:05.181: INFO: Pod "pod-configmaps-4229cbee-1914-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:24:05.184: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-4229cbee-1914-11e9-993a-025056003018 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:24:05.219: INFO: Waiting for pod pod-configmaps-4229cbee-1914-11e9-993a-025056003018 to disappear
Jan 15 22:24:05.222: INFO: Pod pod-configmaps-4229cbee-1914-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:24:05.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gctlx" for this suite.
Jan 15 22:24:11.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:11.309: INFO: namespace: e2e-tests-configmap-gctlx, resource: bindings, ignored listing per whitelist
Jan 15 22:24:11.348: INFO: namespace e2e-tests-configmap-gctlx deletion completed in 6.122371756s

• [SLOW TEST:10.412 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:24:11.354: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-jf44z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-4d7tt
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan 15 22:24:15.800: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-4psxr
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:24:39.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-jf44z" for this suite.
Jan 15 22:24:45.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:46.048: INFO: namespace: e2e-tests-namespaces-jf44z, resource: bindings, ignored listing per whitelist
Jan 15 22:24:46.129: INFO: namespace e2e-tests-namespaces-jf44z deletion completed in 6.147526066s
STEP: Destroying namespace "e2e-tests-nsdeletetest-4d7tt" for this suite.
Jan 15 22:24:46.133: INFO: Namespace e2e-tests-nsdeletetest-4d7tt was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-4psxr" for this suite.
Jan 15 22:24:52.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:52.277: INFO: namespace: e2e-tests-nsdeletetest-4psxr, resource: bindings, ignored listing per whitelist
Jan 15 22:24:52.284: INFO: namespace e2e-tests-nsdeletetest-4psxr deletion completed in 6.151442657s

• [SLOW TEST:40.931 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:24:52.287: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-pz8d5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 22:24:52.541: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Jan 15 22:24:52.553: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pz8d5/daemonsets","resourceVersion":"13664"},"items":null}

Jan 15 22:24:52.557: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pz8d5/pods","resourceVersion":"13664"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:24:52.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pz8d5" for this suite.
Jan 15 22:24:58.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:24:58.659: INFO: namespace: e2e-tests-daemonsets-pz8d5, resource: bindings, ignored listing per whitelist
Jan 15 22:24:58.695: INFO: namespace e2e-tests-daemonsets-pz8d5 deletion completed in 6.119494279s

S [SKIPPING] [6.409 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 15 22:24:52.541: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:24:58.698: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-tpqxr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 22:25:03.439: INFO: Successfully updated pod "annotationupdate6491e140-1914-11e9-993a-025056003018"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:25:05.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tpqxr" for this suite.
Jan 15 22:25:27.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:25:27.511: INFO: namespace: e2e-tests-downward-api-tpqxr, resource: bindings, ignored listing per whitelist
Jan 15 22:25:27.583: INFO: namespace e2e-tests-downward-api-tpqxr deletion completed in 22.104094405s

• [SLOW TEST:28.886 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:25:27.584: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-mg8rt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 22:25:27.805: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 15 22:25:27.825: INFO: Number of nodes with available pods: 0
Jan 15 22:25:27.825: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 15 22:25:27.861: INFO: Number of nodes with available pods: 0
Jan 15 22:25:27.861: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:28.870: INFO: Number of nodes with available pods: 0
Jan 15 22:25:28.870: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:29.867: INFO: Number of nodes with available pods: 0
Jan 15 22:25:29.867: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:30.867: INFO: Number of nodes with available pods: 0
Jan 15 22:25:30.867: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:31.866: INFO: Number of nodes with available pods: 1
Jan 15 22:25:31.866: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 15 22:25:31.913: INFO: Number of nodes with available pods: 1
Jan 15 22:25:31.913: INFO: Number of running nodes: 0, number of available pods: 1
Jan 15 22:25:32.918: INFO: Number of nodes with available pods: 0
Jan 15 22:25:32.918: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 15 22:25:32.931: INFO: Number of nodes with available pods: 0
Jan 15 22:25:32.931: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:33.935: INFO: Number of nodes with available pods: 0
Jan 15 22:25:33.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:34.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:34.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:35.935: INFO: Number of nodes with available pods: 0
Jan 15 22:25:35.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:36.935: INFO: Number of nodes with available pods: 0
Jan 15 22:25:36.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:37.935: INFO: Number of nodes with available pods: 0
Jan 15 22:25:37.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:38.937: INFO: Number of nodes with available pods: 0
Jan 15 22:25:38.937: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:39.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:39.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:40.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:40.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:41.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:41.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:42.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:42.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:43.939: INFO: Number of nodes with available pods: 0
Jan 15 22:25:43.939: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:44.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:44.937: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:45.962: INFO: Number of nodes with available pods: 0
Jan 15 22:25:45.962: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:46.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:46.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:47.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:47.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:48.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:48.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:49.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:49.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:50.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:50.937: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:51.935: INFO: Number of nodes with available pods: 0
Jan 15 22:25:51.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:52.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:52.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:53.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:53.937: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:54.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:54.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:55.935: INFO: Number of nodes with available pods: 0
Jan 15 22:25:55.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:56.940: INFO: Number of nodes with available pods: 0
Jan 15 22:25:56.942: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:57.935: INFO: Number of nodes with available pods: 0
Jan 15 22:25:57.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:58.936: INFO: Number of nodes with available pods: 0
Jan 15 22:25:58.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:25:59.937: INFO: Number of nodes with available pods: 0
Jan 15 22:25:59.937: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:00.935: INFO: Number of nodes with available pods: 0
Jan 15 22:26:00.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:01.937: INFO: Number of nodes with available pods: 0
Jan 15 22:26:01.937: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:02.938: INFO: Number of nodes with available pods: 0
Jan 15 22:26:02.938: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:03.935: INFO: Number of nodes with available pods: 0
Jan 15 22:26:03.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:04.936: INFO: Number of nodes with available pods: 0
Jan 15 22:26:04.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:05.937: INFO: Number of nodes with available pods: 0
Jan 15 22:26:05.937: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:06.935: INFO: Number of nodes with available pods: 0
Jan 15 22:26:06.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:07.935: INFO: Number of nodes with available pods: 0
Jan 15 22:26:07.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:08.936: INFO: Number of nodes with available pods: 0
Jan 15 22:26:08.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:09.939: INFO: Number of nodes with available pods: 0
Jan 15 22:26:09.940: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:10.936: INFO: Number of nodes with available pods: 0
Jan 15 22:26:10.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:11.941: INFO: Number of nodes with available pods: 0
Jan 15 22:26:11.941: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:12.936: INFO: Number of nodes with available pods: 0
Jan 15 22:26:12.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:13.936: INFO: Number of nodes with available pods: 0
Jan 15 22:26:13.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:14.936: INFO: Number of nodes with available pods: 0
Jan 15 22:26:14.936: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:15.935: INFO: Number of nodes with available pods: 0
Jan 15 22:26:15.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:16.939: INFO: Number of nodes with available pods: 0
Jan 15 22:26:16.939: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:17.935: INFO: Number of nodes with available pods: 0
Jan 15 22:26:17.935: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 22:26:18.937: INFO: Number of nodes with available pods: 1
Jan 15 22:26:18.937: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-mg8rt, will wait for the garbage collector to delete the pods
Jan 15 22:26:19.006: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.435692ms
Jan 15 22:26:19.107: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.34425ms
Jan 15 22:26:52.510: INFO: Number of nodes with available pods: 0
Jan 15 22:26:52.510: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 22:26:52.512: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mg8rt/daemonsets","resourceVersion":"13919"},"items":null}

Jan 15 22:26:52.515: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mg8rt/pods","resourceVersion":"13919"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:26:52.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mg8rt" for this suite.
Jan 15 22:26:58.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:26:58.657: INFO: namespace: e2e-tests-daemonsets-mg8rt, resource: bindings, ignored listing per whitelist
Jan 15 22:26:58.664: INFO: namespace e2e-tests-daemonsets-mg8rt deletion completed in 6.119335175s

• [SLOW TEST:91.080 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:26:58.665: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2d5jz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ac1a7a58-1914-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:26:58.910: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac1b8a25-1914-11e9-993a-025056003018" in namespace "e2e-tests-projected-2d5jz" to be "success or failure"
Jan 15 22:26:58.916: INFO: Pod "pod-projected-configmaps-ac1b8a25-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 5.776861ms
Jan 15 22:27:00.921: INFO: Pod "pod-projected-configmaps-ac1b8a25-1914-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011006892s
STEP: Saw pod success
Jan 15 22:27:00.921: INFO: Pod "pod-projected-configmaps-ac1b8a25-1914-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:27:00.926: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-configmaps-ac1b8a25-1914-11e9-993a-025056003018 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:27:00.959: INFO: Waiting for pod pod-projected-configmaps-ac1b8a25-1914-11e9-993a-025056003018 to disappear
Jan 15 22:27:00.967: INFO: Pod pod-projected-configmaps-ac1b8a25-1914-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:27:00.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2d5jz" for this suite.
Jan 15 22:27:06.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:27:07.040: INFO: namespace: e2e-tests-projected-2d5jz, resource: bindings, ignored listing per whitelist
Jan 15 22:27:07.104: INFO: namespace e2e-tests-projected-2d5jz deletion completed in 6.132869142s

• [SLOW TEST:8.439 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:27:07.106: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-497ff
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 15 22:27:07.365: INFO: Waiting up to 5m0s for pod "client-containers-b124b7dc-1914-11e9-993a-025056003018" in namespace "e2e-tests-containers-497ff" to be "success or failure"
Jan 15 22:27:07.374: INFO: Pod "client-containers-b124b7dc-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 9.357504ms
Jan 15 22:27:09.379: INFO: Pod "client-containers-b124b7dc-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013572701s
Jan 15 22:27:11.382: INFO: Pod "client-containers-b124b7dc-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017480847s
Jan 15 22:27:13.387: INFO: Pod "client-containers-b124b7dc-1914-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.022445904s
STEP: Saw pod success
Jan 15 22:27:13.388: INFO: Pod "client-containers-b124b7dc-1914-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:27:13.390: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod client-containers-b124b7dc-1914-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:27:13.417: INFO: Waiting for pod client-containers-b124b7dc-1914-11e9-993a-025056003018 to disappear
Jan 15 22:27:13.424: INFO: Pod client-containers-b124b7dc-1914-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:27:13.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-497ff" for this suite.
Jan 15 22:27:19.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:27:19.535: INFO: namespace: e2e-tests-containers-497ff, resource: bindings, ignored listing per whitelist
Jan 15 22:27:19.538: INFO: namespace e2e-tests-containers-497ff deletion completed in 6.108815916s

• [SLOW TEST:12.432 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:27:19.539: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-vwr9f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 22:27:19.727: INFO: PodSpec: initContainers in spec.initContainers
Jan 15 22:28:08.198: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-b884fedf-1914-11e9-993a-025056003018", GenerateName:"", Namespace:"e2e-tests-init-container-vwr9f", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-vwr9f/pods/pod-init-b884fedf-1914-11e9-993a-025056003018", UID:"b8859cee-1914-11e9-8273-005056af1926", ResourceVersion:"14130", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683188039, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"727489030"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-86f2h", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421a42000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-86f2h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-86f2h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-86f2h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421c881d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"16f34f29-58df-43ef-838e-06a19f186c15", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420d08540), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421c88250)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421c88270)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421c88278), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188039, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188039, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188039, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188039, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"30.0.3.3", PodIP:"40.0.10.2", StartTime:(*v1.Time)(0xc4211b00a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4215ca0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4215ca150)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://0247a3a0c3e78009e4dabed5d5fa694c1e9ef7dacd271f81d978a62f317036da"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4211b00e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4211b00c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:28:08.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vwr9f" for this suite.
Jan 15 22:28:30.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:28:30.283: INFO: namespace: e2e-tests-init-container-vwr9f, resource: bindings, ignored listing per whitelist
Jan 15 22:28:30.350: INFO: namespace e2e-tests-init-container-vwr9f deletion completed in 22.137484103s

• [SLOW TEST:70.811 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:28:30.350: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-g5lpg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-mksz
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:28:30.610: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mksz" in namespace "e2e-tests-subpath-g5lpg" to be "success or failure"
Jan 15 22:28:30.618: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Pending", Reason="", readiness=false. Elapsed: 7.618367ms
Jan 15 22:28:32.625: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014383175s
Jan 15 22:28:34.629: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018331258s
Jan 15 22:28:36.633: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 6.022172313s
Jan 15 22:28:38.637: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 8.02639776s
Jan 15 22:28:40.642: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 10.031700887s
Jan 15 22:28:42.647: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 12.036288503s
Jan 15 22:28:44.651: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 14.040989324s
Jan 15 22:28:46.655: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 16.044779592s
Jan 15 22:28:48.659: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 18.048503914s
Jan 15 22:28:50.663: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 20.052858908s
Jan 15 22:28:52.667: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 22.056776747s
Jan 15 22:28:54.671: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Running", Reason="", readiness=false. Elapsed: 24.061112855s
Jan 15 22:28:56.676: INFO: Pod "pod-subpath-test-downwardapi-mksz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.065515067s
STEP: Saw pod success
Jan 15 22:28:56.676: INFO: Pod "pod-subpath-test-downwardapi-mksz" satisfied condition "success or failure"
Jan 15 22:28:56.679: INFO: Trying to get logs from node b660f798-38a0-4e83-a501-5381799304ec pod pod-subpath-test-downwardapi-mksz container test-container-subpath-downwardapi-mksz: <nil>
STEP: delete the pod
Jan 15 22:28:56.703: INFO: Waiting for pod pod-subpath-test-downwardapi-mksz to disappear
Jan 15 22:28:56.708: INFO: Pod pod-subpath-test-downwardapi-mksz no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mksz
Jan 15 22:28:56.708: INFO: Deleting pod "pod-subpath-test-downwardapi-mksz" in namespace "e2e-tests-subpath-g5lpg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:28:56.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-g5lpg" for this suite.
Jan 15 22:29:02.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:29:02.801: INFO: namespace: e2e-tests-subpath-g5lpg, resource: bindings, ignored listing per whitelist
Jan 15 22:29:02.833: INFO: namespace e2e-tests-subpath-g5lpg deletion completed in 6.118407244s

• [SLOW TEST:32.483 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:29:02.833: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rrrpg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 15 22:29:03.052: INFO: Waiting up to 5m0s for pod "pod-f619d73b-1914-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-rrrpg" to be "success or failure"
Jan 15 22:29:03.054: INFO: Pod "pod-f619d73b-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.65999ms
Jan 15 22:29:05.060: INFO: Pod "pod-f619d73b-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008021821s
Jan 15 22:29:07.064: INFO: Pod "pod-f619d73b-1914-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012161541s
STEP: Saw pod success
Jan 15 22:29:07.064: INFO: Pod "pod-f619d73b-1914-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:29:07.067: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-f619d73b-1914-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:29:07.096: INFO: Waiting for pod pod-f619d73b-1914-11e9-993a-025056003018 to disappear
Jan 15 22:29:07.105: INFO: Pod pod-f619d73b-1914-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:29:07.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rrrpg" for this suite.
Jan 15 22:29:13.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:29:13.169: INFO: namespace: e2e-tests-emptydir-rrrpg, resource: bindings, ignored listing per whitelist
Jan 15 22:29:13.210: INFO: namespace e2e-tests-emptydir-rrrpg deletion completed in 6.099555764s

• [SLOW TEST:10.377 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:29:13.212: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-x7f7b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-5pnmb
STEP: Creating secret with name secret-test-fc478956-1914-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 22:29:13.638: INFO: Waiting up to 5m0s for pod "pod-secrets-fc691fda-1914-11e9-993a-025056003018" in namespace "e2e-tests-secrets-x7f7b" to be "success or failure"
Jan 15 22:29:13.646: INFO: Pod "pod-secrets-fc691fda-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 7.970135ms
Jan 15 22:29:15.655: INFO: Pod "pod-secrets-fc691fda-1914-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017490788s
Jan 15 22:29:17.660: INFO: Pod "pod-secrets-fc691fda-1914-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02163483s
STEP: Saw pod success
Jan 15 22:29:17.660: INFO: Pod "pod-secrets-fc691fda-1914-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:29:17.663: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-fc691fda-1914-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:29:17.693: INFO: Waiting for pod pod-secrets-fc691fda-1914-11e9-993a-025056003018 to disappear
Jan 15 22:29:17.696: INFO: Pod pod-secrets-fc691fda-1914-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:29:17.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x7f7b" for this suite.
Jan 15 22:29:23.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:29:23.798: INFO: namespace: e2e-tests-secrets-x7f7b, resource: bindings, ignored listing per whitelist
Jan 15 22:29:23.814: INFO: namespace e2e-tests-secrets-x7f7b deletion completed in 6.112357108s
STEP: Destroying namespace "e2e-tests-secret-namespace-5pnmb" for this suite.
Jan 15 22:29:29.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:29:29.867: INFO: namespace: e2e-tests-secret-namespace-5pnmb, resource: bindings, ignored listing per whitelist
Jan 15 22:29:29.921: INFO: namespace e2e-tests-secret-namespace-5pnmb deletion completed in 6.107166169s

• [SLOW TEST:16.710 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:29:29.922: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-k5kfg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0115 22:30:10.180297      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 22:30:10.180: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:30:10.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-k5kfg" for this suite.
Jan 15 22:30:16.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:30:16.288: INFO: namespace: e2e-tests-gc-k5kfg, resource: bindings, ignored listing per whitelist
Jan 15 22:30:16.418: INFO: namespace e2e-tests-gc-k5kfg deletion completed in 6.219223047s

• [SLOW TEST:46.496 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:30:16.419: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r7qt5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:30:16.654: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21f88c57-1915-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-r7qt5" to be "success or failure"
Jan 15 22:30:16.676: INFO: Pod "downwardapi-volume-21f88c57-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 22.402428ms
Jan 15 22:30:18.680: INFO: Pod "downwardapi-volume-21f88c57-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025718723s
Jan 15 22:30:20.684: INFO: Pod "downwardapi-volume-21f88c57-1915-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029901598s
STEP: Saw pod success
Jan 15 22:30:20.684: INFO: Pod "downwardapi-volume-21f88c57-1915-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:30:20.687: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-21f88c57-1915-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:30:20.706: INFO: Waiting for pod downwardapi-volume-21f88c57-1915-11e9-993a-025056003018 to disappear
Jan 15 22:30:20.714: INFO: Pod downwardapi-volume-21f88c57-1915-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:30:20.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r7qt5" for this suite.
Jan 15 22:30:26.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:30:26.769: INFO: namespace: e2e-tests-downward-api-r7qt5, resource: bindings, ignored listing per whitelist
Jan 15 22:30:26.829: INFO: namespace e2e-tests-downward-api-r7qt5 deletion completed in 6.110612024s

• [SLOW TEST:10.410 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:30:26.831: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-25bln
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 15 22:30:27.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-25bln'
Jan 15 22:30:28.185: INFO: stderr: ""
Jan 15 22:30:28.185: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 22:30:29.190: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:30:29.190: INFO: Found 0 / 1
Jan 15 22:30:30.189: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:30:30.189: INFO: Found 0 / 1
Jan 15 22:30:31.189: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:30:31.189: INFO: Found 0 / 1
Jan 15 22:30:32.195: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:30:32.195: INFO: Found 0 / 1
Jan 15 22:30:33.189: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:30:33.189: INFO: Found 1 / 1
Jan 15 22:30:33.189: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 15 22:30:33.192: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:30:33.192: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 22:30:33.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 patch pod redis-master-w6v22 --namespace=e2e-tests-kubectl-25bln -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 15 22:30:33.345: INFO: stderr: ""
Jan 15 22:30:33.345: INFO: stdout: "pod/redis-master-w6v22 patched\n"
STEP: checking annotations
Jan 15 22:30:33.351: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:30:33.351: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:30:33.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-25bln" for this suite.
Jan 15 22:30:55.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:30:55.409: INFO: namespace: e2e-tests-kubectl-25bln, resource: bindings, ignored listing per whitelist
Jan 15 22:30:55.462: INFO: namespace e2e-tests-kubectl-25bln deletion completed in 22.105171655s

• [SLOW TEST:28.632 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:30:55.464: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-4rjsm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 15 22:31:03.717: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 22:31:03.722: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 22:31:05.722: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 22:31:05.728: INFO: Pod pod-with-prestop-http-hook still exists
Jan 15 22:31:07.722: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 15 22:31:07.726: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:31:07.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4rjsm" for this suite.
Jan 15 22:31:29.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:29.769: INFO: namespace: e2e-tests-container-lifecycle-hook-4rjsm, resource: bindings, ignored listing per whitelist
Jan 15 22:31:29.844: INFO: namespace e2e-tests-container-lifecycle-hook-4rjsm deletion completed in 22.106191545s

• [SLOW TEST:34.381 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:31:29.846: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-mbhwh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 15 22:31:30.044: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 22:31:30.058: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 22:31:30.061: INFO: 
Logging pods the kubelet thinks is on node 16f34f29-58df-43ef-838e-06a19f186c15 before test
Jan 15 22:31:30.069: INFO: kube-dns-7559c96fc4-fmw6c from kube-system started at 2019-01-15 20:06:19 +0000 UTC (3 container statuses recorded)
Jan 15 22:31:30.069: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 22:31:30.069: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 22:31:30.069: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 22:31:30.069: INFO: fluent-bit-xszkh from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.069: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:31:30.069: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:31:30.069: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-15 22:21:52 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.069: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 22:31:30.069: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-m6gxg from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.069: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 22:31:30.069: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:31:30.069: INFO: 
Logging pods the kubelet thinks is on node 77857714-16e9-437d-8ce8-445ba965630c before test
Jan 15 22:31:30.081: INFO: metrics-server-555d98886f-78dxc from kube-system started at 2019-01-15 20:06:35 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.082: INFO: 	Container metrics-server ready: true, restart count 0
Jan 15 22:31:30.082: INFO: fluent-bit-2szkk from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.082: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:31:30.082: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:31:30.082: INFO: sink-controller-65595c498b-94m5j from pks-system started at 2019-01-15 20:06:48 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.082: INFO: 	Container sink-controller ready: true, restart count 0
Jan 15 22:31:30.082: INFO: sonobuoy-e2e-job-7725116febbe4ed6 from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.082: INFO: 	Container e2e ready: true, restart count 0
Jan 15 22:31:30.082: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:31:30.082: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-bqggf from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.082: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 22:31:30.082: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:31:30.082: INFO: monitoring-influxdb-cdcf4674-lt4k2 from kube-system started at 2019-01-15 20:06:41 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.082: INFO: 	Container influxdb ready: true, restart count 0
Jan 15 22:31:30.082: INFO: telemetry-agent-559f9c8855-xs9n8 from pks-system started at 2019-01-15 20:12:30 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.082: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:31:30.082: INFO: 
Logging pods the kubelet thinks is on node b660f798-38a0-4e83-a501-5381799304ec before test
Jan 15 22:31:30.090: INFO: kubernetes-dashboard-5f4b59b97f-rrcng from kube-system started at 2019-01-15 20:06:44 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.090: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 15 22:31:30.090: INFO: cert-generator-v0.11-h8wxd from pks-system started at 2019-01-15 20:06:48 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.090: INFO: 	Container cert-generator ready: false, restart count 0
Jan 15 22:31:30.090: INFO: fluent-bit-kjcjq from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.090: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:31:30.090: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:31:30.090: INFO: event-controller-6c77ddd949-2mr6m from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.090: INFO: 	Container event-controller ready: true, restart count 1
Jan 15 22:31:30.090: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:31:30.090: INFO: wavefront-proxy-5d455bcbc6-tjnrz from kube-system started at 2019-01-15 20:09:32 +0000 UTC (4 container statuses recorded)
Jan 15 22:31:30.090: INFO: 	Container heapster ready: true, restart count 0
Jan 15 22:31:30.091: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan 15 22:31:30.091: INFO: 	Container telegraf ready: true, restart count 0
Jan 15 22:31:30.091: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan 15 22:31:30.091: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-jjmrz from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:31:30.091: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 22:31:30.091: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:31:30.091: INFO: heapster-85647cf566-x9tdm from kube-system started at 2019-01-15 20:06:38 +0000 UTC (1 container statuses recorded)
Jan 15 22:31:30.091: INFO: 	Container heapster ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 16f34f29-58df-43ef-838e-06a19f186c15
STEP: verifying the node has the label node 77857714-16e9-437d-8ce8-445ba965630c
STEP: verifying the node has the label node b660f798-38a0-4e83-a501-5381799304ec
Jan 15 22:31:30.140: INFO: Pod sonobuoy requesting resource cpu=0m on Node 16f34f29-58df-43ef-838e-06a19f186c15
Jan 15 22:31:30.140: INFO: Pod sonobuoy-e2e-job-7725116febbe4ed6 requesting resource cpu=0m on Node 77857714-16e9-437d-8ce8-445ba965630c
Jan 15 22:31:30.140: INFO: Pod sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-bqggf requesting resource cpu=0m on Node 77857714-16e9-437d-8ce8-445ba965630c
Jan 15 22:31:30.140: INFO: Pod sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-jjmrz requesting resource cpu=0m on Node b660f798-38a0-4e83-a501-5381799304ec
Jan 15 22:31:30.140: INFO: Pod sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-m6gxg requesting resource cpu=0m on Node 16f34f29-58df-43ef-838e-06a19f186c15
Jan 15 22:31:30.140: INFO: Pod heapster-85647cf566-x9tdm requesting resource cpu=0m on Node b660f798-38a0-4e83-a501-5381799304ec
Jan 15 22:31:30.140: INFO: Pod kube-dns-7559c96fc4-fmw6c requesting resource cpu=260m on Node 16f34f29-58df-43ef-838e-06a19f186c15
Jan 15 22:31:30.141: INFO: Pod kubernetes-dashboard-5f4b59b97f-rrcng requesting resource cpu=50m on Node b660f798-38a0-4e83-a501-5381799304ec
Jan 15 22:31:30.141: INFO: Pod metrics-server-555d98886f-78dxc requesting resource cpu=0m on Node 77857714-16e9-437d-8ce8-445ba965630c
Jan 15 22:31:30.141: INFO: Pod monitoring-influxdb-cdcf4674-lt4k2 requesting resource cpu=0m on Node 77857714-16e9-437d-8ce8-445ba965630c
Jan 15 22:31:30.141: INFO: Pod wavefront-proxy-5d455bcbc6-tjnrz requesting resource cpu=0m on Node b660f798-38a0-4e83-a501-5381799304ec
Jan 15 22:31:30.141: INFO: Pod event-controller-6c77ddd949-2mr6m requesting resource cpu=0m on Node b660f798-38a0-4e83-a501-5381799304ec
Jan 15 22:31:30.141: INFO: Pod fluent-bit-2szkk requesting resource cpu=0m on Node 77857714-16e9-437d-8ce8-445ba965630c
Jan 15 22:31:30.141: INFO: Pod fluent-bit-kjcjq requesting resource cpu=0m on Node b660f798-38a0-4e83-a501-5381799304ec
Jan 15 22:31:30.141: INFO: Pod fluent-bit-xszkh requesting resource cpu=0m on Node 16f34f29-58df-43ef-838e-06a19f186c15
Jan 15 22:31:30.141: INFO: Pod sink-controller-65595c498b-94m5j requesting resource cpu=0m on Node 77857714-16e9-437d-8ce8-445ba965630c
Jan 15 22:31:30.141: INFO: Pod telemetry-agent-559f9c8855-xs9n8 requesting resource cpu=0m on Node 77857714-16e9-437d-8ce8-445ba965630c
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc728a2-1915-11e9-993a-025056003018.157a2642c3d33046], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-mbhwh/filler-pod-4dc728a2-1915-11e9-993a-025056003018 to 16f34f29-58df-43ef-838e-06a19f186c15]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc728a2-1915-11e9-993a-025056003018.157a26431cc30251], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc728a2-1915-11e9-993a-025056003018.157a264320f07761], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc728a2-1915-11e9-993a-025056003018.157a26432da5643e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc81e33-1915-11e9-993a-025056003018.157a2642c507d166], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-mbhwh/filler-pod-4dc81e33-1915-11e9-993a-025056003018 to 77857714-16e9-437d-8ce8-445ba965630c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc81e33-1915-11e9-993a-025056003018.157a264326228eb0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc81e33-1915-11e9-993a-025056003018.157a26432a407726], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dc81e33-1915-11e9-993a-025056003018.157a264335024f92], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dca0aed-1915-11e9-993a-025056003018.157a2642c5c317b0], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-mbhwh/filler-pod-4dca0aed-1915-11e9-993a-025056003018 to b660f798-38a0-4e83-a501-5381799304ec]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dca0aed-1915-11e9-993a-025056003018.157a264371871af9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dca0aed-1915-11e9-993a-025056003018.157a26437560e1d9], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4dca0aed-1915-11e9-993a-025056003018.157a264382802392], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157a2643b5a9c691], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 16f34f29-58df-43ef-838e-06a19f186c15
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 77857714-16e9-437d-8ce8-445ba965630c
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node b660f798-38a0-4e83-a501-5381799304ec
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:31:35.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mbhwh" for this suite.
Jan 15 22:31:41.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:41.383: INFO: namespace: e2e-tests-sched-pred-mbhwh, resource: bindings, ignored listing per whitelist
Jan 15 22:31:41.396: INFO: namespace e2e-tests-sched-pred-mbhwh deletion completed in 6.119206125s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.550 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:31:41.396: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-n28r6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 15 22:31:41.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 api-versions'
Jan 15 22:31:41.751: INFO: stderr: ""
Jan 15 22:31:41.751: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps.pivotal.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:31:41.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n28r6" for this suite.
Jan 15 22:31:47.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:47.805: INFO: namespace: e2e-tests-kubectl-n28r6, resource: bindings, ignored listing per whitelist
Jan 15 22:31:47.891: INFO: namespace e2e-tests-kubectl-n28r6 deletion completed in 6.134040916s

• [SLOW TEST:6.495 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:31:47.893: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hpqfc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 22:31:48.112: INFO: Waiting up to 5m0s for pod "downward-api-587b9af0-1915-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-hpqfc" to be "success or failure"
Jan 15 22:31:48.149: INFO: Pod "downward-api-587b9af0-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 36.367849ms
Jan 15 22:31:50.153: INFO: Pod "downward-api-587b9af0-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040375519s
Jan 15 22:31:52.156: INFO: Pod "downward-api-587b9af0-1915-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044108986s
STEP: Saw pod success
Jan 15 22:31:52.157: INFO: Pod "downward-api-587b9af0-1915-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:31:52.159: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downward-api-587b9af0-1915-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:31:52.186: INFO: Waiting for pod downward-api-587b9af0-1915-11e9-993a-025056003018 to disappear
Jan 15 22:31:52.189: INFO: Pod downward-api-587b9af0-1915-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:31:52.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hpqfc" for this suite.
Jan 15 22:31:58.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:31:58.301: INFO: namespace: e2e-tests-downward-api-hpqfc, resource: bindings, ignored listing per whitelist
Jan 15 22:31:58.307: INFO: namespace e2e-tests-downward-api-hpqfc deletion completed in 6.114354248s

• [SLOW TEST:10.414 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:31:58.308: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qm429
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:31:58.520: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018" in namespace "e2e-tests-projected-qm429" to be "success or failure"
Jan 15 22:31:58.523: INFO: Pod "downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.633128ms
Jan 15 22:32:00.527: INFO: Pod "downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006288827s
Jan 15 22:32:02.530: INFO: Pod "downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009916992s
STEP: Saw pod success
Jan 15 22:32:02.530: INFO: Pod "downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:32:02.535: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:32:02.618: INFO: Waiting for pod downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018 to disappear
Jan 15 22:32:02.623: INFO: Pod downwardapi-volume-5eb0481f-1915-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:32:02.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qm429" for this suite.
Jan 15 22:32:08.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:32:08.746: INFO: namespace: e2e-tests-projected-qm429, resource: bindings, ignored listing per whitelist
Jan 15 22:32:08.763: INFO: namespace e2e-tests-projected-qm429 deletion completed in 6.135117886s

• [SLOW TEST:10.455 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:32:08.764: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xn9fh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:32:08.993: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64ec1d91-1915-11e9-993a-025056003018" in namespace "e2e-tests-projected-xn9fh" to be "success or failure"
Jan 15 22:32:09.001: INFO: Pod "downwardapi-volume-64ec1d91-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 8.276165ms
Jan 15 22:32:11.006: INFO: Pod "downwardapi-volume-64ec1d91-1915-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013404993s
STEP: Saw pod success
Jan 15 22:32:11.007: INFO: Pod "downwardapi-volume-64ec1d91-1915-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:32:11.011: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-64ec1d91-1915-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:32:11.032: INFO: Waiting for pod downwardapi-volume-64ec1d91-1915-11e9-993a-025056003018 to disappear
Jan 15 22:32:11.036: INFO: Pod downwardapi-volume-64ec1d91-1915-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:32:11.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xn9fh" for this suite.
Jan 15 22:32:17.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:32:17.137: INFO: namespace: e2e-tests-projected-xn9fh, resource: bindings, ignored listing per whitelist
Jan 15 22:32:17.143: INFO: namespace e2e-tests-projected-xn9fh deletion completed in 6.102134833s

• [SLOW TEST:8.379 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:32:17.147: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-x4f4f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-2snlk
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-72nlq
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:32:23.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-x4f4f" for this suite.
Jan 15 22:32:29.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:32:29.753: INFO: namespace: e2e-tests-namespaces-x4f4f, resource: bindings, ignored listing per whitelist
Jan 15 22:32:29.776: INFO: namespace e2e-tests-namespaces-x4f4f deletion completed in 6.105073362s
STEP: Destroying namespace "e2e-tests-nsdeletetest-2snlk" for this suite.
Jan 15 22:32:29.780: INFO: Namespace e2e-tests-nsdeletetest-2snlk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-72nlq" for this suite.
Jan 15 22:32:35.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:32:35.831: INFO: namespace: e2e-tests-nsdeletetest-72nlq, resource: bindings, ignored listing per whitelist
Jan 15 22:32:35.889: INFO: namespace e2e-tests-nsdeletetest-72nlq deletion completed in 6.108225665s

• [SLOW TEST:18.742 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:32:35.889: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5jpds
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:32:36.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75140540-1915-11e9-993a-025056003018" in namespace "e2e-tests-projected-5jpds" to be "success or failure"
Jan 15 22:32:36.095: INFO: Pod "downwardapi-volume-75140540-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 9.686612ms
Jan 15 22:32:38.099: INFO: Pod "downwardapi-volume-75140540-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013836129s
Jan 15 22:32:40.103: INFO: Pod "downwardapi-volume-75140540-1915-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017165581s
STEP: Saw pod success
Jan 15 22:32:40.103: INFO: Pod "downwardapi-volume-75140540-1915-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:32:40.106: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-75140540-1915-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:32:40.127: INFO: Waiting for pod downwardapi-volume-75140540-1915-11e9-993a-025056003018 to disappear
Jan 15 22:32:40.131: INFO: Pod downwardapi-volume-75140540-1915-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:32:40.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5jpds" for this suite.
Jan 15 22:32:46.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:32:46.235: INFO: namespace: e2e-tests-projected-5jpds, resource: bindings, ignored listing per whitelist
Jan 15 22:32:46.235: INFO: namespace e2e-tests-projected-5jpds deletion completed in 6.100861484s

• [SLOW TEST:10.346 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:32:46.236: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gwqml
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 15 22:32:46.448: INFO: namespace e2e-tests-kubectl-gwqml
Jan 15 22:32:46.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-gwqml'
Jan 15 22:32:46.692: INFO: stderr: ""
Jan 15 22:32:46.692: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 22:32:47.697: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:32:47.697: INFO: Found 0 / 1
Jan 15 22:32:48.697: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:32:48.697: INFO: Found 0 / 1
Jan 15 22:32:49.696: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:32:49.696: INFO: Found 1 / 1
Jan 15 22:32:49.696: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 22:32:49.699: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:32:49.699: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 22:32:49.699: INFO: wait on redis-master startup in e2e-tests-kubectl-gwqml 
Jan 15 22:32:49.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 logs redis-master-99zq8 redis-master --namespace=e2e-tests-kubectl-gwqml'
Jan 15 22:32:49.831: INFO: stderr: ""
Jan 15 22:32:49.831: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 22:32:48.859 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 22:32:48.859 # Server started, Redis version 3.2.12\n1:M 15 Jan 22:32:48.859 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 22:32:48.859 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 15 22:32:49.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-gwqml'
Jan 15 22:32:49.953: INFO: stderr: ""
Jan 15 22:32:49.953: INFO: stdout: "service/rm2 exposed\n"
Jan 15 22:32:49.960: INFO: Service rm2 in namespace e2e-tests-kubectl-gwqml found.
STEP: exposing service
Jan 15 22:32:51.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-gwqml'
Jan 15 22:32:52.126: INFO: stderr: ""
Jan 15 22:32:52.126: INFO: stdout: "service/rm3 exposed\n"
Jan 15 22:32:52.139: INFO: Service rm3 in namespace e2e-tests-kubectl-gwqml found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:32:54.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gwqml" for this suite.
Jan 15 22:33:16.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:33:16.176: INFO: namespace: e2e-tests-kubectl-gwqml, resource: bindings, ignored listing per whitelist
Jan 15 22:33:16.248: INFO: namespace e2e-tests-kubectl-gwqml deletion completed in 22.10020692s

• [SLOW TEST:30.013 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:33:16.251: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gfcc2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:33:16.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8d238b30-1915-11e9-993a-025056003018" in namespace "e2e-tests-projected-gfcc2" to be "success or failure"
Jan 15 22:33:16.456: INFO: Pod "downwardapi-volume-8d238b30-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 7.451851ms
Jan 15 22:33:18.461: INFO: Pod "downwardapi-volume-8d238b30-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012072522s
Jan 15 22:33:20.465: INFO: Pod "downwardapi-volume-8d238b30-1915-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01601855s
STEP: Saw pod success
Jan 15 22:33:20.465: INFO: Pod "downwardapi-volume-8d238b30-1915-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:33:20.468: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-8d238b30-1915-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:33:20.495: INFO: Waiting for pod downwardapi-volume-8d238b30-1915-11e9-993a-025056003018 to disappear
Jan 15 22:33:20.504: INFO: Pod downwardapi-volume-8d238b30-1915-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:33:20.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gfcc2" for this suite.
Jan 15 22:33:26.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:33:26.552: INFO: namespace: e2e-tests-projected-gfcc2, resource: bindings, ignored listing per whitelist
Jan 15 22:33:26.613: INFO: namespace e2e-tests-projected-gfcc2 deletion completed in 6.104964151s

• [SLOW TEST:10.363 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:33:26.616: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bqnsv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 22:33:26.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-bqnsv'
Jan 15 22:33:26.942: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 15 22:33:26.943: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 15 22:33:26.972: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-qbv6g]
Jan 15 22:33:26.972: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-qbv6g" in namespace "e2e-tests-kubectl-bqnsv" to be "running and ready"
Jan 15 22:33:26.979: INFO: Pod "e2e-test-nginx-rc-qbv6g": Phase="Pending", Reason="", readiness=false. Elapsed: 7.360777ms
Jan 15 22:33:28.983: INFO: Pod "e2e-test-nginx-rc-qbv6g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01078314s
Jan 15 22:33:30.987: INFO: Pod "e2e-test-nginx-rc-qbv6g": Phase="Running", Reason="", readiness=true. Elapsed: 4.014748425s
Jan 15 22:33:30.987: INFO: Pod "e2e-test-nginx-rc-qbv6g" satisfied condition "running and ready"
Jan 15 22:33:30.987: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-qbv6g]
Jan 15 22:33:30.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-bqnsv'
Jan 15 22:33:31.117: INFO: stderr: ""
Jan 15 22:33:31.117: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Jan 15 22:33:31.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-bqnsv'
Jan 15 22:33:31.228: INFO: stderr: ""
Jan 15 22:33:31.228: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:33:31.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bqnsv" for this suite.
Jan 15 22:33:37.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:33:37.360: INFO: namespace: e2e-tests-kubectl-bqnsv, resource: bindings, ignored listing per whitelist
Jan 15 22:33:37.373: INFO: namespace e2e-tests-kubectl-bqnsv deletion completed in 6.134489166s

• [SLOW TEST:10.757 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:33:37.375: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-hz869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 15 22:33:41.616: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-99bc91b5-1915-11e9-993a-025056003018", GenerateName:"", Namespace:"e2e-tests-pods-hz869", SelfLink:"/api/v1/namespaces/e2e-tests-pods-hz869/pods/pod-submit-remove-99bc91b5-1915-11e9-993a-025056003018", UID:"99bdd2b1-1915-11e9-8273-005056af1926", ResourceVersion:"15393", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683188417, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"579056367", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fjvhp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422b02600), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fjvhp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4229fdae8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"16f34f29-58df-43ef-838e-06a19f186c15", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42294fda0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4229fdb20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4229fdb40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4229fdb48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188417, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188420, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188420, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683188417, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"30.0.3.3", PodIP:"40.0.10.2", StartTime:(*v1.Time)(0xc422f87180), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc422f871a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://be2c0610f07505cd1759f36b796a4a14a1f8778500500f7041dee2e367814fd7"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 15 22:33:46.634: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:33:46.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hz869" for this suite.
Jan 15 22:33:52.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:33:52.679: INFO: namespace: e2e-tests-pods-hz869, resource: bindings, ignored listing per whitelist
Jan 15 22:33:52.756: INFO: namespace e2e-tests-pods-hz869 deletion completed in 6.114806298s

• [SLOW TEST:15.381 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:33:52.757: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-vdjzk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vdjzk
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-vdjzk
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-vdjzk
Jan 15 22:33:53.035: INFO: Found 0 stateful pods, waiting for 1
Jan 15 22:34:03.040: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 15 22:34:03.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 22:34:03.282: INFO: stderr: ""
Jan 15 22:34:03.282: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 22:34:03.282: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 22:34:03.287: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 15 22:34:13.291: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 22:34:13.291: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 22:34:13.311: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999775s
Jan 15 22:34:14.315: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994201249s
Jan 15 22:34:15.319: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99043638s
Jan 15 22:34:16.324: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985478636s
Jan 15 22:34:17.328: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981523103s
Jan 15 22:34:18.336: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977179407s
Jan 15 22:34:19.342: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.968320626s
Jan 15 22:34:20.346: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.962600288s
Jan 15 22:34:21.352: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.958355793s
Jan 15 22:34:22.357: INFO: Verifying statefulset ss doesn't scale past 1 for another 953.330226ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-vdjzk
Jan 15 22:34:23.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 22:34:23.588: INFO: stderr: ""
Jan 15 22:34:23.588: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 22:34:23.588: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 22:34:23.592: INFO: Found 1 stateful pods, waiting for 3
Jan 15 22:34:33.597: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:34:33.597: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:34:33.597: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 15 22:34:33.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 22:34:33.790: INFO: stderr: ""
Jan 15 22:34:33.790: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 22:34:33.790: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 22:34:33.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 22:34:34.032: INFO: stderr: ""
Jan 15 22:34:34.032: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 22:34:34.032: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 22:34:34.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 22:34:34.288: INFO: stderr: ""
Jan 15 22:34:34.288: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 22:34:34.288: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 22:34:34.288: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 22:34:34.291: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 15 22:34:44.300: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 22:34:44.300: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 22:34:44.300: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 22:34:44.319: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999693s
Jan 15 22:34:45.324: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990707573s
Jan 15 22:34:46.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985953623s
Jan 15 22:34:47.333: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981704227s
Jan 15 22:34:48.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977448104s
Jan 15 22:34:49.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973218638s
Jan 15 22:34:50.344: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969434091s
Jan 15 22:34:51.348: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965716424s
Jan 15 22:34:52.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962127372s
Jan 15 22:34:53.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.64431ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-vdjzk
Jan 15 22:34:54.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 22:34:54.582: INFO: stderr: ""
Jan 15 22:34:54.582: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 22:34:54.582: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 22:34:54.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 22:34:54.785: INFO: stderr: ""
Jan 15 22:34:54.785: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 22:34:54.785: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 22:34:54.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-vdjzk ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 22:34:55.017: INFO: stderr: ""
Jan 15 22:34:55.017: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 22:34:55.017: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 22:34:55.017: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 22:35:05.093: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vdjzk
Jan 15 22:35:05.099: INFO: Scaling statefulset ss to 0
Jan 15 22:35:05.109: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 22:35:05.112: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:35:05.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vdjzk" for this suite.
Jan 15 22:35:11.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:35:11.218: INFO: namespace: e2e-tests-statefulset-vdjzk, resource: bindings, ignored listing per whitelist
Jan 15 22:35:11.243: INFO: namespace e2e-tests-statefulset-vdjzk deletion completed in 6.115512363s

• [SLOW TEST:78.487 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:35:11.245: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-2ngsh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-2ngsh
Jan 15 22:35:15.461: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-2ngsh
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 22:35:15.465: INFO: Initial restart count of pod liveness-exec is 0
Jan 15 22:35:59.562: INFO: Restart count of pod e2e-tests-container-probe-2ngsh/liveness-exec is now 1 (44.097341317s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:35:59.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2ngsh" for this suite.
Jan 15 22:36:05.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:36:05.703: INFO: namespace: e2e-tests-container-probe-2ngsh, resource: bindings, ignored listing per whitelist
Jan 15 22:36:05.705: INFO: namespace e2e-tests-container-probe-2ngsh deletion completed in 6.118287211s

• [SLOW TEST:54.461 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:36:05.706: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-r2x77
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f2241c12-1915-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 22:36:05.918: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f225c565-1915-11e9-993a-025056003018" in namespace "e2e-tests-projected-r2x77" to be "success or failure"
Jan 15 22:36:05.929: INFO: Pod "pod-projected-secrets-f225c565-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 11.276116ms
Jan 15 22:36:07.934: INFO: Pod "pod-projected-secrets-f225c565-1915-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016173414s
Jan 15 22:36:09.938: INFO: Pod "pod-projected-secrets-f225c565-1915-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020504945s
STEP: Saw pod success
Jan 15 22:36:09.938: INFO: Pod "pod-projected-secrets-f225c565-1915-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:36:09.941: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-secrets-f225c565-1915-11e9-993a-025056003018 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:36:09.958: INFO: Waiting for pod pod-projected-secrets-f225c565-1915-11e9-993a-025056003018 to disappear
Jan 15 22:36:09.966: INFO: Pod pod-projected-secrets-f225c565-1915-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:36:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r2x77" for this suite.
Jan 15 22:36:15.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:36:16.036: INFO: namespace: e2e-tests-projected-r2x77, resource: bindings, ignored listing per whitelist
Jan 15 22:36:16.091: INFO: namespace e2e-tests-projected-r2x77 deletion completed in 6.121117273s

• [SLOW TEST:10.385 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:36:16.091: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-sdb9c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 15 22:36:20.308: INFO: Pod pod-hostip-f8556090-1915-11e9-993a-025056003018 has hostIP: 30.0.3.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:36:20.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-sdb9c" for this suite.
Jan 15 22:36:42.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:36:42.390: INFO: namespace: e2e-tests-pods-sdb9c, resource: bindings, ignored listing per whitelist
Jan 15 22:36:42.430: INFO: namespace e2e-tests-pods-sdb9c deletion completed in 22.119137871s

• [SLOW TEST:26.339 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:36:42.431: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zfvk2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:36:42.658: INFO: Waiting up to 5m0s for pod "downwardapi-volume-080b826f-1916-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-zfvk2" to be "success or failure"
Jan 15 22:36:42.661: INFO: Pod "downwardapi-volume-080b826f-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 3.078992ms
Jan 15 22:36:44.665: INFO: Pod "downwardapi-volume-080b826f-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00749897s
Jan 15 22:36:46.670: INFO: Pod "downwardapi-volume-080b826f-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012403239s
STEP: Saw pod success
Jan 15 22:36:46.670: INFO: Pod "downwardapi-volume-080b826f-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:36:46.674: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-080b826f-1916-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:36:46.704: INFO: Waiting for pod downwardapi-volume-080b826f-1916-11e9-993a-025056003018 to disappear
Jan 15 22:36:46.707: INFO: Pod downwardapi-volume-080b826f-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:36:46.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zfvk2" for this suite.
Jan 15 22:36:52.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:36:52.772: INFO: namespace: e2e-tests-downward-api-zfvk2, resource: bindings, ignored listing per whitelist
Jan 15 22:36:52.817: INFO: namespace e2e-tests-downward-api-zfvk2 deletion completed in 6.106304153s

• [SLOW TEST:10.386 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:36:52.821: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-qxmqv
Jan 15 22:36:53.021: INFO: Unexpected error occurred: 0-length response
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
STEP: Destroying namespace "e2e-tests-replicaset-qxmqv" for this suite.
Jan 15 22:36:59.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:36:59.079: INFO: namespace: e2e-tests-replicaset-qxmqv, resource: bindings, ignored listing per whitelist
Jan 15 22:36:59.127: INFO: namespace e2e-tests-replicaset-qxmqv deletion completed in 6.103075366s

• Failure in Spec Setup (BeforeEach) [6.306 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance] [BeforeEach]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Expected error:
      <*errors.errorString | 0xc4203756d0>: {
          s: "0-length response",
      }
      0-length response
  not to have occurred

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/psp_util.go:144
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:36:59.130: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qrnwd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 15 22:36:59.321: INFO: Waiting up to 5m0s for pod "pod-11fb09ed-1916-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-qrnwd" to be "success or failure"
Jan 15 22:36:59.326: INFO: Pod "pod-11fb09ed-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.489666ms
Jan 15 22:37:01.330: INFO: Pod "pod-11fb09ed-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008727118s
Jan 15 22:37:03.334: INFO: Pod "pod-11fb09ed-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013133577s
STEP: Saw pod success
Jan 15 22:37:03.334: INFO: Pod "pod-11fb09ed-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:37:03.337: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-11fb09ed-1916-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:37:03.357: INFO: Waiting for pod pod-11fb09ed-1916-11e9-993a-025056003018 to disappear
Jan 15 22:37:03.364: INFO: Pod pod-11fb09ed-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:37:03.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qrnwd" for this suite.
Jan 15 22:37:09.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:37:09.460: INFO: namespace: e2e-tests-emptydir-qrnwd, resource: bindings, ignored listing per whitelist
Jan 15 22:37:09.481: INFO: namespace e2e-tests-emptydir-qrnwd deletion completed in 6.113515924s

• [SLOW TEST:10.352 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:37:09.482: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bcjsk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 15 22:37:09.691: INFO: Waiting up to 5m0s for pod "pod-18292ecd-1916-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-bcjsk" to be "success or failure"
Jan 15 22:37:09.700: INFO: Pod "pod-18292ecd-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 9.097081ms
Jan 15 22:37:11.704: INFO: Pod "pod-18292ecd-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013018976s
Jan 15 22:37:13.708: INFO: Pod "pod-18292ecd-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017103817s
STEP: Saw pod success
Jan 15 22:37:13.709: INFO: Pod "pod-18292ecd-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:37:13.712: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-18292ecd-1916-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:37:13.732: INFO: Waiting for pod pod-18292ecd-1916-11e9-993a-025056003018 to disappear
Jan 15 22:37:13.741: INFO: Pod pod-18292ecd-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:37:13.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bcjsk" for this suite.
Jan 15 22:37:19.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:37:19.819: INFO: namespace: e2e-tests-emptydir-bcjsk, resource: bindings, ignored listing per whitelist
Jan 15 22:37:19.882: INFO: namespace e2e-tests-emptydir-bcjsk deletion completed in 6.136725245s

• [SLOW TEST:10.400 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:37:19.882: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-v7q8n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1e5f1c8b-1916-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 22:37:20.118: INFO: Waiting up to 5m0s for pod "pod-secrets-1e5feebf-1916-11e9-993a-025056003018" in namespace "e2e-tests-secrets-v7q8n" to be "success or failure"
Jan 15 22:37:20.124: INFO: Pod "pod-secrets-1e5feebf-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 5.544358ms
Jan 15 22:37:22.129: INFO: Pod "pod-secrets-1e5feebf-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010208157s
Jan 15 22:37:24.134: INFO: Pod "pod-secrets-1e5feebf-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015985262s
STEP: Saw pod success
Jan 15 22:37:24.135: INFO: Pod "pod-secrets-1e5feebf-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:37:24.138: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-1e5feebf-1916-11e9-993a-025056003018 container secret-env-test: <nil>
STEP: delete the pod
Jan 15 22:37:24.162: INFO: Waiting for pod pod-secrets-1e5feebf-1916-11e9-993a-025056003018 to disappear
Jan 15 22:37:24.165: INFO: Pod pod-secrets-1e5feebf-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:37:24.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v7q8n" for this suite.
Jan 15 22:37:30.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:37:30.239: INFO: namespace: e2e-tests-secrets-v7q8n, resource: bindings, ignored listing per whitelist
Jan 15 22:37:30.310: INFO: namespace e2e-tests-secrets-v7q8n deletion completed in 6.141243181s

• [SLOW TEST:10.428 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:37:30.310: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-v76fn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0115 22:37:31.624825      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 22:37:31.624: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:37:31.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-v76fn" for this suite.
Jan 15 22:37:37.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:37:37.687: INFO: namespace: e2e-tests-gc-v76fn, resource: bindings, ignored listing per whitelist
Jan 15 22:37:37.748: INFO: namespace e2e-tests-gc-v76fn deletion completed in 6.119398003s

• [SLOW TEST:7.438 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:37:37.749: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qfkt6
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 15 22:37:37.956: INFO: Waiting up to 5m0s for pod "pod-2901e80b-1916-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-qfkt6" to be "success or failure"
Jan 15 22:37:37.967: INFO: Pod "pod-2901e80b-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 10.810857ms
Jan 15 22:37:39.971: INFO: Pod "pod-2901e80b-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014419779s
Jan 15 22:37:41.976: INFO: Pod "pod-2901e80b-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019234602s
STEP: Saw pod success
Jan 15 22:37:41.976: INFO: Pod "pod-2901e80b-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:37:41.982: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-2901e80b-1916-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:37:42.011: INFO: Waiting for pod pod-2901e80b-1916-11e9-993a-025056003018 to disappear
Jan 15 22:37:42.015: INFO: Pod pod-2901e80b-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:37:42.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qfkt6" for this suite.
Jan 15 22:37:48.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:37:48.137: INFO: namespace: e2e-tests-emptydir-qfkt6, resource: bindings, ignored listing per whitelist
Jan 15 22:37:48.143: INFO: namespace e2e-tests-emptydir-qfkt6 deletion completed in 6.123083332s

• [SLOW TEST:10.394 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:37:48.144: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-ll5qv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 15 22:37:58.386: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:37:58.393: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:00.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:00.398: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:02.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:02.399: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:04.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:04.398: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:06.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:06.400: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:08.396: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:08.400: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:10.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:10.399: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:12.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:12.401: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:14.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:14.399: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:16.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:16.398: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 15 22:38:18.394: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 15 22:38:18.398: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:38:18.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ll5qv" for this suite.
Jan 15 22:38:40.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:38:40.473: INFO: namespace: e2e-tests-container-lifecycle-hook-ll5qv, resource: bindings, ignored listing per whitelist
Jan 15 22:38:40.507: INFO: namespace e2e-tests-container-lifecycle-hook-ll5qv deletion completed in 22.095659861s

• [SLOW TEST:52.364 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:38:40.511: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-8txmd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 15 22:38:41.238: INFO: Waiting up to 5m0s for pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld" in namespace "e2e-tests-svcaccounts-8txmd" to be "success or failure"
Jan 15 22:38:41.247: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld": Phase="Pending", Reason="", readiness=false. Elapsed: 9.483185ms
Jan 15 22:38:43.251: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013539454s
Jan 15 22:38:45.255: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016770977s
STEP: Saw pod success
Jan 15 22:38:45.255: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld" satisfied condition "success or failure"
Jan 15 22:38:45.259: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld container token-test: <nil>
STEP: delete the pod
Jan 15 22:38:45.284: INFO: Waiting for pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld to disappear
Jan 15 22:38:45.291: INFO: Pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-p6nld no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 15 22:38:45.297: INFO: Waiting up to 5m0s for pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm" in namespace "e2e-tests-svcaccounts-8txmd" to be "success or failure"
Jan 15 22:38:45.302: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.816452ms
Jan 15 22:38:47.310: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012222237s
Jan 15 22:38:49.313: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015889727s
STEP: Saw pod success
Jan 15 22:38:49.313: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm" satisfied condition "success or failure"
Jan 15 22:38:49.316: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm container root-ca-test: <nil>
STEP: delete the pod
Jan 15 22:38:49.343: INFO: Waiting for pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm to disappear
Jan 15 22:38:49.346: INFO: Pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-bm5tm no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 15 22:38:49.352: INFO: Waiting up to 5m0s for pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w" in namespace "e2e-tests-svcaccounts-8txmd" to be "success or failure"
Jan 15 22:38:49.361: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w": Phase="Pending", Reason="", readiness=false. Elapsed: 8.893903ms
Jan 15 22:38:51.365: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012508099s
Jan 15 22:38:53.369: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016437232s
STEP: Saw pod success
Jan 15 22:38:53.369: INFO: Pod "pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w" satisfied condition "success or failure"
Jan 15 22:38:53.372: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w container namespace-test: <nil>
STEP: delete the pod
Jan 15 22:38:53.397: INFO: Waiting for pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w to disappear
Jan 15 22:38:53.401: INFO: Pod pod-service-account-4eb8c94c-1916-11e9-993a-025056003018-lfk5w no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:38:53.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8txmd" for this suite.
Jan 15 22:38:59.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:38:59.504: INFO: namespace: e2e-tests-svcaccounts-8txmd, resource: bindings, ignored listing per whitelist
Jan 15 22:38:59.518: INFO: namespace e2e-tests-svcaccounts-8txmd deletion completed in 6.112269771s

• [SLOW TEST:19.008 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:38:59.520: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-6pz27
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 15 22:39:09.785: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:09.790: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:11.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:11.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:13.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:13.795: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:15.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:15.795: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:17.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:17.793: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:19.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:19.793: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:21.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:21.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:23.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:23.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:25.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:25.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:27.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:27.796: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:29.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:29.795: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:31.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:31.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:33.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:33.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:35.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:35.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:37.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:37.794: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 15 22:39:39.790: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 15 22:39:39.793: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:39:39.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6pz27" for this suite.
Jan 15 22:40:01.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:40:01.957: INFO: namespace: e2e-tests-container-lifecycle-hook-6pz27, resource: bindings, ignored listing per whitelist
Jan 15 22:40:01.960: INFO: namespace e2e-tests-container-lifecycle-hook-6pz27 deletion completed in 22.161707505s

• [SLOW TEST:62.440 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:40:01.963: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zq9d7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7efe0b61-1916-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:40:02.228: INFO: Waiting up to 5m0s for pod "pod-configmaps-7efecac2-1916-11e9-993a-025056003018" in namespace "e2e-tests-configmap-zq9d7" to be "success or failure"
Jan 15 22:40:02.232: INFO: Pod "pod-configmaps-7efecac2-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.281967ms
Jan 15 22:40:04.237: INFO: Pod "pod-configmaps-7efecac2-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00887109s
Jan 15 22:40:06.245: INFO: Pod "pod-configmaps-7efecac2-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017150276s
STEP: Saw pod success
Jan 15 22:40:06.246: INFO: Pod "pod-configmaps-7efecac2-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:40:06.249: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-7efecac2-1916-11e9-993a-025056003018 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:40:06.275: INFO: Waiting for pod pod-configmaps-7efecac2-1916-11e9-993a-025056003018 to disappear
Jan 15 22:40:06.279: INFO: Pod pod-configmaps-7efecac2-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:40:06.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zq9d7" for this suite.
Jan 15 22:40:12.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:40:12.351: INFO: namespace: e2e-tests-configmap-zq9d7, resource: bindings, ignored listing per whitelist
Jan 15 22:40:12.392: INFO: namespace e2e-tests-configmap-zq9d7 deletion completed in 6.108919522s

• [SLOW TEST:10.429 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:40:12.392: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qp5bx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 15 22:40:12.595: INFO: Waiting up to 5m0s for pod "pod-852e337d-1916-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-qp5bx" to be "success or failure"
Jan 15 22:40:12.600: INFO: Pod "pod-852e337d-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.35585ms
Jan 15 22:40:14.605: INFO: Pod "pod-852e337d-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009148312s
Jan 15 22:40:16.610: INFO: Pod "pod-852e337d-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013997881s
STEP: Saw pod success
Jan 15 22:40:16.610: INFO: Pod "pod-852e337d-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:40:16.612: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-852e337d-1916-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:40:16.640: INFO: Waiting for pod pod-852e337d-1916-11e9-993a-025056003018 to disappear
Jan 15 22:40:16.644: INFO: Pod pod-852e337d-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:40:16.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qp5bx" for this suite.
Jan 15 22:40:22.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:40:22.768: INFO: namespace: e2e-tests-emptydir-qp5bx, resource: bindings, ignored listing per whitelist
Jan 15 22:40:22.783: INFO: namespace e2e-tests-emptydir-qp5bx deletion completed in 6.135246849s

• [SLOW TEST:10.391 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:40:22.786: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9m2jt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 22:40:27.545: INFO: Successfully updated pod "labelsupdate8b62b53f-1916-11e9-993a-025056003018"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:40:29.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9m2jt" for this suite.
Jan 15 22:40:51.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:40:51.632: INFO: namespace: e2e-tests-projected-9m2jt, resource: bindings, ignored listing per whitelist
Jan 15 22:40:51.675: INFO: namespace e2e-tests-projected-9m2jt deletion completed in 22.102629724s

• [SLOW TEST:28.889 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:40:51.679: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-55qxd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-9c99f647-1916-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 22:40:51.893: INFO: Waiting up to 5m0s for pod "pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018" in namespace "e2e-tests-secrets-55qxd" to be "success or failure"
Jan 15 22:40:51.904: INFO: Pod "pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 10.46627ms
Jan 15 22:40:53.908: INFO: Pod "pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014516581s
Jan 15 22:40:55.912: INFO: Pod "pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018758176s
STEP: Saw pod success
Jan 15 22:40:55.912: INFO: Pod "pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:40:55.915: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:40:55.941: INFO: Waiting for pod pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018 to disappear
Jan 15 22:40:55.944: INFO: Pod pod-secrets-9c9ad7bc-1916-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:40:55.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-55qxd" for this suite.
Jan 15 22:41:01.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:02.023: INFO: namespace: e2e-tests-secrets-55qxd, resource: bindings, ignored listing per whitelist
Jan 15 22:41:02.081: INFO: namespace e2e-tests-secrets-55qxd deletion completed in 6.133012938s

• [SLOW TEST:10.403 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:41:02.082: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-54qtv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 15 22:41:02.303: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 22:41:02.310: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 22:41:02.313: INFO: 
Logging pods the kubelet thinks is on node 16f34f29-58df-43ef-838e-06a19f186c15 before test
Jan 15 22:41:02.320: INFO: kube-dns-7559c96fc4-fmw6c from kube-system started at 2019-01-15 20:06:19 +0000 UTC (3 container statuses recorded)
Jan 15 22:41:02.320: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 22:41:02.320: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 22:41:02.320: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 22:41:02.320: INFO: fluent-bit-xszkh from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.320: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:41:02.320: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:41:02.320: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-15 22:21:52 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.320: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 22:41:02.320: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-m6gxg from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.320: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 22:41:02.320: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:41:02.320: INFO: 
Logging pods the kubelet thinks is on node 77857714-16e9-437d-8ce8-445ba965630c before test
Jan 15 22:41:02.329: INFO: monitoring-influxdb-cdcf4674-lt4k2 from kube-system started at 2019-01-15 20:06:41 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.329: INFO: 	Container influxdb ready: true, restart count 0
Jan 15 22:41:02.329: INFO: telemetry-agent-559f9c8855-xs9n8 from pks-system started at 2019-01-15 20:12:30 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.329: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:41:02.329: INFO: metrics-server-555d98886f-78dxc from kube-system started at 2019-01-15 20:06:35 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.329: INFO: 	Container metrics-server ready: true, restart count 0
Jan 15 22:41:02.330: INFO: fluent-bit-2szkk from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.330: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:41:02.330: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:41:02.330: INFO: sink-controller-65595c498b-94m5j from pks-system started at 2019-01-15 20:06:48 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.330: INFO: 	Container sink-controller ready: true, restart count 0
Jan 15 22:41:02.330: INFO: sonobuoy-e2e-job-7725116febbe4ed6 from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.330: INFO: 	Container e2e ready: true, restart count 0
Jan 15 22:41:02.330: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:41:02.330: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-bqggf from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.330: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 22:41:02.330: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:41:02.330: INFO: 
Logging pods the kubelet thinks is on node b660f798-38a0-4e83-a501-5381799304ec before test
Jan 15 22:41:02.340: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-jjmrz from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.340: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 22:41:02.340: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 22:41:02.340: INFO: kubernetes-dashboard-5f4b59b97f-rrcng from kube-system started at 2019-01-15 20:06:44 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.340: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 15 22:41:02.340: INFO: cert-generator-v0.11-h8wxd from pks-system started at 2019-01-15 20:06:48 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.341: INFO: 	Container cert-generator ready: false, restart count 0
Jan 15 22:41:02.341: INFO: fluent-bit-kjcjq from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.341: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 22:41:02.341: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:41:02.341: INFO: event-controller-6c77ddd949-2mr6m from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 22:41:02.341: INFO: 	Container event-controller ready: true, restart count 1
Jan 15 22:41:02.341: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 22:41:02.342: INFO: wavefront-proxy-5d455bcbc6-tjnrz from kube-system started at 2019-01-15 20:09:32 +0000 UTC (4 container statuses recorded)
Jan 15 22:41:02.342: INFO: 	Container heapster ready: true, restart count 0
Jan 15 22:41:02.342: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan 15 22:41:02.342: INFO: 	Container telegraf ready: true, restart count 0
Jan 15 22:41:02.342: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan 15 22:41:02.342: INFO: heapster-85647cf566-x9tdm from kube-system started at 2019-01-15 20:06:38 +0000 UTC (1 container statuses recorded)
Jan 15 22:41:02.342: INFO: 	Container heapster ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157a26c7fe7ba6f9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:41:03.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-54qtv" for this suite.
Jan 15 22:41:09.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:41:09.417: INFO: namespace: e2e-tests-sched-pred-54qtv, resource: bindings, ignored listing per whitelist
Jan 15 22:41:09.530: INFO: namespace e2e-tests-sched-pred-54qtv deletion completed in 6.149741039s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.449 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:41:09.531: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-54n7x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-54n7x
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 15 22:41:09.839: INFO: Found 0 stateful pods, waiting for 3
Jan 15 22:41:19.845: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:41:19.845: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:41:19.845: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 22:41:19.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-54n7x ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 22:41:20.168: INFO: stderr: ""
Jan 15 22:41:20.168: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 22:41:20.168: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 15 22:41:30.210: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 15 22:41:40.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-54n7x ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 22:41:40.487: INFO: stderr: ""
Jan 15 22:41:40.487: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 22:41:40.487: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 22:41:50.520: INFO: Waiting for StatefulSet e2e-tests-statefulset-54n7x/ss2 to complete update
Jan 15 22:41:50.520: INFO: Waiting for Pod e2e-tests-statefulset-54n7x/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 15 22:41:50.520: INFO: Waiting for Pod e2e-tests-statefulset-54n7x/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 15 22:42:00.528: INFO: Waiting for StatefulSet e2e-tests-statefulset-54n7x/ss2 to complete update
Jan 15 22:42:00.528: INFO: Waiting for Pod e2e-tests-statefulset-54n7x/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan 15 22:42:10.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-54n7x ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 22:42:10.741: INFO: stderr: ""
Jan 15 22:42:10.741: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 22:42:10.741: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 22:42:20.771: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 15 22:42:30.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-54n7x ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 22:42:30.992: INFO: stderr: ""
Jan 15 22:42:30.992: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 22:42:30.992: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 22:42:51.014: INFO: Deleting all statefulset in ns e2e-tests-statefulset-54n7x
Jan 15 22:42:51.016: INFO: Scaling statefulset ss2 to 0
Jan 15 22:43:21.032: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 22:43:21.035: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:43:21.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-54n7x" for this suite.
Jan 15 22:43:27.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:43:27.156: INFO: namespace: e2e-tests-statefulset-54n7x, resource: bindings, ignored listing per whitelist
Jan 15 22:43:27.188: INFO: namespace e2e-tests-statefulset-54n7x deletion completed in 6.137181709s

• [SLOW TEST:137.658 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:43:27.192: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-t6gd6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 15 22:43:31.944: INFO: Successfully updated pod "pod-update-activedeadlineseconds-f94bac3d-1916-11e9-993a-025056003018"
Jan 15 22:43:31.944: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-f94bac3d-1916-11e9-993a-025056003018" in namespace "e2e-tests-pods-t6gd6" to be "terminated due to deadline exceeded"
Jan 15 22:43:31.952: INFO: Pod "pod-update-activedeadlineseconds-f94bac3d-1916-11e9-993a-025056003018": Phase="Running", Reason="", readiness=true. Elapsed: 8.099249ms
Jan 15 22:43:33.956: INFO: Pod "pod-update-activedeadlineseconds-f94bac3d-1916-11e9-993a-025056003018": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.01189267s
Jan 15 22:43:33.956: INFO: Pod "pod-update-activedeadlineseconds-f94bac3d-1916-11e9-993a-025056003018" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:43:33.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-t6gd6" for this suite.
Jan 15 22:43:39.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:43:40.059: INFO: namespace: e2e-tests-pods-t6gd6, resource: bindings, ignored listing per whitelist
Jan 15 22:43:40.077: INFO: namespace e2e-tests-pods-t6gd6 deletion completed in 6.116624563s

• [SLOW TEST:12.884 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:43:40.079: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8djtq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 15 22:43:40.290: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-736916119 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:43:40.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8djtq" for this suite.
Jan 15 22:43:46.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:43:46.487: INFO: namespace: e2e-tests-kubectl-8djtq, resource: bindings, ignored listing per whitelist
Jan 15 22:43:46.527: INFO: namespace e2e-tests-kubectl-8djtq deletion completed in 6.131670535s

• [SLOW TEST:6.448 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:43:46.528: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-d6bfq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 15 22:43:46.802: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-d6bfq" to be "success or failure"
Jan 15 22:43:46.817: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 14.969779ms
Jan 15 22:43:48.823: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020794074s
Jan 15 22:43:50.829: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026061442s
STEP: Saw pod success
Jan 15 22:43:50.829: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 15 22:43:50.832: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 15 22:43:50.860: INFO: Waiting for pod pod-host-path-test to disappear
Jan 15 22:43:50.869: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:43:50.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-d6bfq" for this suite.
Jan 15 22:43:56.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:43:56.931: INFO: namespace: e2e-tests-hostpath-d6bfq, resource: bindings, ignored listing per whitelist
Jan 15 22:43:56.983: INFO: namespace e2e-tests-hostpath-d6bfq deletion completed in 6.109203753s

• [SLOW TEST:10.456 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:43:56.987: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-mfk6x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 15 22:44:01.234: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0b0e5b34-1917-11e9-993a-025056003018,GenerateName:,Namespace:e2e-tests-events-mfk6x,SelfLink:/api/v1/namespaces/e2e-tests-events-mfk6x/pods/send-events-0b0e5b34-1917-11e9-993a-025056003018,UID:0b107e06-1917-11e9-8273-005056af1926,ResourceVersion:17500,Generation:0,CreationTimestamp:2019-01-15 22:43:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 194327240,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4vvdg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4vvdg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-4vvdg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228bc3e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228bc400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:43:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:44:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:44:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:43:57 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.10.2,StartTime:2019-01-15 22:43:57 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-15 22:43:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://d62e0b2c8d8a681e446a7303f1a91178287f39a457ee88b58785b8154a568943}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 15 22:44:03.241: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 15 22:44:05.245: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:44:05.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-mfk6x" for this suite.
Jan 15 22:44:47.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:44:47.393: INFO: namespace: e2e-tests-events-mfk6x, resource: bindings, ignored listing per whitelist
Jan 15 22:44:47.437: INFO: namespace e2e-tests-events-mfk6x deletion completed in 42.174392907s

• [SLOW TEST:50.451 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:44:47.442: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-45bnb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 15 22:44:47.649: INFO: Waiting up to 5m0s for pod "pod-292016e8-1917-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-45bnb" to be "success or failure"
Jan 15 22:44:47.668: INFO: Pod "pod-292016e8-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 18.833716ms
Jan 15 22:44:49.673: INFO: Pod "pod-292016e8-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023899612s
Jan 15 22:44:51.677: INFO: Pod "pod-292016e8-1917-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027550176s
STEP: Saw pod success
Jan 15 22:44:51.677: INFO: Pod "pod-292016e8-1917-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:44:51.680: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-292016e8-1917-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:44:51.749: INFO: Waiting for pod pod-292016e8-1917-11e9-993a-025056003018 to disappear
Jan 15 22:44:51.758: INFO: Pod pod-292016e8-1917-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:44:51.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-45bnb" for this suite.
Jan 15 22:44:57.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:44:57.864: INFO: namespace: e2e-tests-emptydir-45bnb, resource: bindings, ignored listing per whitelist
Jan 15 22:44:57.911: INFO: namespace e2e-tests-emptydir-45bnb deletion completed in 6.137580221s

• [SLOW TEST:10.469 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:44:57.911: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-prv7f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2f5fe38a-1917-11e9-993a-025056003018
STEP: Creating secret with name s-test-opt-upd-2f5fe3ca-1917-11e9-993a-025056003018
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2f5fe38a-1917-11e9-993a-025056003018
STEP: Updating secret s-test-opt-upd-2f5fe3ca-1917-11e9-993a-025056003018
STEP: Creating secret with name s-test-opt-create-2f5fe586-1917-11e9-993a-025056003018
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:45:06.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-prv7f" for this suite.
Jan 15 22:45:28.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:45:28.619: INFO: namespace: e2e-tests-projected-prv7f, resource: bindings, ignored listing per whitelist
Jan 15 22:45:28.643: INFO: namespace e2e-tests-projected-prv7f deletion completed in 22.12858184s

• [SLOW TEST:30.733 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:45:28.651: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-qvjlx
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-41b08c1e-1917-11e9-993a-025056003018
STEP: Creating configMap with name cm-test-opt-upd-41b08dbd-1917-11e9-993a-025056003018
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-41b08c1e-1917-11e9-993a-025056003018
STEP: Updating configmap cm-test-opt-upd-41b08dbd-1917-11e9-993a-025056003018
STEP: Creating configMap with name cm-test-opt-create-41b08dd0-1917-11e9-993a-025056003018
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:45:35.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qvjlx" for this suite.
Jan 15 22:45:57.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:45:57.081: INFO: namespace: e2e-tests-configmap-qvjlx, resource: bindings, ignored listing per whitelist
Jan 15 22:45:57.130: INFO: namespace e2e-tests-configmap-qvjlx deletion completed in 22.110485123s

• [SLOW TEST:28.480 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:45:57.135: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d67rt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 15 22:45:57.339: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-736916119 proxy --unix-socket=/tmp/kubectl-proxy-unix635483402/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:45:57.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d67rt" for this suite.
Jan 15 22:46:03.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:46:03.507: INFO: namespace: e2e-tests-kubectl-d67rt, resource: bindings, ignored listing per whitelist
Jan 15 22:46:03.556: INFO: namespace e2e-tests-kubectl-d67rt deletion completed in 6.11948733s

• [SLOW TEST:6.421 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:46:03.559: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-msdw5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 22:46:03.830: INFO: Waiting up to 5m0s for pod "downward-api-5687c890-1917-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-msdw5" to be "success or failure"
Jan 15 22:46:03.839: INFO: Pod "downward-api-5687c890-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 8.60967ms
Jan 15 22:46:05.843: INFO: Pod "downward-api-5687c890-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012619829s
Jan 15 22:46:07.848: INFO: Pod "downward-api-5687c890-1917-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017801152s
STEP: Saw pod success
Jan 15 22:46:07.849: INFO: Pod "downward-api-5687c890-1917-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:46:07.854: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downward-api-5687c890-1917-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:46:07.879: INFO: Waiting for pod downward-api-5687c890-1917-11e9-993a-025056003018 to disappear
Jan 15 22:46:07.883: INFO: Pod downward-api-5687c890-1917-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:46:07.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-msdw5" for this suite.
Jan 15 22:46:13.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:46:14.005: INFO: namespace: e2e-tests-downward-api-msdw5, resource: bindings, ignored listing per whitelist
Jan 15 22:46:14.007: INFO: namespace e2e-tests-downward-api-msdw5 deletion completed in 6.118584967s

• [SLOW TEST:10.448 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:46:14.008: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-j8w8b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Jan 15 22:46:14.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-j8w8b'
Jan 15 22:46:15.199: INFO: stderr: ""
Jan 15 22:46:15.199: INFO: stdout: "pod/pause created\n"
Jan 15 22:46:15.200: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 15 22:46:15.200: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-j8w8b" to be "running and ready"
Jan 15 22:46:15.204: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.978244ms
Jan 15 22:46:17.208: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00837283s
Jan 15 22:46:19.212: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.012470092s
Jan 15 22:46:19.212: INFO: Pod "pause" satisfied condition "running and ready"
Jan 15 22:46:19.212: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 15 22:46:19.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-j8w8b'
Jan 15 22:46:19.344: INFO: stderr: ""
Jan 15 22:46:19.344: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 15 22:46:19.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pod pause -L testing-label --namespace=e2e-tests-kubectl-j8w8b'
Jan 15 22:46:19.462: INFO: stderr: ""
Jan 15 22:46:19.462: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 15 22:46:19.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 label pods pause testing-label- --namespace=e2e-tests-kubectl-j8w8b'
Jan 15 22:46:19.569: INFO: stderr: ""
Jan 15 22:46:19.569: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 15 22:46:19.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pod pause -L testing-label --namespace=e2e-tests-kubectl-j8w8b'
Jan 15 22:46:19.695: INFO: stderr: ""
Jan 15 22:46:19.695: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Jan 15 22:46:19.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j8w8b'
Jan 15 22:46:19.840: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 22:46:19.840: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 15 22:46:19.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-j8w8b'
Jan 15 22:46:19.957: INFO: stderr: "No resources found.\n"
Jan 15 22:46:19.957: INFO: stdout: ""
Jan 15 22:46:19.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -l name=pause --namespace=e2e-tests-kubectl-j8w8b -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 22:46:20.113: INFO: stderr: ""
Jan 15 22:46:20.113: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:46:20.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j8w8b" for this suite.
Jan 15 22:46:26.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:46:26.148: INFO: namespace: e2e-tests-kubectl-j8w8b, resource: bindings, ignored listing per whitelist
Jan 15 22:46:26.234: INFO: namespace e2e-tests-kubectl-j8w8b deletion completed in 6.115082901s

• [SLOW TEST:12.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:46:26.237: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2ktqr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:46:26.461: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6405c137-1917-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-2ktqr" to be "success or failure"
Jan 15 22:46:26.463: INFO: Pod "downwardapi-volume-6405c137-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.536749ms
Jan 15 22:46:28.467: INFO: Pod "downwardapi-volume-6405c137-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00670333s
Jan 15 22:46:30.472: INFO: Pod "downwardapi-volume-6405c137-1917-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011045816s
STEP: Saw pod success
Jan 15 22:46:30.472: INFO: Pod "downwardapi-volume-6405c137-1917-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:46:30.475: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-6405c137-1917-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:46:30.495: INFO: Waiting for pod downwardapi-volume-6405c137-1917-11e9-993a-025056003018 to disappear
Jan 15 22:46:30.500: INFO: Pod downwardapi-volume-6405c137-1917-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:46:30.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2ktqr" for this suite.
Jan 15 22:46:36.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:46:36.616: INFO: namespace: e2e-tests-downward-api-2ktqr, resource: bindings, ignored listing per whitelist
Jan 15 22:46:36.625: INFO: namespace e2e-tests-downward-api-2ktqr deletion completed in 6.121326173s

• [SLOW TEST:10.388 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:46:36.625: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-6z5cb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0115 22:46:46.849148      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 22:46:46.849: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:46:46.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6z5cb" for this suite.
Jan 15 22:46:52.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:46:52.898: INFO: namespace: e2e-tests-gc-6z5cb, resource: bindings, ignored listing per whitelist
Jan 15 22:46:52.959: INFO: namespace e2e-tests-gc-6z5cb deletion completed in 6.106494385s

• [SLOW TEST:16.334 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:46:52.959: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7gcql
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:46:53.162: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73ef55bb-1917-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-7gcql" to be "success or failure"
Jan 15 22:46:53.164: INFO: Pod "downwardapi-volume-73ef55bb-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.68672ms
Jan 15 22:46:55.174: INFO: Pod "downwardapi-volume-73ef55bb-1917-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012586688s
STEP: Saw pod success
Jan 15 22:46:55.174: INFO: Pod "downwardapi-volume-73ef55bb-1917-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:46:55.183: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-73ef55bb-1917-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:46:55.218: INFO: Waiting for pod downwardapi-volume-73ef55bb-1917-11e9-993a-025056003018 to disappear
Jan 15 22:46:55.229: INFO: Pod downwardapi-volume-73ef55bb-1917-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:46:55.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7gcql" for this suite.
Jan 15 22:47:01.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:47:01.335: INFO: namespace: e2e-tests-downward-api-7gcql, resource: bindings, ignored listing per whitelist
Jan 15 22:47:01.368: INFO: namespace e2e-tests-downward-api-7gcql deletion completed in 6.13455525s

• [SLOW TEST:8.408 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:47:01.368: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-pjb5s
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-78f96483-1917-11e9-993a-025056003018
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-78f96483-1917-11e9-993a-025056003018
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:48:10.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pjb5s" for this suite.
Jan 15 22:48:32.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:48:32.097: INFO: namespace: e2e-tests-configmap-pjb5s, resource: bindings, ignored listing per whitelist
Jan 15 22:48:32.143: INFO: namespace e2e-tests-configmap-pjb5s deletion completed in 22.134894013s

• [SLOW TEST:90.775 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:48:32.145: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-pqsrz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pqsrz
Jan 15 22:48:36.412: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pqsrz
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 22:48:36.417: INFO: Initial restart count of pod liveness-http is 0
Jan 15 22:48:54.458: INFO: Restart count of pod e2e-tests-container-probe-pqsrz/liveness-http is now 1 (18.040433094s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:48:54.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pqsrz" for this suite.
Jan 15 22:49:00.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:49:00.589: INFO: namespace: e2e-tests-container-probe-pqsrz, resource: bindings, ignored listing per whitelist
Jan 15 22:49:00.646: INFO: namespace e2e-tests-container-probe-pqsrz deletion completed in 6.157219408s

• [SLOW TEST:28.501 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:49:00.648: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-p4bdh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c00b24a9-1917-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:49:00.850: INFO: Waiting up to 5m0s for pod "pod-configmaps-c00baa99-1917-11e9-993a-025056003018" in namespace "e2e-tests-configmap-p4bdh" to be "success or failure"
Jan 15 22:49:00.856: INFO: Pod "pod-configmaps-c00baa99-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 5.222015ms
Jan 15 22:49:02.860: INFO: Pod "pod-configmaps-c00baa99-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009587824s
Jan 15 22:49:04.864: INFO: Pod "pod-configmaps-c00baa99-1917-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014043688s
STEP: Saw pod success
Jan 15 22:49:04.865: INFO: Pod "pod-configmaps-c00baa99-1917-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:49:04.868: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-c00baa99-1917-11e9-993a-025056003018 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:49:04.895: INFO: Waiting for pod pod-configmaps-c00baa99-1917-11e9-993a-025056003018 to disappear
Jan 15 22:49:04.901: INFO: Pod pod-configmaps-c00baa99-1917-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:49:04.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p4bdh" for this suite.
Jan 15 22:49:10.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:49:10.963: INFO: namespace: e2e-tests-configmap-p4bdh, resource: bindings, ignored listing per whitelist
Jan 15 22:49:11.032: INFO: namespace e2e-tests-configmap-p4bdh deletion completed in 6.126470971s

• [SLOW TEST:10.384 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:49:11.035: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-6frs5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0115 22:49:41.803485      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 22:49:41.803: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:49:41.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6frs5" for this suite.
Jan 15 22:49:47.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:49:47.865: INFO: namespace: e2e-tests-gc-6frs5, resource: bindings, ignored listing per whitelist
Jan 15 22:49:47.909: INFO: namespace e2e-tests-gc-6frs5 deletion completed in 6.102122504s

• [SLOW TEST:36.875 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:49:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-hn8tw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-hn8tw
I0115 22:49:48.121335      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-hn8tw, replica count: 1
I0115 22:49:49.172135      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 22:49:50.172404      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 22:49:51.172694      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 15 22:49:51.285: INFO: Created: latency-svc-qt8qm
Jan 15 22:49:51.297: INFO: Got endpoints: latency-svc-qt8qm [24.318355ms]
Jan 15 22:49:51.319: INFO: Created: latency-svc-hj4sr
Jan 15 22:49:51.319: INFO: Created: latency-svc-6njk9
Jan 15 22:49:51.324: INFO: Created: latency-svc-d265d
Jan 15 22:49:51.334: INFO: Got endpoints: latency-svc-6njk9 [35.343601ms]
Jan 15 22:49:51.334: INFO: Got endpoints: latency-svc-hj4sr [36.649797ms]
Jan 15 22:49:51.342: INFO: Got endpoints: latency-svc-d265d [43.678523ms]
Jan 15 22:49:51.347: INFO: Created: latency-svc-dk2cx
Jan 15 22:49:51.356: INFO: Created: latency-svc-sdcl4
Jan 15 22:49:51.361: INFO: Got endpoints: latency-svc-dk2cx [62.925928ms]
Jan 15 22:49:51.376: INFO: Got endpoints: latency-svc-sdcl4 [78.809805ms]
Jan 15 22:49:51.379: INFO: Created: latency-svc-dknft
Jan 15 22:49:51.379: INFO: Got endpoints: latency-svc-dknft [80.360766ms]
Jan 15 22:49:51.379: INFO: Created: latency-svc-85gjc
Jan 15 22:49:51.384: INFO: Got endpoints: latency-svc-85gjc [84.967583ms]
Jan 15 22:49:51.395: INFO: Created: latency-svc-29zkh
Jan 15 22:49:51.401: INFO: Created: latency-svc-gkvrl
Jan 15 22:49:51.403: INFO: Got endpoints: latency-svc-29zkh [103.135324ms]
Jan 15 22:49:51.417: INFO: Got endpoints: latency-svc-gkvrl [116.595032ms]
Jan 15 22:49:51.418: INFO: Created: latency-svc-f5wg7
Jan 15 22:49:51.420: INFO: Got endpoints: latency-svc-f5wg7 [119.055661ms]
Jan 15 22:49:51.426: INFO: Created: latency-svc-swjsb
Jan 15 22:49:51.431: INFO: Created: latency-svc-s4zhl
Jan 15 22:49:51.445: INFO: Created: latency-svc-9vjbv
Jan 15 22:49:51.448: INFO: Got endpoints: latency-svc-s4zhl [146.858852ms]
Jan 15 22:49:51.449: INFO: Got endpoints: latency-svc-swjsb [146.939225ms]
Jan 15 22:49:51.455: INFO: Got endpoints: latency-svc-9vjbv [152.705495ms]
Jan 15 22:49:51.459: INFO: Created: latency-svc-jq64v
Jan 15 22:49:51.469: INFO: Got endpoints: latency-svc-jq64v [167.301229ms]
Jan 15 22:49:51.473: INFO: Created: latency-svc-nw6mz
Jan 15 22:49:51.483: INFO: Got endpoints: latency-svc-nw6mz [181.065486ms]
Jan 15 22:49:51.486: INFO: Created: latency-svc-77gbd
Jan 15 22:49:51.488: INFO: Created: latency-svc-mt6fr
Jan 15 22:49:51.496: INFO: Got endpoints: latency-svc-77gbd [162.713513ms]
Jan 15 22:49:51.499: INFO: Got endpoints: latency-svc-mt6fr [164.738483ms]
Jan 15 22:49:51.507: INFO: Created: latency-svc-88m2p
Jan 15 22:49:51.515: INFO: Created: latency-svc-4r6pl
Jan 15 22:49:51.517: INFO: Got endpoints: latency-svc-88m2p [174.839158ms]
Jan 15 22:49:51.528: INFO: Created: latency-svc-z5j29
Jan 15 22:49:51.541: INFO: Created: latency-svc-fwpxc
Jan 15 22:49:51.553: INFO: Got endpoints: latency-svc-fwpxc [174.730195ms]
Jan 15 22:49:51.554: INFO: Got endpoints: latency-svc-4r6pl [192.779499ms]
Jan 15 22:49:51.554: INFO: Got endpoints: latency-svc-z5j29 [177.292072ms]
Jan 15 22:49:51.562: INFO: Created: latency-svc-qc8nm
Jan 15 22:49:51.567: INFO: Created: latency-svc-qqq28
Jan 15 22:49:51.570: INFO: Got endpoints: latency-svc-qc8nm [185.119771ms]
Jan 15 22:49:51.578: INFO: Created: latency-svc-4dxfm
Jan 15 22:49:51.579: INFO: Got endpoints: latency-svc-qqq28 [175.827874ms]
Jan 15 22:49:51.593: INFO: Got endpoints: latency-svc-4dxfm [176.656524ms]
Jan 15 22:49:51.629: INFO: Created: latency-svc-rk8d2
Jan 15 22:49:51.634: INFO: Got endpoints: latency-svc-rk8d2 [214.219946ms]
Jan 15 22:49:51.641: INFO: Created: latency-svc-227dp
Jan 15 22:49:51.650: INFO: Got endpoints: latency-svc-227dp [201.32488ms]
Jan 15 22:49:51.657: INFO: Created: latency-svc-hwj5f
Jan 15 22:49:51.668: INFO: Created: latency-svc-skdrs
Jan 15 22:49:51.672: INFO: Got endpoints: latency-svc-hwj5f [223.303099ms]
Jan 15 22:49:51.680: INFO: Got endpoints: latency-svc-skdrs [225.489071ms]
Jan 15 22:49:51.685: INFO: Created: latency-svc-xqbhd
Jan 15 22:49:51.687: INFO: Created: latency-svc-bhc26
Jan 15 22:49:51.707: INFO: Got endpoints: latency-svc-bhc26 [223.789899ms]
Jan 15 22:49:51.707: INFO: Got endpoints: latency-svc-xqbhd [238.854392ms]
Jan 15 22:49:51.715: INFO: Created: latency-svc-ftcch
Jan 15 22:49:51.719: INFO: Got endpoints: latency-svc-ftcch [222.334273ms]
Jan 15 22:49:51.726: INFO: Created: latency-svc-fj57f
Jan 15 22:49:51.729: INFO: Created: latency-svc-2mc7h
Jan 15 22:49:51.731: INFO: Got endpoints: latency-svc-fj57f [231.728276ms]
Jan 15 22:49:51.737: INFO: Got endpoints: latency-svc-2mc7h [220.556718ms]
Jan 15 22:49:51.751: INFO: Created: latency-svc-wtqq5
Jan 15 22:49:51.754: INFO: Got endpoints: latency-svc-wtqq5 [200.86983ms]
Jan 15 22:49:51.773: INFO: Created: latency-svc-xlt4l
Jan 15 22:49:51.774: INFO: Created: latency-svc-wwvdm
Jan 15 22:49:51.788: INFO: Created: latency-svc-vfqlf
Jan 15 22:49:51.789: INFO: Got endpoints: latency-svc-xlt4l [235.386147ms]
Jan 15 22:49:51.789: INFO: Got endpoints: latency-svc-wwvdm [235.335564ms]
Jan 15 22:49:51.797: INFO: Got endpoints: latency-svc-vfqlf [226.935522ms]
Jan 15 22:49:51.798: INFO: Created: latency-svc-klvkp
Jan 15 22:49:51.801: INFO: Got endpoints: latency-svc-klvkp [207.155955ms]
Jan 15 22:49:51.808: INFO: Created: latency-svc-bjv78
Jan 15 22:49:51.819: INFO: Got endpoints: latency-svc-bjv78 [240.126973ms]
Jan 15 22:49:51.832: INFO: Created: latency-svc-qhw8l
Jan 15 22:49:51.837: INFO: Created: latency-svc-ppt4x
Jan 15 22:49:51.841: INFO: Created: latency-svc-t8r44
Jan 15 22:49:51.844: INFO: Got endpoints: latency-svc-qhw8l [209.474458ms]
Jan 15 22:49:51.861: INFO: Created: latency-svc-qmpsb
Jan 15 22:49:51.866: INFO: Created: latency-svc-2knkl
Jan 15 22:49:51.873: INFO: Created: latency-svc-sqdp5
Jan 15 22:49:51.881: INFO: Created: latency-svc-dkkqd
Jan 15 22:49:51.897: INFO: Created: latency-svc-c7798
Jan 15 22:49:51.906: INFO: Created: latency-svc-ds8vv
Jan 15 22:49:51.906: INFO: Got endpoints: latency-svc-ppt4x [256.421234ms]
Jan 15 22:49:51.911: INFO: Created: latency-svc-lpt6s
Jan 15 22:49:51.924: INFO: Created: latency-svc-sfcl2
Jan 15 22:49:51.931: INFO: Created: latency-svc-bm6pj
Jan 15 22:49:51.934: INFO: Created: latency-svc-sgqc2
Jan 15 22:49:51.948: INFO: Got endpoints: latency-svc-t8r44 [275.656888ms]
Jan 15 22:49:51.966: INFO: Created: latency-svc-f4g55
Jan 15 22:49:51.969: INFO: Created: latency-svc-kd65x
Jan 15 22:49:51.974: INFO: Created: latency-svc-9bdw7
Jan 15 22:49:51.989: INFO: Created: latency-svc-64h5j
Jan 15 22:49:51.997: INFO: Got endpoints: latency-svc-qmpsb [316.192537ms]
Jan 15 22:49:52.008: INFO: Created: latency-svc-vcv29
Jan 15 22:49:52.020: INFO: Created: latency-svc-tct5c
Jan 15 22:49:52.038: INFO: Got endpoints: latency-svc-2knkl [331.229238ms]
Jan 15 22:49:52.045: INFO: Created: latency-svc-n7hdv
Jan 15 22:49:52.088: INFO: Got endpoints: latency-svc-sqdp5 [380.092402ms]
Jan 15 22:49:52.099: INFO: Created: latency-svc-t24mk
Jan 15 22:49:52.144: INFO: Got endpoints: latency-svc-dkkqd [425.550126ms]
Jan 15 22:49:52.162: INFO: Created: latency-svc-tghtz
Jan 15 22:49:52.193: INFO: Got endpoints: latency-svc-c7798 [461.944619ms]
Jan 15 22:49:52.212: INFO: Created: latency-svc-6dspg
Jan 15 22:49:52.241: INFO: Got endpoints: latency-svc-ds8vv [503.721956ms]
Jan 15 22:49:52.254: INFO: Created: latency-svc-dbbpv
Jan 15 22:49:52.292: INFO: Got endpoints: latency-svc-lpt6s [537.674579ms]
Jan 15 22:49:52.303: INFO: Created: latency-svc-mdwnz
Jan 15 22:49:52.341: INFO: Got endpoints: latency-svc-sfcl2 [552.335249ms]
Jan 15 22:49:52.368: INFO: Created: latency-svc-xc95l
Jan 15 22:49:52.388: INFO: Got endpoints: latency-svc-bm6pj [598.092998ms]
Jan 15 22:49:52.401: INFO: Created: latency-svc-qw2bv
Jan 15 22:49:52.439: INFO: Got endpoints: latency-svc-sgqc2 [642.011366ms]
Jan 15 22:49:52.453: INFO: Created: latency-svc-x8zl7
Jan 15 22:49:52.489: INFO: Got endpoints: latency-svc-f4g55 [688.784451ms]
Jan 15 22:49:52.502: INFO: Created: latency-svc-8kbzg
Jan 15 22:49:52.540: INFO: Got endpoints: latency-svc-kd65x [721.157584ms]
Jan 15 22:49:52.549: INFO: Created: latency-svc-hq8tq
Jan 15 22:49:52.587: INFO: Got endpoints: latency-svc-9bdw7 [743.427019ms]
Jan 15 22:49:52.597: INFO: Created: latency-svc-x6jm6
Jan 15 22:49:52.638: INFO: Got endpoints: latency-svc-64h5j [731.484893ms]
Jan 15 22:49:52.656: INFO: Created: latency-svc-bjfzr
Jan 15 22:49:52.691: INFO: Got endpoints: latency-svc-vcv29 [743.413685ms]
Jan 15 22:49:52.702: INFO: Created: latency-svc-mtmdr
Jan 15 22:49:52.741: INFO: Got endpoints: latency-svc-tct5c [744.610937ms]
Jan 15 22:49:52.753: INFO: Created: latency-svc-wqd6m
Jan 15 22:49:52.787: INFO: Got endpoints: latency-svc-n7hdv [748.900481ms]
Jan 15 22:49:52.802: INFO: Created: latency-svc-lcnt5
Jan 15 22:49:52.839: INFO: Got endpoints: latency-svc-t24mk [751.715327ms]
Jan 15 22:49:52.849: INFO: Created: latency-svc-hqpcl
Jan 15 22:49:52.888: INFO: Got endpoints: latency-svc-tghtz [741.166289ms]
Jan 15 22:49:52.908: INFO: Created: latency-svc-mm4g5
Jan 15 22:49:52.938: INFO: Got endpoints: latency-svc-6dspg [745.611247ms]
Jan 15 22:49:52.953: INFO: Created: latency-svc-xchb5
Jan 15 22:49:52.991: INFO: Got endpoints: latency-svc-dbbpv [748.016882ms]
Jan 15 22:49:53.004: INFO: Created: latency-svc-jd52s
Jan 15 22:49:53.041: INFO: Got endpoints: latency-svc-mdwnz [749.14398ms]
Jan 15 22:49:53.051: INFO: Created: latency-svc-v5jh8
Jan 15 22:49:53.089: INFO: Got endpoints: latency-svc-xc95l [747.342431ms]
Jan 15 22:49:53.102: INFO: Created: latency-svc-cclvq
Jan 15 22:49:53.138: INFO: Got endpoints: latency-svc-qw2bv [749.872839ms]
Jan 15 22:49:53.147: INFO: Created: latency-svc-bznxh
Jan 15 22:49:53.191: INFO: Got endpoints: latency-svc-x8zl7 [752.423051ms]
Jan 15 22:49:53.209: INFO: Created: latency-svc-z5hgf
Jan 15 22:49:53.238: INFO: Got endpoints: latency-svc-8kbzg [748.7879ms]
Jan 15 22:49:53.250: INFO: Created: latency-svc-98kxh
Jan 15 22:49:53.290: INFO: Got endpoints: latency-svc-hq8tq [749.51378ms]
Jan 15 22:49:53.309: INFO: Created: latency-svc-mxlb6
Jan 15 22:49:53.338: INFO: Got endpoints: latency-svc-x6jm6 [750.969434ms]
Jan 15 22:49:53.350: INFO: Created: latency-svc-rfk7s
Jan 15 22:49:53.390: INFO: Got endpoints: latency-svc-bjfzr [752.56231ms]
Jan 15 22:49:53.400: INFO: Created: latency-svc-rhmzb
Jan 15 22:49:53.438: INFO: Got endpoints: latency-svc-mtmdr [746.466259ms]
Jan 15 22:49:53.453: INFO: Created: latency-svc-gwsnf
Jan 15 22:49:53.488: INFO: Got endpoints: latency-svc-wqd6m [746.320166ms]
Jan 15 22:49:53.507: INFO: Created: latency-svc-z7kjm
Jan 15 22:49:53.540: INFO: Got endpoints: latency-svc-lcnt5 [752.78126ms]
Jan 15 22:49:53.555: INFO: Created: latency-svc-t7cm8
Jan 15 22:49:53.591: INFO: Got endpoints: latency-svc-hqpcl [751.285676ms]
Jan 15 22:49:53.601: INFO: Created: latency-svc-wlg67
Jan 15 22:49:53.643: INFO: Got endpoints: latency-svc-mm4g5 [755.257967ms]
Jan 15 22:49:53.654: INFO: Created: latency-svc-rp6ck
Jan 15 22:49:53.688: INFO: Got endpoints: latency-svc-xchb5 [749.126576ms]
Jan 15 22:49:53.699: INFO: Created: latency-svc-75b2f
Jan 15 22:49:53.740: INFO: Got endpoints: latency-svc-jd52s [749.234086ms]
Jan 15 22:49:53.748: INFO: Created: latency-svc-xjbs4
Jan 15 22:49:53.788: INFO: Got endpoints: latency-svc-v5jh8 [747.044574ms]
Jan 15 22:49:53.796: INFO: Created: latency-svc-g5t4m
Jan 15 22:49:53.839: INFO: Got endpoints: latency-svc-cclvq [750.109584ms]
Jan 15 22:49:53.849: INFO: Created: latency-svc-rdm7d
Jan 15 22:49:53.888: INFO: Got endpoints: latency-svc-bznxh [750.323302ms]
Jan 15 22:49:53.900: INFO: Created: latency-svc-799qm
Jan 15 22:49:53.938: INFO: Got endpoints: latency-svc-z5hgf [746.894986ms]
Jan 15 22:49:53.947: INFO: Created: latency-svc-zzc9q
Jan 15 22:49:53.992: INFO: Got endpoints: latency-svc-98kxh [753.440303ms]
Jan 15 22:49:54.003: INFO: Created: latency-svc-lpmsz
Jan 15 22:49:54.039: INFO: Got endpoints: latency-svc-mxlb6 [748.739933ms]
Jan 15 22:49:54.055: INFO: Created: latency-svc-hllj8
Jan 15 22:49:54.097: INFO: Got endpoints: latency-svc-rfk7s [758.774918ms]
Jan 15 22:49:54.106: INFO: Created: latency-svc-5ktqn
Jan 15 22:49:54.139: INFO: Got endpoints: latency-svc-rhmzb [748.183418ms]
Jan 15 22:49:54.149: INFO: Created: latency-svc-284w8
Jan 15 22:49:54.187: INFO: Got endpoints: latency-svc-gwsnf [749.281756ms]
Jan 15 22:49:54.198: INFO: Created: latency-svc-hnq67
Jan 15 22:49:54.241: INFO: Got endpoints: latency-svc-z7kjm [753.792426ms]
Jan 15 22:49:54.258: INFO: Created: latency-svc-66lz6
Jan 15 22:49:54.293: INFO: Got endpoints: latency-svc-t7cm8 [753.133944ms]
Jan 15 22:49:54.310: INFO: Created: latency-svc-zvpnb
Jan 15 22:49:54.339: INFO: Got endpoints: latency-svc-wlg67 [748.518893ms]
Jan 15 22:49:54.348: INFO: Created: latency-svc-lsw9w
Jan 15 22:49:54.390: INFO: Got endpoints: latency-svc-rp6ck [747.101384ms]
Jan 15 22:49:54.404: INFO: Created: latency-svc-cq8nb
Jan 15 22:49:54.439: INFO: Got endpoints: latency-svc-75b2f [751.074419ms]
Jan 15 22:49:54.449: INFO: Created: latency-svc-9cs58
Jan 15 22:49:54.489: INFO: Got endpoints: latency-svc-xjbs4 [748.61853ms]
Jan 15 22:49:54.498: INFO: Created: latency-svc-zmgfb
Jan 15 22:49:54.538: INFO: Got endpoints: latency-svc-g5t4m [749.212576ms]
Jan 15 22:49:54.548: INFO: Created: latency-svc-d4886
Jan 15 22:49:54.591: INFO: Got endpoints: latency-svc-rdm7d [751.093967ms]
Jan 15 22:49:54.601: INFO: Created: latency-svc-ws8z9
Jan 15 22:49:54.800: INFO: Got endpoints: latency-svc-799qm [912.120296ms]
Jan 15 22:49:54.829: INFO: Got endpoints: latency-svc-zzc9q [891.267951ms]
Jan 15 22:49:54.830: INFO: Got endpoints: latency-svc-hllj8 [790.900925ms]
Jan 15 22:49:54.830: INFO: Got endpoints: latency-svc-lpmsz [837.975037ms]
Jan 15 22:49:54.834: INFO: Created: latency-svc-h8tnk
Jan 15 22:49:54.846: INFO: Got endpoints: latency-svc-5ktqn [748.523461ms]
Jan 15 22:49:54.856: INFO: Created: latency-svc-vwrtk
Jan 15 22:49:54.891: INFO: Created: latency-svc-xrzsv
Jan 15 22:49:54.894: INFO: Got endpoints: latency-svc-284w8 [754.885528ms]
Jan 15 22:49:54.904: INFO: Created: latency-svc-h257g
Jan 15 22:49:54.910: INFO: Created: latency-svc-dgx5q
Jan 15 22:49:54.928: INFO: Created: latency-svc-wq5l9
Jan 15 22:49:54.939: INFO: Got endpoints: latency-svc-hnq67 [751.819276ms]
Jan 15 22:49:54.953: INFO: Created: latency-svc-9flqb
Jan 15 22:49:54.992: INFO: Got endpoints: latency-svc-66lz6 [750.595143ms]
Jan 15 22:49:55.024: INFO: Created: latency-svc-hrgdz
Jan 15 22:49:55.038: INFO: Got endpoints: latency-svc-zvpnb [744.879372ms]
Jan 15 22:49:55.049: INFO: Created: latency-svc-jckrr
Jan 15 22:49:55.090: INFO: Got endpoints: latency-svc-lsw9w [751.173118ms]
Jan 15 22:49:55.109: INFO: Created: latency-svc-8q5np
Jan 15 22:49:55.151: INFO: Got endpoints: latency-svc-cq8nb [760.396308ms]
Jan 15 22:49:55.163: INFO: Created: latency-svc-c4d42
Jan 15 22:49:55.200: INFO: Got endpoints: latency-svc-9cs58 [761.051478ms]
Jan 15 22:49:55.229: INFO: Created: latency-svc-cm9jx
Jan 15 22:49:55.241: INFO: Got endpoints: latency-svc-zmgfb [752.58937ms]
Jan 15 22:49:55.266: INFO: Created: latency-svc-5hjwc
Jan 15 22:49:55.288: INFO: Got endpoints: latency-svc-d4886 [750.698697ms]
Jan 15 22:49:55.321: INFO: Created: latency-svc-tjwbp
Jan 15 22:49:55.351: INFO: Got endpoints: latency-svc-ws8z9 [760.65145ms]
Jan 15 22:49:55.377: INFO: Created: latency-svc-k26rc
Jan 15 22:49:55.401: INFO: Got endpoints: latency-svc-h8tnk [600.322487ms]
Jan 15 22:49:55.439: INFO: Created: latency-svc-79wc8
Jan 15 22:49:55.461: INFO: Got endpoints: latency-svc-vwrtk [631.738143ms]
Jan 15 22:49:55.468: INFO: Created: latency-svc-jcqw7
Jan 15 22:49:55.530: INFO: Got endpoints: latency-svc-xrzsv [700.166297ms]
Jan 15 22:49:55.539: INFO: Got endpoints: latency-svc-h257g [709.08589ms]
Jan 15 22:49:55.558: INFO: Created: latency-svc-4m4f9
Jan 15 22:49:55.579: INFO: Created: latency-svc-k7p9h
Jan 15 22:49:55.613: INFO: Got endpoints: latency-svc-dgx5q [766.95871ms]
Jan 15 22:49:55.643: INFO: Created: latency-svc-92xp9
Jan 15 22:49:55.657: INFO: Got endpoints: latency-svc-wq5l9 [762.976751ms]
Jan 15 22:49:55.697: INFO: Got endpoints: latency-svc-9flqb [757.42805ms]
Jan 15 22:49:55.708: INFO: Created: latency-svc-gbfqv
Jan 15 22:49:55.728: INFO: Created: latency-svc-h9695
Jan 15 22:49:55.747: INFO: Got endpoints: latency-svc-hrgdz [754.432544ms]
Jan 15 22:49:55.780: INFO: Created: latency-svc-rthj8
Jan 15 22:49:55.794: INFO: Got endpoints: latency-svc-jckrr [755.41746ms]
Jan 15 22:49:55.812: INFO: Created: latency-svc-z97sk
Jan 15 22:49:55.846: INFO: Got endpoints: latency-svc-8q5np [755.580226ms]
Jan 15 22:49:55.855: INFO: Created: latency-svc-rs8pd
Jan 15 22:49:55.888: INFO: Got endpoints: latency-svc-c4d42 [737.059347ms]
Jan 15 22:49:55.904: INFO: Created: latency-svc-ffbnx
Jan 15 22:49:55.947: INFO: Got endpoints: latency-svc-cm9jx [747.279178ms]
Jan 15 22:49:55.972: INFO: Created: latency-svc-njzp2
Jan 15 22:49:55.988: INFO: Got endpoints: latency-svc-5hjwc [747.082293ms]
Jan 15 22:49:55.999: INFO: Created: latency-svc-4wfjk
Jan 15 22:49:56.038: INFO: Got endpoints: latency-svc-tjwbp [749.681332ms]
Jan 15 22:49:56.049: INFO: Created: latency-svc-89h5f
Jan 15 22:49:56.090: INFO: Got endpoints: latency-svc-k26rc [738.298861ms]
Jan 15 22:49:56.100: INFO: Created: latency-svc-wdllj
Jan 15 22:49:56.138: INFO: Got endpoints: latency-svc-79wc8 [737.566479ms]
Jan 15 22:49:56.146: INFO: Created: latency-svc-knh6h
Jan 15 22:49:56.189: INFO: Got endpoints: latency-svc-jcqw7 [727.684542ms]
Jan 15 22:49:56.202: INFO: Created: latency-svc-g826r
Jan 15 22:49:56.242: INFO: Got endpoints: latency-svc-4m4f9 [712.311777ms]
Jan 15 22:49:56.251: INFO: Created: latency-svc-2bjx6
Jan 15 22:49:56.289: INFO: Got endpoints: latency-svc-k7p9h [750.106737ms]
Jan 15 22:49:56.302: INFO: Created: latency-svc-6zq4h
Jan 15 22:49:56.341: INFO: Got endpoints: latency-svc-92xp9 [727.576743ms]
Jan 15 22:49:56.351: INFO: Created: latency-svc-88dkw
Jan 15 22:49:56.389: INFO: Got endpoints: latency-svc-gbfqv [732.533915ms]
Jan 15 22:49:56.403: INFO: Created: latency-svc-g5h7t
Jan 15 22:49:56.442: INFO: Got endpoints: latency-svc-h9695 [745.416364ms]
Jan 15 22:49:56.451: INFO: Created: latency-svc-cdd5n
Jan 15 22:49:56.497: INFO: Got endpoints: latency-svc-rthj8 [750.446619ms]
Jan 15 22:49:56.515: INFO: Created: latency-svc-6x2kb
Jan 15 22:49:56.539: INFO: Got endpoints: latency-svc-z97sk [745.567885ms]
Jan 15 22:49:56.552: INFO: Created: latency-svc-cwx7l
Jan 15 22:49:56.589: INFO: Got endpoints: latency-svc-rs8pd [742.563488ms]
Jan 15 22:49:56.606: INFO: Created: latency-svc-22sqp
Jan 15 22:49:56.641: INFO: Got endpoints: latency-svc-ffbnx [752.480119ms]
Jan 15 22:49:56.649: INFO: Created: latency-svc-lrsb6
Jan 15 22:49:56.691: INFO: Got endpoints: latency-svc-njzp2 [743.481571ms]
Jan 15 22:49:56.709: INFO: Created: latency-svc-fl7mj
Jan 15 22:49:56.740: INFO: Got endpoints: latency-svc-4wfjk [751.456003ms]
Jan 15 22:49:56.762: INFO: Created: latency-svc-njx85
Jan 15 22:49:56.788: INFO: Got endpoints: latency-svc-89h5f [749.634594ms]
Jan 15 22:49:56.803: INFO: Created: latency-svc-tvxf5
Jan 15 22:49:56.842: INFO: Got endpoints: latency-svc-wdllj [752.086783ms]
Jan 15 22:49:56.864: INFO: Created: latency-svc-g5trz
Jan 15 22:49:56.889: INFO: Got endpoints: latency-svc-knh6h [751.24937ms]
Jan 15 22:49:56.904: INFO: Created: latency-svc-fn78g
Jan 15 22:49:56.938: INFO: Got endpoints: latency-svc-g826r [748.835449ms]
Jan 15 22:49:56.947: INFO: Created: latency-svc-v2p84
Jan 15 22:49:56.992: INFO: Got endpoints: latency-svc-2bjx6 [750.011535ms]
Jan 15 22:49:57.000: INFO: Created: latency-svc-46cj4
Jan 15 22:49:57.038: INFO: Got endpoints: latency-svc-6zq4h [749.244985ms]
Jan 15 22:49:57.052: INFO: Created: latency-svc-7zbt9
Jan 15 22:49:57.089: INFO: Got endpoints: latency-svc-88dkw [747.987589ms]
Jan 15 22:49:57.098: INFO: Created: latency-svc-tjq7s
Jan 15 22:49:57.142: INFO: Got endpoints: latency-svc-g5h7t [752.472643ms]
Jan 15 22:49:57.151: INFO: Created: latency-svc-ltb9w
Jan 15 22:49:57.191: INFO: Got endpoints: latency-svc-cdd5n [749.281464ms]
Jan 15 22:49:57.200: INFO: Created: latency-svc-n8gt8
Jan 15 22:49:57.237: INFO: Got endpoints: latency-svc-6x2kb [740.221578ms]
Jan 15 22:49:57.248: INFO: Created: latency-svc-h2qrw
Jan 15 22:49:57.287: INFO: Got endpoints: latency-svc-cwx7l [747.908198ms]
Jan 15 22:49:57.302: INFO: Created: latency-svc-v7kf4
Jan 15 22:49:57.338: INFO: Got endpoints: latency-svc-22sqp [748.783718ms]
Jan 15 22:49:57.357: INFO: Created: latency-svc-xdfhr
Jan 15 22:49:57.389: INFO: Got endpoints: latency-svc-lrsb6 [748.218052ms]
Jan 15 22:49:57.404: INFO: Created: latency-svc-qp77t
Jan 15 22:49:57.441: INFO: Got endpoints: latency-svc-fl7mj [750.320503ms]
Jan 15 22:49:57.453: INFO: Created: latency-svc-99r5x
Jan 15 22:49:57.488: INFO: Got endpoints: latency-svc-njx85 [748.471966ms]
Jan 15 22:49:57.505: INFO: Created: latency-svc-znhqt
Jan 15 22:49:57.541: INFO: Got endpoints: latency-svc-tvxf5 [752.659329ms]
Jan 15 22:49:57.550: INFO: Created: latency-svc-t5z2l
Jan 15 22:49:57.594: INFO: Got endpoints: latency-svc-g5trz [751.667658ms]
Jan 15 22:49:57.610: INFO: Created: latency-svc-xmgkc
Jan 15 22:49:57.641: INFO: Got endpoints: latency-svc-fn78g [751.444958ms]
Jan 15 22:49:57.649: INFO: Created: latency-svc-gbk5d
Jan 15 22:49:57.690: INFO: Got endpoints: latency-svc-v2p84 [752.143556ms]
Jan 15 22:49:57.710: INFO: Created: latency-svc-vm9vc
Jan 15 22:49:57.745: INFO: Got endpoints: latency-svc-46cj4 [752.614338ms]
Jan 15 22:49:57.761: INFO: Created: latency-svc-p89pw
Jan 15 22:49:57.788: INFO: Got endpoints: latency-svc-7zbt9 [749.677208ms]
Jan 15 22:49:57.805: INFO: Created: latency-svc-rdjrh
Jan 15 22:49:57.838: INFO: Got endpoints: latency-svc-tjq7s [749.290476ms]
Jan 15 22:49:57.851: INFO: Created: latency-svc-n6zqb
Jan 15 22:49:57.893: INFO: Got endpoints: latency-svc-ltb9w [751.639696ms]
Jan 15 22:49:57.903: INFO: Created: latency-svc-vs2f6
Jan 15 22:49:57.938: INFO: Got endpoints: latency-svc-n8gt8 [746.461012ms]
Jan 15 22:49:57.952: INFO: Created: latency-svc-gpg6n
Jan 15 22:49:57.993: INFO: Got endpoints: latency-svc-h2qrw [755.055049ms]
Jan 15 22:49:58.017: INFO: Created: latency-svc-wlbq5
Jan 15 22:49:58.038: INFO: Got endpoints: latency-svc-v7kf4 [750.011611ms]
Jan 15 22:49:58.048: INFO: Created: latency-svc-gblpb
Jan 15 22:49:58.090: INFO: Got endpoints: latency-svc-xdfhr [751.7376ms]
Jan 15 22:49:58.102: INFO: Created: latency-svc-8n4fj
Jan 15 22:49:58.138: INFO: Got endpoints: latency-svc-qp77t [749.531612ms]
Jan 15 22:49:58.146: INFO: Created: latency-svc-2kbtn
Jan 15 22:49:58.190: INFO: Got endpoints: latency-svc-99r5x [748.371633ms]
Jan 15 22:49:58.204: INFO: Created: latency-svc-hhzbd
Jan 15 22:49:58.240: INFO: Got endpoints: latency-svc-znhqt [751.285946ms]
Jan 15 22:49:58.252: INFO: Created: latency-svc-nr4k8
Jan 15 22:49:58.290: INFO: Got endpoints: latency-svc-t5z2l [749.128771ms]
Jan 15 22:49:58.296: INFO: Created: latency-svc-x9tzs
Jan 15 22:49:58.338: INFO: Got endpoints: latency-svc-xmgkc [744.190921ms]
Jan 15 22:49:58.348: INFO: Created: latency-svc-p6pwb
Jan 15 22:49:58.389: INFO: Got endpoints: latency-svc-gbk5d [747.808935ms]
Jan 15 22:49:58.396: INFO: Created: latency-svc-26l5g
Jan 15 22:49:58.441: INFO: Got endpoints: latency-svc-vm9vc [751.058583ms]
Jan 15 22:49:58.470: INFO: Created: latency-svc-dvqtj
Jan 15 22:49:58.489: INFO: Got endpoints: latency-svc-p89pw [744.045756ms]
Jan 15 22:49:58.499: INFO: Created: latency-svc-hfnhc
Jan 15 22:49:58.538: INFO: Got endpoints: latency-svc-rdjrh [749.299981ms]
Jan 15 22:49:58.549: INFO: Created: latency-svc-xk5k6
Jan 15 22:49:58.590: INFO: Got endpoints: latency-svc-n6zqb [751.968325ms]
Jan 15 22:49:58.598: INFO: Created: latency-svc-xb88n
Jan 15 22:49:58.641: INFO: Got endpoints: latency-svc-vs2f6 [747.100791ms]
Jan 15 22:49:58.647: INFO: Created: latency-svc-tkh5c
Jan 15 22:49:58.689: INFO: Got endpoints: latency-svc-gpg6n [750.850251ms]
Jan 15 22:49:58.698: INFO: Created: latency-svc-cxb5b
Jan 15 22:49:58.741: INFO: Got endpoints: latency-svc-wlbq5 [748.479935ms]
Jan 15 22:49:58.757: INFO: Created: latency-svc-gkbnb
Jan 15 22:49:58.790: INFO: Got endpoints: latency-svc-gblpb [751.888732ms]
Jan 15 22:49:58.799: INFO: Created: latency-svc-nmxlw
Jan 15 22:49:58.843: INFO: Got endpoints: latency-svc-8n4fj [753.284338ms]
Jan 15 22:49:58.849: INFO: Created: latency-svc-l55kb
Jan 15 22:49:58.891: INFO: Got endpoints: latency-svc-2kbtn [752.027966ms]
Jan 15 22:49:58.903: INFO: Created: latency-svc-dct9w
Jan 15 22:49:58.940: INFO: Got endpoints: latency-svc-hhzbd [749.968627ms]
Jan 15 22:49:58.951: INFO: Created: latency-svc-k547d
Jan 15 22:49:58.992: INFO: Got endpoints: latency-svc-nr4k8 [752.480458ms]
Jan 15 22:49:59.024: INFO: Created: latency-svc-4jvvs
Jan 15 22:49:59.052: INFO: Got endpoints: latency-svc-x9tzs [761.588999ms]
Jan 15 22:49:59.065: INFO: Created: latency-svc-g6sns
Jan 15 22:49:59.088: INFO: Got endpoints: latency-svc-p6pwb [750.523125ms]
Jan 15 22:49:59.102: INFO: Created: latency-svc-nvlj5
Jan 15 22:49:59.140: INFO: Got endpoints: latency-svc-26l5g [750.884863ms]
Jan 15 22:49:59.189: INFO: Got endpoints: latency-svc-dvqtj [748.010513ms]
Jan 15 22:49:59.245: INFO: Got endpoints: latency-svc-hfnhc [755.718731ms]
Jan 15 22:49:59.288: INFO: Got endpoints: latency-svc-xk5k6 [750.475306ms]
Jan 15 22:49:59.340: INFO: Got endpoints: latency-svc-xb88n [749.674243ms]
Jan 15 22:49:59.390: INFO: Got endpoints: latency-svc-tkh5c [749.374717ms]
Jan 15 22:49:59.439: INFO: Got endpoints: latency-svc-cxb5b [749.6237ms]
Jan 15 22:49:59.493: INFO: Got endpoints: latency-svc-gkbnb [751.515475ms]
Jan 15 22:49:59.538: INFO: Got endpoints: latency-svc-nmxlw [747.876088ms]
Jan 15 22:49:59.591: INFO: Got endpoints: latency-svc-l55kb [747.522275ms]
Jan 15 22:49:59.640: INFO: Got endpoints: latency-svc-dct9w [749.350407ms]
Jan 15 22:49:59.691: INFO: Got endpoints: latency-svc-k547d [751.126022ms]
Jan 15 22:49:59.737: INFO: Got endpoints: latency-svc-4jvvs [745.052676ms]
Jan 15 22:49:59.792: INFO: Got endpoints: latency-svc-g6sns [739.864828ms]
Jan 15 22:49:59.839: INFO: Got endpoints: latency-svc-nvlj5 [750.59656ms]
Jan 15 22:49:59.840: INFO: Latencies: [35.343601ms 36.649797ms 43.678523ms 62.925928ms 78.809805ms 80.360766ms 84.967583ms 103.135324ms 116.595032ms 119.055661ms 146.858852ms 146.939225ms 152.705495ms 162.713513ms 164.738483ms 167.301229ms 174.730195ms 174.839158ms 175.827874ms 176.656524ms 177.292072ms 181.065486ms 185.119771ms 192.779499ms 200.86983ms 201.32488ms 207.155955ms 209.474458ms 214.219946ms 220.556718ms 222.334273ms 223.303099ms 223.789899ms 225.489071ms 226.935522ms 231.728276ms 235.335564ms 235.386147ms 238.854392ms 240.126973ms 256.421234ms 275.656888ms 316.192537ms 331.229238ms 380.092402ms 425.550126ms 461.944619ms 503.721956ms 537.674579ms 552.335249ms 598.092998ms 600.322487ms 631.738143ms 642.011366ms 688.784451ms 700.166297ms 709.08589ms 712.311777ms 721.157584ms 727.576743ms 727.684542ms 731.484893ms 732.533915ms 737.059347ms 737.566479ms 738.298861ms 739.864828ms 740.221578ms 741.166289ms 742.563488ms 743.413685ms 743.427019ms 743.481571ms 744.045756ms 744.190921ms 744.610937ms 744.879372ms 745.052676ms 745.416364ms 745.567885ms 745.611247ms 746.320166ms 746.461012ms 746.466259ms 746.894986ms 747.044574ms 747.082293ms 747.100791ms 747.101384ms 747.279178ms 747.342431ms 747.522275ms 747.808935ms 747.876088ms 747.908198ms 747.987589ms 748.010513ms 748.016882ms 748.183418ms 748.218052ms 748.371633ms 748.471966ms 748.479935ms 748.518893ms 748.523461ms 748.61853ms 748.739933ms 748.783718ms 748.7879ms 748.835449ms 748.900481ms 749.126576ms 749.128771ms 749.14398ms 749.212576ms 749.234086ms 749.244985ms 749.281464ms 749.281756ms 749.290476ms 749.299981ms 749.350407ms 749.374717ms 749.51378ms 749.531612ms 749.6237ms 749.634594ms 749.674243ms 749.677208ms 749.681332ms 749.872839ms 749.968627ms 750.011535ms 750.011611ms 750.106737ms 750.109584ms 750.320503ms 750.323302ms 750.446619ms 750.475306ms 750.523125ms 750.595143ms 750.59656ms 750.698697ms 750.850251ms 750.884863ms 750.969434ms 751.058583ms 751.074419ms 751.093967ms 751.126022ms 751.173118ms 751.24937ms 751.285676ms 751.285946ms 751.444958ms 751.456003ms 751.515475ms 751.639696ms 751.667658ms 751.715327ms 751.7376ms 751.819276ms 751.888732ms 751.968325ms 752.027966ms 752.086783ms 752.143556ms 752.423051ms 752.472643ms 752.480119ms 752.480458ms 752.56231ms 752.58937ms 752.614338ms 752.659329ms 752.78126ms 753.133944ms 753.284338ms 753.440303ms 753.792426ms 754.432544ms 754.885528ms 755.055049ms 755.257967ms 755.41746ms 755.580226ms 755.718731ms 757.42805ms 758.774918ms 760.396308ms 760.65145ms 761.051478ms 761.588999ms 762.976751ms 766.95871ms 790.900925ms 837.975037ms 891.267951ms 912.120296ms]
Jan 15 22:49:59.840: INFO: 50 %ile: 748.371633ms
Jan 15 22:49:59.840: INFO: 90 %ile: 753.792426ms
Jan 15 22:49:59.840: INFO: 99 %ile: 891.267951ms
Jan 15 22:49:59.840: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:49:59.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-hn8tw" for this suite.
Jan 15 22:50:09.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:50:09.983: INFO: namespace: e2e-tests-svc-latency-hn8tw, resource: bindings, ignored listing per whitelist
Jan 15 22:50:10.009: INFO: namespace e2e-tests-svc-latency-hn8tw deletion completed in 10.160517663s

• [SLOW TEST:22.096 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:50:10.010: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l55s8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Jan 15 22:50:10.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-l55s8'
Jan 15 22:50:10.843: INFO: stderr: ""
Jan 15 22:50:10.843: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 15 22:50:11.849: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:50:11.849: INFO: Found 0 / 1
Jan 15 22:50:12.850: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:50:12.850: INFO: Found 1 / 1
Jan 15 22:50:12.850: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 22:50:12.855: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 22:50:12.855: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 15 22:50:12.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 logs redis-master-bcjsj redis-master --namespace=e2e-tests-kubectl-l55s8'
Jan 15 22:50:12.995: INFO: stderr: ""
Jan 15 22:50:12.995: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 22:50:12.135 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 22:50:12.135 # Server started, Redis version 3.2.12\n1:M 15 Jan 22:50:12.137 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 22:50:12.143 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 15 22:50:12.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 log redis-master-bcjsj redis-master --namespace=e2e-tests-kubectl-l55s8 --tail=1'
Jan 15 22:50:13.130: INFO: stderr: ""
Jan 15 22:50:13.130: INFO: stdout: "1:M 15 Jan 22:50:12.143 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 15 22:50:13.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 log redis-master-bcjsj redis-master --namespace=e2e-tests-kubectl-l55s8 --limit-bytes=1'
Jan 15 22:50:13.272: INFO: stderr: ""
Jan 15 22:50:13.272: INFO: stdout: " "
STEP: exposing timestamps
Jan 15 22:50:13.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 log redis-master-bcjsj redis-master --namespace=e2e-tests-kubectl-l55s8 --tail=1 --timestamps'
Jan 15 22:50:13.393: INFO: stderr: ""
Jan 15 22:50:13.393: INFO: stdout: "2019-01-15T22:50:12.143675319Z 1:M 15 Jan 22:50:12.143 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 15 22:50:15.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 log redis-master-bcjsj redis-master --namespace=e2e-tests-kubectl-l55s8 --since=1s'
Jan 15 22:50:16.063: INFO: stderr: ""
Jan 15 22:50:16.063: INFO: stdout: ""
Jan 15 22:50:16.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 log redis-master-bcjsj redis-master --namespace=e2e-tests-kubectl-l55s8 --since=24h'
Jan 15 22:50:16.212: INFO: stderr: ""
Jan 15 22:50:16.212: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 15 Jan 22:50:12.135 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 15 Jan 22:50:12.135 # Server started, Redis version 3.2.12\n1:M 15 Jan 22:50:12.137 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 15 Jan 22:50:12.143 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Jan 15 22:50:16.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l55s8'
Jan 15 22:50:16.311: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 22:50:16.311: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 15 22:50:16.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-l55s8'
Jan 15 22:50:16.424: INFO: stderr: "No resources found.\n"
Jan 15 22:50:16.424: INFO: stdout: ""
Jan 15 22:50:16.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -l name=nginx --namespace=e2e-tests-kubectl-l55s8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 22:50:16.557: INFO: stderr: ""
Jan 15 22:50:16.557: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:50:16.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l55s8" for this suite.
Jan 15 22:50:22.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:50:22.658: INFO: namespace: e2e-tests-kubectl-l55s8, resource: bindings, ignored listing per whitelist
Jan 15 22:50:22.669: INFO: namespace e2e-tests-kubectl-l55s8 deletion completed in 6.107468674s

• [SLOW TEST:12.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:50:22.671: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-kzbjj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-kzbjj/secret-test-f0ef466d-1917-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 22:50:22.881: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0f013b6-1917-11e9-993a-025056003018" in namespace "e2e-tests-secrets-kzbjj" to be "success or failure"
Jan 15 22:50:22.888: INFO: Pod "pod-configmaps-f0f013b6-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 6.321866ms
Jan 15 22:50:24.892: INFO: Pod "pod-configmaps-f0f013b6-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010507508s
Jan 15 22:50:26.896: INFO: Pod "pod-configmaps-f0f013b6-1917-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014805891s
STEP: Saw pod success
Jan 15 22:50:26.896: INFO: Pod "pod-configmaps-f0f013b6-1917-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:50:26.900: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-f0f013b6-1917-11e9-993a-025056003018 container env-test: <nil>
STEP: delete the pod
Jan 15 22:50:26.935: INFO: Waiting for pod pod-configmaps-f0f013b6-1917-11e9-993a-025056003018 to disappear
Jan 15 22:50:26.950: INFO: Pod pod-configmaps-f0f013b6-1917-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:50:26.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kzbjj" for this suite.
Jan 15 22:50:32.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:50:33.061: INFO: namespace: e2e-tests-secrets-kzbjj, resource: bindings, ignored listing per whitelist
Jan 15 22:50:33.067: INFO: namespace e2e-tests-secrets-kzbjj deletion completed in 6.113925512s

• [SLOW TEST:10.397 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:50:33.069: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6qfpl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 15 22:50:33.289: INFO: Waiting up to 5m0s for pod "client-containers-f723e250-1917-11e9-993a-025056003018" in namespace "e2e-tests-containers-6qfpl" to be "success or failure"
Jan 15 22:50:33.301: INFO: Pod "client-containers-f723e250-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 11.42897ms
Jan 15 22:50:35.306: INFO: Pod "client-containers-f723e250-1917-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017206833s
Jan 15 22:50:37.311: INFO: Pod "client-containers-f723e250-1917-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021852091s
STEP: Saw pod success
Jan 15 22:50:37.311: INFO: Pod "client-containers-f723e250-1917-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:50:37.315: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod client-containers-f723e250-1917-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:50:37.351: INFO: Waiting for pod client-containers-f723e250-1917-11e9-993a-025056003018 to disappear
Jan 15 22:50:37.385: INFO: Pod client-containers-f723e250-1917-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:50:37.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6qfpl" for this suite.
Jan 15 22:50:43.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:50:43.473: INFO: namespace: e2e-tests-containers-6qfpl, resource: bindings, ignored listing per whitelist
Jan 15 22:50:43.496: INFO: namespace e2e-tests-containers-6qfpl deletion completed in 6.106691012s

• [SLOW TEST:10.427 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:50:43.498: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-v26ht
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-v26ht
Jan 15 22:50:45.709: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-v26ht
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 22:50:45.712: INFO: Initial restart count of pod liveness-http is 0
Jan 15 22:51:01.746: INFO: Restart count of pod e2e-tests-container-probe-v26ht/liveness-http is now 1 (16.033790529s elapsed)
Jan 15 22:51:21.785: INFO: Restart count of pod e2e-tests-container-probe-v26ht/liveness-http is now 2 (36.072593462s elapsed)
Jan 15 22:51:41.823: INFO: Restart count of pod e2e-tests-container-probe-v26ht/liveness-http is now 3 (56.111181473s elapsed)
Jan 15 22:52:01.868: INFO: Restart count of pod e2e-tests-container-probe-v26ht/liveness-http is now 4 (1m16.156071548s elapsed)
Jan 15 22:53:04.012: INFO: Restart count of pod e2e-tests-container-probe-v26ht/liveness-http is now 5 (2m18.300043496s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:53:04.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-v26ht" for this suite.
Jan 15 22:53:10.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:53:10.079: INFO: namespace: e2e-tests-container-probe-v26ht, resource: bindings, ignored listing per whitelist
Jan 15 22:53:10.153: INFO: namespace e2e-tests-container-probe-v26ht deletion completed in 6.113153128s

• [SLOW TEST:146.656 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:53:10.155: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fwl7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 15 22:53:10.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 cluster-info'
Jan 15 22:53:10.481: INFO: stderr: ""
Jan 15 22:53:10.481: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mmonitoring-influxdb\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:53:10.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fwl7s" for this suite.
Jan 15 22:53:16.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:53:16.530: INFO: namespace: e2e-tests-kubectl-fwl7s, resource: bindings, ignored listing per whitelist
Jan 15 22:53:16.589: INFO: namespace e2e-tests-kubectl-fwl7s deletion completed in 6.104359926s

• [SLOW TEST:6.434 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:53:16.589: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-p4mdm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 15 22:53:16.790: INFO: Waiting up to 5m0s for pod "var-expansion-589875ad-1918-11e9-993a-025056003018" in namespace "e2e-tests-var-expansion-p4mdm" to be "success or failure"
Jan 15 22:53:16.812: INFO: Pod "var-expansion-589875ad-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 21.328002ms
Jan 15 22:53:18.815: INFO: Pod "var-expansion-589875ad-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024729232s
STEP: Saw pod success
Jan 15 22:53:18.815: INFO: Pod "var-expansion-589875ad-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:53:18.818: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod var-expansion-589875ad-1918-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:53:18.842: INFO: Waiting for pod var-expansion-589875ad-1918-11e9-993a-025056003018 to disappear
Jan 15 22:53:18.845: INFO: Pod var-expansion-589875ad-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:53:18.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-p4mdm" for this suite.
Jan 15 22:53:24.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:53:24.956: INFO: namespace: e2e-tests-var-expansion-p4mdm, resource: bindings, ignored listing per whitelist
Jan 15 22:53:24.979: INFO: namespace e2e-tests-var-expansion-p4mdm deletion completed in 6.123273991s

• [SLOW TEST:8.390 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:53:24.980: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mlx4k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-5d99e571-1918-11e9-993a-025056003018
STEP: Creating secret with name secret-projected-all-test-volume-5d99e561-1918-11e9-993a-025056003018
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 15 22:53:25.204: INFO: Waiting up to 5m0s for pod "projected-volume-5d99e532-1918-11e9-993a-025056003018" in namespace "e2e-tests-projected-mlx4k" to be "success or failure"
Jan 15 22:53:25.207: INFO: Pod "projected-volume-5d99e532-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.516454ms
Jan 15 22:53:27.211: INFO: Pod "projected-volume-5d99e532-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006438216s
Jan 15 22:53:29.215: INFO: Pod "projected-volume-5d99e532-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010368147s
STEP: Saw pod success
Jan 15 22:53:29.215: INFO: Pod "projected-volume-5d99e532-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:53:29.218: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod projected-volume-5d99e532-1918-11e9-993a-025056003018 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 15 22:53:29.241: INFO: Waiting for pod projected-volume-5d99e532-1918-11e9-993a-025056003018 to disappear
Jan 15 22:53:29.243: INFO: Pod projected-volume-5d99e532-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:53:29.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mlx4k" for this suite.
Jan 15 22:53:35.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:53:35.277: INFO: namespace: e2e-tests-projected-mlx4k, resource: bindings, ignored listing per whitelist
Jan 15 22:53:35.363: INFO: namespace e2e-tests-projected-mlx4k deletion completed in 6.115742529s

• [SLOW TEST:10.383 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:53:35.365: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-4xnmm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-9prb
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 22:53:35.582: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9prb" in namespace "e2e-tests-subpath-4xnmm" to be "success or failure"
Jan 15 22:53:35.593: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.278273ms
Jan 15 22:53:37.598: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016236965s
Jan 15 22:53:39.602: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020446123s
Jan 15 22:53:41.606: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 6.024077137s
Jan 15 22:53:43.611: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 8.029641221s
Jan 15 22:53:45.616: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 10.033877284s
Jan 15 22:53:47.619: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 12.037678981s
Jan 15 22:53:49.624: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 14.042416131s
Jan 15 22:53:51.628: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 16.046607782s
Jan 15 22:53:53.633: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 18.051774475s
Jan 15 22:53:55.638: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 20.056189188s
Jan 15 22:53:57.641: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 22.059677447s
Jan 15 22:53:59.645: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Running", Reason="", readiness=false. Elapsed: 24.063764091s
Jan 15 22:54:01.650: INFO: Pod "pod-subpath-test-configmap-9prb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.06791632s
STEP: Saw pod success
Jan 15 22:54:01.650: INFO: Pod "pod-subpath-test-configmap-9prb" satisfied condition "success or failure"
Jan 15 22:54:01.652: INFO: Trying to get logs from node b660f798-38a0-4e83-a501-5381799304ec pod pod-subpath-test-configmap-9prb container test-container-subpath-configmap-9prb: <nil>
STEP: delete the pod
Jan 15 22:54:01.689: INFO: Waiting for pod pod-subpath-test-configmap-9prb to disappear
Jan 15 22:54:01.692: INFO: Pod pod-subpath-test-configmap-9prb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9prb
Jan 15 22:54:01.692: INFO: Deleting pod "pod-subpath-test-configmap-9prb" in namespace "e2e-tests-subpath-4xnmm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:54:01.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4xnmm" for this suite.
Jan 15 22:54:07.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:54:07.736: INFO: namespace: e2e-tests-subpath-4xnmm, resource: bindings, ignored listing per whitelist
Jan 15 22:54:07.815: INFO: namespace e2e-tests-subpath-4xnmm deletion completed in 6.115375394s

• [SLOW TEST:32.450 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:54:07.819: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wxh7p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 15 22:54:08.022: INFO: Waiting up to 5m0s for pod "pod-7722148f-1918-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-wxh7p" to be "success or failure"
Jan 15 22:54:08.027: INFO: Pod "pod-7722148f-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.968974ms
Jan 15 22:54:10.033: INFO: Pod "pod-7722148f-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010288869s
Jan 15 22:54:12.037: INFO: Pod "pod-7722148f-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014864934s
STEP: Saw pod success
Jan 15 22:54:12.057: INFO: Pod "pod-7722148f-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:54:12.061: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-7722148f-1918-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:54:12.088: INFO: Waiting for pod pod-7722148f-1918-11e9-993a-025056003018 to disappear
Jan 15 22:54:12.094: INFO: Pod pod-7722148f-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:54:12.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wxh7p" for this suite.
Jan 15 22:54:18.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:54:18.183: INFO: namespace: e2e-tests-emptydir-wxh7p, resource: bindings, ignored listing per whitelist
Jan 15 22:54:18.223: INFO: namespace e2e-tests-emptydir-wxh7p deletion completed in 6.122117592s

• [SLOW TEST:10.405 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:54:18.225: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-sh878
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-sh878
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sh878 to expose endpoints map[]
Jan 15 22:54:18.439: INFO: Get endpoints failed (6.745396ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 15 22:54:19.443: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sh878 exposes endpoints map[] (1.010177562s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-sh878
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sh878 to expose endpoints map[pod1:[100]]
Jan 15 22:54:22.500: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sh878 exposes endpoints map[pod1:[100]] (3.047733088s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-sh878
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sh878 to expose endpoints map[pod1:[100] pod2:[101]]
Jan 15 22:54:25.548: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sh878 exposes endpoints map[pod1:[100] pod2:[101]] (3.041471031s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-sh878
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sh878 to expose endpoints map[pod2:[101]]
Jan 15 22:54:25.576: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sh878 exposes endpoints map[pod2:[101]] (19.785988ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-sh878
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sh878 to expose endpoints map[]
Jan 15 22:54:26.596: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sh878 exposes endpoints map[] (1.011801388s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:54:26.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-sh878" for this suite.
Jan 15 22:54:48.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:54:48.677: INFO: namespace: e2e-tests-services-sh878, resource: bindings, ignored listing per whitelist
Jan 15 22:54:48.723: INFO: namespace e2e-tests-services-sh878 deletion completed in 22.097427379s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.498 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:54:48.726: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9fshd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:54:48.919: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f82d48a-1918-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-9fshd" to be "success or failure"
Jan 15 22:54:48.929: INFO: Pod "downwardapi-volume-8f82d48a-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 9.825549ms
Jan 15 22:54:50.933: INFO: Pod "downwardapi-volume-8f82d48a-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013613065s
STEP: Saw pod success
Jan 15 22:54:50.933: INFO: Pod "downwardapi-volume-8f82d48a-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:54:50.936: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-8f82d48a-1918-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:54:50.961: INFO: Waiting for pod downwardapi-volume-8f82d48a-1918-11e9-993a-025056003018 to disappear
Jan 15 22:54:50.969: INFO: Pod downwardapi-volume-8f82d48a-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:54:50.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9fshd" for this suite.
Jan 15 22:54:56.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:54:57.058: INFO: namespace: e2e-tests-downward-api-9fshd, resource: bindings, ignored listing per whitelist
Jan 15 22:54:57.082: INFO: namespace e2e-tests-downward-api-9fshd deletion completed in 6.109690887s

• [SLOW TEST:8.357 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:54:57.084: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xh9zt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:54:57.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-947d0907-1918-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-xh9zt" to be "success or failure"
Jan 15 22:54:57.290: INFO: Pod "downwardapi-volume-947d0907-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 17.408456ms
Jan 15 22:54:59.294: INFO: Pod "downwardapi-volume-947d0907-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021190672s
Jan 15 22:55:01.298: INFO: Pod "downwardapi-volume-947d0907-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025723435s
STEP: Saw pod success
Jan 15 22:55:01.299: INFO: Pod "downwardapi-volume-947d0907-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:55:01.303: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-947d0907-1918-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:55:01.330: INFO: Waiting for pod downwardapi-volume-947d0907-1918-11e9-993a-025056003018 to disappear
Jan 15 22:55:01.333: INFO: Pod downwardapi-volume-947d0907-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:55:01.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xh9zt" for this suite.
Jan 15 22:55:07.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:55:07.404: INFO: namespace: e2e-tests-downward-api-xh9zt, resource: bindings, ignored listing per whitelist
Jan 15 22:55:07.449: INFO: namespace e2e-tests-downward-api-xh9zt deletion completed in 6.112385809s

• [SLOW TEST:10.365 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:55:07.449: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-p9k9h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 15 22:55:07.658: INFO: Waiting up to 5m0s for pod "pod-9aae0268-1918-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-p9k9h" to be "success or failure"
Jan 15 22:55:07.672: INFO: Pod "pod-9aae0268-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 13.833784ms
Jan 15 22:55:09.676: INFO: Pod "pod-9aae0268-1918-11e9-993a-025056003018": Phase="Running", Reason="", readiness=true. Elapsed: 2.018158036s
Jan 15 22:55:11.681: INFO: Pod "pod-9aae0268-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022757311s
STEP: Saw pod success
Jan 15 22:55:11.681: INFO: Pod "pod-9aae0268-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:55:11.684: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-9aae0268-1918-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:55:11.712: INFO: Waiting for pod pod-9aae0268-1918-11e9-993a-025056003018 to disappear
Jan 15 22:55:11.717: INFO: Pod pod-9aae0268-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:55:11.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p9k9h" for this suite.
Jan 15 22:55:17.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:55:17.786: INFO: namespace: e2e-tests-emptydir-p9k9h, resource: bindings, ignored listing per whitelist
Jan 15 22:55:17.818: INFO: namespace e2e-tests-emptydir-p9k9h deletion completed in 6.095937691s

• [SLOW TEST:10.369 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:55:17.821: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-jf22f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 22:55:18.012: INFO: (0) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.581742ms)
Jan 15 22:55:18.016: INFO: (1) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.193349ms)
Jan 15 22:55:18.020: INFO: (2) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.752008ms)
Jan 15 22:55:18.023: INFO: (3) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.341601ms)
Jan 15 22:55:18.031: INFO: (4) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.260505ms)
Jan 15 22:55:18.037: INFO: (5) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.209352ms)
Jan 15 22:55:18.040: INFO: (6) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.432452ms)
Jan 15 22:55:18.045: INFO: (7) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.550082ms)
Jan 15 22:55:18.055: INFO: (8) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.029736ms)
Jan 15 22:55:18.059: INFO: (9) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.373352ms)
Jan 15 22:55:18.062: INFO: (10) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.083219ms)
Jan 15 22:55:18.065: INFO: (11) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.745021ms)
Jan 15 22:55:18.069: INFO: (12) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.442364ms)
Jan 15 22:55:18.072: INFO: (13) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.178949ms)
Jan 15 22:55:18.075: INFO: (14) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.296759ms)
Jan 15 22:55:18.078: INFO: (15) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.969271ms)
Jan 15 22:55:18.082: INFO: (16) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.557243ms)
Jan 15 22:55:18.085: INFO: (17) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.850194ms)
Jan 15 22:55:18.088: INFO: (18) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.116101ms)
Jan 15 22:55:18.092: INFO: (19) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.217146ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:55:18.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jf22f" for this suite.
Jan 15 22:55:24.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:55:24.143: INFO: namespace: e2e-tests-proxy-jf22f, resource: bindings, ignored listing per whitelist
Jan 15 22:55:24.194: INFO: namespace e2e-tests-proxy-jf22f deletion completed in 6.099205448s

• [SLOW TEST:6.374 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:55:24.195: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jf9nh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a4af12ad-1918-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:55:24.445: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018" in namespace "e2e-tests-projected-jf9nh" to be "success or failure"
Jan 15 22:55:24.460: INFO: Pod "pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 15.180161ms
Jan 15 22:55:26.465: INFO: Pod "pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019537862s
Jan 15 22:55:28.469: INFO: Pod "pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023823741s
STEP: Saw pod success
Jan 15 22:55:28.469: INFO: Pod "pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:55:28.473: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:55:28.504: INFO: Waiting for pod pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018 to disappear
Jan 15 22:55:28.508: INFO: Pod pod-projected-configmaps-a4afbd76-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:55:28.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jf9nh" for this suite.
Jan 15 22:55:34.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:55:34.615: INFO: namespace: e2e-tests-projected-jf9nh, resource: bindings, ignored listing per whitelist
Jan 15 22:55:34.622: INFO: namespace e2e-tests-projected-jf9nh deletion completed in 6.109625775s

• [SLOW TEST:10.427 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:55:34.624: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8gsxg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 22:55:36.866: INFO: Waiting up to 5m0s for pod "client-envvars-ac165f02-1918-11e9-993a-025056003018" in namespace "e2e-tests-pods-8gsxg" to be "success or failure"
Jan 15 22:55:36.886: INFO: Pod "client-envvars-ac165f02-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 19.965023ms
Jan 15 22:55:38.890: INFO: Pod "client-envvars-ac165f02-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023389729s
STEP: Saw pod success
Jan 15 22:55:38.890: INFO: Pod "client-envvars-ac165f02-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:55:38.893: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod client-envvars-ac165f02-1918-11e9-993a-025056003018 container env3cont: <nil>
STEP: delete the pod
Jan 15 22:55:38.919: INFO: Waiting for pod client-envvars-ac165f02-1918-11e9-993a-025056003018 to disappear
Jan 15 22:55:38.922: INFO: Pod client-envvars-ac165f02-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:55:38.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8gsxg" for this suite.
Jan 15 22:56:28.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:56:28.989: INFO: namespace: e2e-tests-pods-8gsxg, resource: bindings, ignored listing per whitelist
Jan 15 22:56:29.017: INFO: namespace e2e-tests-pods-8gsxg deletion completed in 50.091978118s

• [SLOW TEST:54.394 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:56:29.019: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-cp8jx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 15 22:56:29.250: INFO: Waiting up to 5m0s for pod "client-containers-cb4f2c50-1918-11e9-993a-025056003018" in namespace "e2e-tests-containers-cp8jx" to be "success or failure"
Jan 15 22:56:29.254: INFO: Pod "client-containers-cb4f2c50-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035226ms
Jan 15 22:56:31.258: INFO: Pod "client-containers-cb4f2c50-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008016966s
Jan 15 22:56:33.263: INFO: Pod "client-containers-cb4f2c50-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012653888s
STEP: Saw pod success
Jan 15 22:56:33.263: INFO: Pod "client-containers-cb4f2c50-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:56:33.266: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod client-containers-cb4f2c50-1918-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 22:56:33.287: INFO: Waiting for pod client-containers-cb4f2c50-1918-11e9-993a-025056003018 to disappear
Jan 15 22:56:33.294: INFO: Pod client-containers-cb4f2c50-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:56:33.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-cp8jx" for this suite.
Jan 15 22:56:39.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:56:39.405: INFO: namespace: e2e-tests-containers-cp8jx, resource: bindings, ignored listing per whitelist
Jan 15 22:56:39.419: INFO: namespace e2e-tests-containers-cp8jx deletion completed in 6.120952004s

• [SLOW TEST:10.400 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:56:39.420: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jscfg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 22:56:44.161: INFO: Successfully updated pod "annotationupdated17f5a42-1918-11e9-993a-025056003018"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:56:46.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jscfg" for this suite.
Jan 15 22:57:08.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:57:08.291: INFO: namespace: e2e-tests-projected-jscfg, resource: bindings, ignored listing per whitelist
Jan 15 22:57:08.316: INFO: namespace e2e-tests-projected-jscfg deletion completed in 22.127071125s

• [SLOW TEST:28.897 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:57:08.319: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-8qkh5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 22:57:08.527: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 15 22:57:13.531: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 22:57:13.531: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 15 22:57:15.534: INFO: Creating deployment "test-rollover-deployment"
Jan 15 22:57:15.545: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 15 22:57:17.556: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 15 22:57:17.562: INFO: Ensure that both replica sets have 1 created replica
Jan 15 22:57:17.567: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 15 22:57:17.574: INFO: Updating deployment test-rollover-deployment
Jan 15 22:57:17.574: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 15 22:57:19.588: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 15 22:57:19.595: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 15 22:57:19.602: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:57:19.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189837, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:57:21.609: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:57:21.609: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189837, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:57:23.608: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:57:23.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:57:25.610: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:57:25.610: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:57:27.608: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:57:27.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:57:29.609: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:57:29.609: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:57:31.608: INFO: all replica sets need to contain the pod-template-hash label
Jan 15 22:57:31.609: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189842, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683189835, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 22:57:33.608: INFO: 
Jan 15 22:57:33.608: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 22:57:33.616: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-8qkh5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8qkh5/deployments/test-rollover-deployment,UID:e6e7b069-1918-11e9-8273-005056af1926,ResourceVersion:21057,Generation:2,CreationTimestamp:2019-01-15 22:57:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-15 22:57:15 +0000 UTC 2019-01-15 22:57:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-15 22:57:32 +0000 UTC 2019-01-15 22:57:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 15 22:57:33.620: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-8qkh5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8qkh5/replicasets/test-rollover-deployment-5b76ff8c4,UID:e81ec324-1918-11e9-8273-005056af1926,ResourceVersion:21048,Generation:2,CreationTimestamp:2019-01-15 22:57:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e6e7b069-1918-11e9-8273-005056af1926 0xc4230068f7 0xc4230068f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 22:57:33.620: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 15 22:57:33.620: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-8qkh5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8qkh5/replicasets/test-rollover-controller,UID:e2b84b2b-1918-11e9-8273-005056af1926,ResourceVersion:21056,Generation:2,CreationTimestamp:2019-01-15 22:57:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e6e7b069-1918-11e9-8273-005056af1926 0xc42300682e 0xc42300682f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 22:57:33.620: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-8qkh5,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8qkh5/replicasets/test-rollover-deployment-6975f4fb87,UID:e6eae679-1918-11e9-8273-005056af1926,ResourceVersion:21014,Generation:2,CreationTimestamp:2019-01-15 22:57:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment e6e7b069-1918-11e9-8273-005056af1926 0xc423006a27 0xc423006a28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 22:57:33.624: INFO: Pod "test-rollover-deployment-5b76ff8c4-xqmnh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-xqmnh,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-8qkh5,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8qkh5/pods/test-rollover-deployment-5b76ff8c4-xqmnh,UID:e82514fb-1918-11e9-8273-005056af1926,ResourceVersion:21031,Generation:0,CreationTimestamp:2019-01-15 22:57:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 e81ec324-1918-11e9-8273-005056af1926 0xc422b106d0 0xc422b106d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9t4q4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9t4q4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9t4q4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:b660f798-38a0-4e83-a501-5381799304ec,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422b10730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422b10750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:57:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:57:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:57:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 22:57:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.9.4,StartTime:2019-01-15 22:57:17 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-15 22:57:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://18928b60a9f192a97539806aaa192162fc2b06abf37968bfa25a64125ae45efd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:57:33.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8qkh5" for this suite.
Jan 15 22:57:39.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:57:39.673: INFO: namespace: e2e-tests-deployment-8qkh5, resource: bindings, ignored listing per whitelist
Jan 15 22:57:39.734: INFO: namespace e2e-tests-deployment-8qkh5 deletion completed in 6.106426409s

• [SLOW TEST:31.415 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:57:39.735: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j7qtm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:57:39.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5705607-1918-11e9-993a-025056003018" in namespace "e2e-tests-projected-j7qtm" to be "success or failure"
Jan 15 22:57:39.935: INFO: Pod "downwardapi-volume-f5705607-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 5.8431ms
Jan 15 22:57:41.939: INFO: Pod "downwardapi-volume-f5705607-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009459342s
Jan 15 22:57:43.942: INFO: Pod "downwardapi-volume-f5705607-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013247625s
STEP: Saw pod success
Jan 15 22:57:43.942: INFO: Pod "downwardapi-volume-f5705607-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:57:43.945: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-f5705607-1918-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:57:43.966: INFO: Waiting for pod downwardapi-volume-f5705607-1918-11e9-993a-025056003018 to disappear
Jan 15 22:57:43.970: INFO: Pod downwardapi-volume-f5705607-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:57:43.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j7qtm" for this suite.
Jan 15 22:57:49.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:57:50.018: INFO: namespace: e2e-tests-projected-j7qtm, resource: bindings, ignored listing per whitelist
Jan 15 22:57:50.086: INFO: namespace e2e-tests-projected-j7qtm deletion completed in 6.111767378s

• [SLOW TEST:10.352 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:57:50.088: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d8snv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 22:57:50.294: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018" in namespace "e2e-tests-projected-d8snv" to be "success or failure"
Jan 15 22:57:50.299: INFO: Pod "downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52018ms
Jan 15 22:57:52.303: INFO: Pod "downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00913821s
Jan 15 22:57:54.307: INFO: Pod "downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012616899s
STEP: Saw pod success
Jan 15 22:57:54.307: INFO: Pod "downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:57:54.310: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 22:57:54.330: INFO: Waiting for pod downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018 to disappear
Jan 15 22:57:54.334: INFO: Pod downwardapi-volume-fb9e5b2c-1918-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:57:54.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d8snv" for this suite.
Jan 15 22:58:00.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:58:00.419: INFO: namespace: e2e-tests-projected-d8snv, resource: bindings, ignored listing per whitelist
Jan 15 22:58:00.438: INFO: namespace e2e-tests-projected-d8snv deletion completed in 6.100608281s

• [SLOW TEST:10.351 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:58:00.443: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nrq9j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-nrq9j/configmap-test-01cac6c0-1919-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:58:00.665: INFO: Waiting up to 5m0s for pod "pod-configmaps-01cc231b-1919-11e9-993a-025056003018" in namespace "e2e-tests-configmap-nrq9j" to be "success or failure"
Jan 15 22:58:00.687: INFO: Pod "pod-configmaps-01cc231b-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 22.16185ms
Jan 15 22:58:02.691: INFO: Pod "pod-configmaps-01cc231b-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026066522s
Jan 15 22:58:04.696: INFO: Pod "pod-configmaps-01cc231b-1919-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031077745s
STEP: Saw pod success
Jan 15 22:58:04.696: INFO: Pod "pod-configmaps-01cc231b-1919-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:58:04.705: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-01cc231b-1919-11e9-993a-025056003018 container env-test: <nil>
STEP: delete the pod
Jan 15 22:58:04.765: INFO: Waiting for pod pod-configmaps-01cc231b-1919-11e9-993a-025056003018 to disappear
Jan 15 22:58:04.770: INFO: Pod pod-configmaps-01cc231b-1919-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:58:04.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nrq9j" for this suite.
Jan 15 22:58:10.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:58:10.857: INFO: namespace: e2e-tests-configmap-nrq9j, resource: bindings, ignored listing per whitelist
Jan 15 22:58:10.899: INFO: namespace e2e-tests-configmap-nrq9j deletion completed in 6.122739124s

• [SLOW TEST:10.456 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:58:10.899: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-xr7nx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 15 22:58:11.116: INFO: Waiting up to 5m0s for pod "var-expansion-0806f6f7-1919-11e9-993a-025056003018" in namespace "e2e-tests-var-expansion-xr7nx" to be "success or failure"
Jan 15 22:58:11.134: INFO: Pod "var-expansion-0806f6f7-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 17.896398ms
Jan 15 22:58:13.139: INFO: Pod "var-expansion-0806f6f7-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022140802s
Jan 15 22:58:15.143: INFO: Pod "var-expansion-0806f6f7-1919-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026621233s
STEP: Saw pod success
Jan 15 22:58:15.144: INFO: Pod "var-expansion-0806f6f7-1919-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:58:15.146: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod var-expansion-0806f6f7-1919-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:58:15.170: INFO: Waiting for pod var-expansion-0806f6f7-1919-11e9-993a-025056003018 to disappear
Jan 15 22:58:15.173: INFO: Pod var-expansion-0806f6f7-1919-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:58:15.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-xr7nx" for this suite.
Jan 15 22:58:21.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:58:21.207: INFO: namespace: e2e-tests-var-expansion-xr7nx, resource: bindings, ignored listing per whitelist
Jan 15 22:58:21.300: INFO: namespace e2e-tests-var-expansion-xr7nx deletion completed in 6.123794335s

• [SLOW TEST:10.401 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:58:21.304: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kt4w7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 22:58:21.509: INFO: Waiting up to 5m0s for pod "downward-api-0e38dbf1-1919-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-kt4w7" to be "success or failure"
Jan 15 22:58:21.513: INFO: Pod "downward-api-0e38dbf1-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 3.943735ms
Jan 15 22:58:23.517: INFO: Pod "downward-api-0e38dbf1-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0074409s
Jan 15 22:58:25.522: INFO: Pod "downward-api-0e38dbf1-1919-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012654348s
STEP: Saw pod success
Jan 15 22:58:25.522: INFO: Pod "downward-api-0e38dbf1-1919-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:58:25.525: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downward-api-0e38dbf1-1919-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 22:58:25.553: INFO: Waiting for pod downward-api-0e38dbf1-1919-11e9-993a-025056003018 to disappear
Jan 15 22:58:25.560: INFO: Pod downward-api-0e38dbf1-1919-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:58:25.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kt4w7" for this suite.
Jan 15 22:58:31.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:58:31.663: INFO: namespace: e2e-tests-downward-api-kt4w7, resource: bindings, ignored listing per whitelist
Jan 15 22:58:31.690: INFO: namespace e2e-tests-downward-api-kt4w7 deletion completed in 6.125016006s

• [SLOW TEST:10.386 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:58:31.692: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-57blg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-146d8f1c-1919-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 22:58:31.927: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-146e8c3d-1919-11e9-993a-025056003018" in namespace "e2e-tests-projected-57blg" to be "success or failure"
Jan 15 22:58:31.932: INFO: Pod "pod-projected-secrets-146e8c3d-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 5.249833ms
Jan 15 22:58:33.935: INFO: Pod "pod-projected-secrets-146e8c3d-1919-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008812141s
STEP: Saw pod success
Jan 15 22:58:33.936: INFO: Pod "pod-projected-secrets-146e8c3d-1919-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:58:33.940: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-secrets-146e8c3d-1919-11e9-993a-025056003018 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 22:58:33.963: INFO: Waiting for pod pod-projected-secrets-146e8c3d-1919-11e9-993a-025056003018 to disappear
Jan 15 22:58:33.966: INFO: Pod pod-projected-secrets-146e8c3d-1919-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:58:33.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-57blg" for this suite.
Jan 15 22:58:39.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:58:40.014: INFO: namespace: e2e-tests-projected-57blg, resource: bindings, ignored listing per whitelist
Jan 15 22:58:40.096: INFO: namespace e2e-tests-projected-57blg deletion completed in 6.124043075s

• [SLOW TEST:8.404 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:58:40.098: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vqqt9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-19754663-1919-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 22:58:40.370: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018" in namespace "e2e-tests-projected-vqqt9" to be "success or failure"
Jan 15 22:58:40.380: INFO: Pod "pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 10.517489ms
Jan 15 22:58:42.385: INFO: Pod "pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01514977s
Jan 15 22:58:44.389: INFO: Pod "pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019650597s
STEP: Saw pod success
Jan 15 22:58:44.390: INFO: Pod "pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 22:58:44.393: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 22:58:44.418: INFO: Waiting for pod pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018 to disappear
Jan 15 22:58:44.430: INFO: Pod pod-projected-configmaps-19762ea1-1919-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 22:58:44.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vqqt9" for this suite.
Jan 15 22:58:50.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 22:58:50.522: INFO: namespace: e2e-tests-projected-vqqt9, resource: bindings, ignored listing per whitelist
Jan 15 22:58:50.533: INFO: namespace e2e-tests-projected-vqqt9 deletion completed in 6.099028973s

• [SLOW TEST:10.436 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 22:58:50.534: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-ftz5g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-ftz5g
Jan 15 22:58:54.775: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-ftz5g
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 22:58:54.779: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:02:55.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-ftz5g" for this suite.
Jan 15 23:03:01.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:03:01.445: INFO: namespace: e2e-tests-container-probe-ftz5g, resource: bindings, ignored listing per whitelist
Jan 15 23:03:01.529: INFO: namespace e2e-tests-container-probe-ftz5g deletion completed in 6.1217169s

• [SLOW TEST:250.996 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:03:01.533: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-9z7jw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 23:03:01.746: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:03:05.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-9z7jw" for this suite.
Jan 15 23:03:11.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:03:11.777: INFO: namespace: e2e-tests-init-container-9z7jw, resource: bindings, ignored listing per whitelist
Jan 15 23:03:11.870: INFO: namespace e2e-tests-init-container-9z7jw deletion completed in 6.129385593s

• [SLOW TEST:10.337 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:03:11.871: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g8dcp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 15 23:03:12.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:13.070: INFO: stderr: ""
Jan 15 23:03:13.070: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 23:03:13.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:13.185: INFO: stderr: ""
Jan 15 23:03:13.185: INFO: stdout: "update-demo-nautilus-69k2j update-demo-nautilus-t2z59 "
Jan 15 23:03:13.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-69k2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:13.284: INFO: stderr: ""
Jan 15 23:03:13.284: INFO: stdout: ""
Jan 15 23:03:13.284: INFO: update-demo-nautilus-69k2j is created but not running
Jan 15 23:03:18.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:18.382: INFO: stderr: ""
Jan 15 23:03:18.382: INFO: stdout: "update-demo-nautilus-69k2j update-demo-nautilus-t2z59 "
Jan 15 23:03:18.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-69k2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:18.475: INFO: stderr: ""
Jan 15 23:03:18.475: INFO: stdout: ""
Jan 15 23:03:18.475: INFO: update-demo-nautilus-69k2j is created but not running
Jan 15 23:03:23.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:23.601: INFO: stderr: ""
Jan 15 23:03:23.601: INFO: stdout: "update-demo-nautilus-69k2j update-demo-nautilus-t2z59 "
Jan 15 23:03:23.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-69k2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:23.714: INFO: stderr: ""
Jan 15 23:03:23.714: INFO: stdout: "true"
Jan 15 23:03:23.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-69k2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:23.838: INFO: stderr: ""
Jan 15 23:03:23.838: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:03:23.838: INFO: validating pod update-demo-nautilus-69k2j
Jan 15 23:03:23.846: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:03:23.846: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:03:23.846: INFO: update-demo-nautilus-69k2j is verified up and running
Jan 15 23:03:23.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:23.977: INFO: stderr: ""
Jan 15 23:03:23.977: INFO: stdout: "true"
Jan 15 23:03:23.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:24.113: INFO: stderr: ""
Jan 15 23:03:24.114: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:03:24.114: INFO: validating pod update-demo-nautilus-t2z59
Jan 15 23:03:24.119: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:03:24.119: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:03:24.119: INFO: update-demo-nautilus-t2z59 is verified up and running
STEP: scaling down the replication controller
Jan 15 23:03:24.121: INFO: scanned /root for discovery docs: <nil>
Jan 15 23:03:24.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:25.286: INFO: stderr: ""
Jan 15 23:03:25.286: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 23:03:25.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:25.396: INFO: stderr: ""
Jan 15 23:03:25.396: INFO: stdout: "update-demo-nautilus-69k2j update-demo-nautilus-t2z59 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 15 23:03:30.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:30.498: INFO: stderr: ""
Jan 15 23:03:30.498: INFO: stdout: "update-demo-nautilus-t2z59 "
Jan 15 23:03:30.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:30.618: INFO: stderr: ""
Jan 15 23:03:30.618: INFO: stdout: "true"
Jan 15 23:03:30.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:30.711: INFO: stderr: ""
Jan 15 23:03:30.711: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:03:30.711: INFO: validating pod update-demo-nautilus-t2z59
Jan 15 23:03:30.714: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:03:30.714: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:03:30.714: INFO: update-demo-nautilus-t2z59 is verified up and running
STEP: scaling up the replication controller
Jan 15 23:03:30.716: INFO: scanned /root for discovery docs: <nil>
Jan 15 23:03:30.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:31.860: INFO: stderr: ""
Jan 15 23:03:31.861: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 23:03:31.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:31.965: INFO: stderr: ""
Jan 15 23:03:31.965: INFO: stdout: "update-demo-nautilus-t2z59 update-demo-nautilus-znxxn "
Jan 15 23:03:31.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:32.108: INFO: stderr: ""
Jan 15 23:03:32.108: INFO: stdout: "true"
Jan 15 23:03:32.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:32.266: INFO: stderr: ""
Jan 15 23:03:32.266: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:03:32.266: INFO: validating pod update-demo-nautilus-t2z59
Jan 15 23:03:32.273: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:03:32.273: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:03:32.273: INFO: update-demo-nautilus-t2z59 is verified up and running
Jan 15 23:03:32.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-znxxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:32.374: INFO: stderr: ""
Jan 15 23:03:32.374: INFO: stdout: ""
Jan 15 23:03:32.374: INFO: update-demo-nautilus-znxxn is created but not running
Jan 15 23:03:37.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:37.491: INFO: stderr: ""
Jan 15 23:03:37.491: INFO: stdout: "update-demo-nautilus-t2z59 update-demo-nautilus-znxxn "
Jan 15 23:03:37.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:37.612: INFO: stderr: ""
Jan 15 23:03:37.612: INFO: stdout: "true"
Jan 15 23:03:37.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-t2z59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:37.719: INFO: stderr: ""
Jan 15 23:03:37.719: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:03:37.719: INFO: validating pod update-demo-nautilus-t2z59
Jan 15 23:03:37.723: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:03:37.723: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:03:37.723: INFO: update-demo-nautilus-t2z59 is verified up and running
Jan 15 23:03:37.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-znxxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:37.829: INFO: stderr: ""
Jan 15 23:03:37.829: INFO: stdout: "true"
Jan 15 23:03:37.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-znxxn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:37.929: INFO: stderr: ""
Jan 15 23:03:37.929: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:03:37.929: INFO: validating pod update-demo-nautilus-znxxn
Jan 15 23:03:37.935: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:03:37.935: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:03:37.935: INFO: update-demo-nautilus-znxxn is verified up and running
STEP: using delete to clean up resources
Jan 15 23:03:37.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:38.057: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:03:38.057: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 15 23:03:38.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-g8dcp'
Jan 15 23:03:38.178: INFO: stderr: "No resources found.\n"
Jan 15 23:03:38.178: INFO: stdout: ""
Jan 15 23:03:38.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -l name=update-demo --namespace=e2e-tests-kubectl-g8dcp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 23:03:38.294: INFO: stderr: ""
Jan 15 23:03:38.295: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:03:38.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g8dcp" for this suite.
Jan 15 23:03:44.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:03:44.409: INFO: namespace: e2e-tests-kubectl-g8dcp, resource: bindings, ignored listing per whitelist
Jan 15 23:03:44.411: INFO: namespace e2e-tests-kubectl-g8dcp deletion completed in 6.111135028s

• [SLOW TEST:32.541 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:03:44.418: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kk9f5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 15 23:03:44.635: INFO: Waiting up to 5m0s for pod "pod-ced20522-1919-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-kk9f5" to be "success or failure"
Jan 15 23:03:44.647: INFO: Pod "pod-ced20522-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 11.353837ms
Jan 15 23:03:46.651: INFO: Pod "pod-ced20522-1919-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016023883s
Jan 15 23:03:48.655: INFO: Pod "pod-ced20522-1919-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02021808s
STEP: Saw pod success
Jan 15 23:03:48.656: INFO: Pod "pod-ced20522-1919-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:03:48.659: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-ced20522-1919-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 23:03:48.694: INFO: Waiting for pod pod-ced20522-1919-11e9-993a-025056003018 to disappear
Jan 15 23:03:48.698: INFO: Pod pod-ced20522-1919-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:03:48.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kk9f5" for this suite.
Jan 15 23:03:54.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:03:54.737: INFO: namespace: e2e-tests-emptydir-kk9f5, resource: bindings, ignored listing per whitelist
Jan 15 23:03:54.819: INFO: namespace e2e-tests-emptydir-kk9f5 deletion completed in 6.115232865s

• [SLOW TEST:10.401 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:03:54.821: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rnbhv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d50a5b81-1919-11e9-993a-025056003018
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d50a5b81-1919-11e9-993a-025056003018
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:04:01.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rnbhv" for this suite.
Jan 15 23:04:23.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:04:23.286: INFO: namespace: e2e-tests-projected-rnbhv, resource: bindings, ignored listing per whitelist
Jan 15 23:04:23.317: INFO: namespace e2e-tests-projected-rnbhv deletion completed in 22.143459131s

• [SLOW TEST:28.496 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:04:23.317: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-j7fp5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 15 23:04:23.520: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 15 23:04:23.528: INFO: Waiting for terminating namespaces to be deleted...
Jan 15 23:04:23.530: INFO: 
Logging pods the kubelet thinks is on node 16f34f29-58df-43ef-838e-06a19f186c15 before test
Jan 15 23:04:23.536: INFO: kube-dns-7559c96fc4-fmw6c from kube-system started at 2019-01-15 20:06:19 +0000 UTC (3 container statuses recorded)
Jan 15 23:04:23.536: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 15 23:04:23.536: INFO: 	Container kubedns ready: true, restart count 0
Jan 15 23:04:23.536: INFO: 	Container sidecar ready: true, restart count 0
Jan 15 23:04:23.536: INFO: fluent-bit-xszkh from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.536: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 23:04:23.536: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 23:04:23.536: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-15 22:21:52 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.536: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 15 23:04:23.536: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-m6gxg from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.536: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 23:04:23.536: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 23:04:23.536: INFO: 
Logging pods the kubelet thinks is on node 77857714-16e9-437d-8ce8-445ba965630c before test
Jan 15 23:04:23.547: INFO: monitoring-influxdb-cdcf4674-lt4k2 from kube-system started at 2019-01-15 20:06:41 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.547: INFO: 	Container influxdb ready: true, restart count 0
Jan 15 23:04:23.547: INFO: telemetry-agent-559f9c8855-xs9n8 from pks-system started at 2019-01-15 20:12:30 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.547: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 23:04:23.547: INFO: metrics-server-555d98886f-78dxc from kube-system started at 2019-01-15 20:06:35 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.547: INFO: 	Container metrics-server ready: true, restart count 0
Jan 15 23:04:23.547: INFO: fluent-bit-2szkk from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.547: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 23:04:23.547: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 23:04:23.547: INFO: sink-controller-65595c498b-94m5j from pks-system started at 2019-01-15 20:06:48 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.547: INFO: 	Container sink-controller ready: true, restart count 0
Jan 15 23:04:23.548: INFO: sonobuoy-e2e-job-7725116febbe4ed6 from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.548: INFO: 	Container e2e ready: true, restart count 0
Jan 15 23:04:23.548: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 23:04:23.548: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-bqggf from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.548: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 23:04:23.548: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 23:04:23.548: INFO: 
Logging pods the kubelet thinks is on node b660f798-38a0-4e83-a501-5381799304ec before test
Jan 15 23:04:23.557: INFO: event-controller-6c77ddd949-2mr6m from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.558: INFO: 	Container event-controller ready: true, restart count 1
Jan 15 23:04:23.558: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 23:04:23.558: INFO: wavefront-proxy-5d455bcbc6-tjnrz from kube-system started at 2019-01-15 20:09:32 +0000 UTC (4 container statuses recorded)
Jan 15 23:04:23.558: INFO: 	Container heapster ready: true, restart count 0
Jan 15 23:04:23.558: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan 15 23:04:23.558: INFO: 	Container telegraf ready: true, restart count 0
Jan 15 23:04:23.558: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan 15 23:04:23.558: INFO: sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-jjmrz from heptio-sonobuoy started at 2019-01-15 22:21:58 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.558: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 15 23:04:23.558: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 15 23:04:23.558: INFO: kubernetes-dashboard-5f4b59b97f-rrcng from kube-system started at 2019-01-15 20:06:44 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.558: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 15 23:04:23.558: INFO: cert-generator-v0.11-h8wxd from pks-system started at 2019-01-15 20:06:48 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.558: INFO: 	Container cert-generator ready: false, restart count 0
Jan 15 23:04:23.558: INFO: fluent-bit-kjcjq from pks-system started at 2019-01-15 20:06:48 +0000 UTC (2 container statuses recorded)
Jan 15 23:04:23.558: INFO: 	Container fluent-bit ready: true, restart count 0
Jan 15 23:04:23.558: INFO: 	Container ghostunnel ready: true, restart count 0
Jan 15 23:04:23.558: INFO: heapster-85647cf566-x9tdm from kube-system started at 2019-01-15 20:06:38 +0000 UTC (1 container statuses recorded)
Jan 15 23:04:23.558: INFO: 	Container heapster ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e86ec789-1919-11e9-993a-025056003018 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-e86ec789-1919-11e9-993a-025056003018 off the node 16f34f29-58df-43ef-838e-06a19f186c15
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e86ec789-1919-11e9-993a-025056003018
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:04:29.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-j7fp5" for this suite.
Jan 15 23:04:37.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:04:37.738: INFO: namespace: e2e-tests-sched-pred-j7fp5, resource: bindings, ignored listing per whitelist
Jan 15 23:04:37.826: INFO: namespace e2e-tests-sched-pred-j7fp5 deletion completed in 8.122005648s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:14.509 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:04:37.826: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-99l26
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-eea4fa23-1919-11e9-993a-025056003018
STEP: Creating configMap with name cm-test-opt-upd-eea4fbc6-1919-11e9-993a-025056003018
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-eea4fa23-1919-11e9-993a-025056003018
STEP: Updating configmap cm-test-opt-upd-eea4fbc6-1919-11e9-993a-025056003018
STEP: Creating configMap with name cm-test-opt-create-eea4fbda-1919-11e9-993a-025056003018
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:05:44.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-99l26" for this suite.
Jan 15 23:06:06.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:06:06.563: INFO: namespace: e2e-tests-projected-99l26, resource: bindings, ignored listing per whitelist
Jan 15 23:06:06.612: INFO: namespace e2e-tests-projected-99l26 deletion completed in 22.116484944s

• [SLOW TEST:88.786 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:06:06.615: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wfmj8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-23922cc2-191a-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:06:06.836: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018" in namespace "e2e-tests-projected-wfmj8" to be "success or failure"
Jan 15 23:06:06.872: INFO: Pod "pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 35.712041ms
Jan 15 23:06:08.876: INFO: Pod "pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040273771s
Jan 15 23:06:10.881: INFO: Pod "pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044855511s
STEP: Saw pod success
Jan 15 23:06:10.881: INFO: Pod "pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:06:10.884: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 23:06:10.913: INFO: Waiting for pod pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018 to disappear
Jan 15 23:06:10.916: INFO: Pod pod-projected-configmaps-23934ad6-191a-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:06:10.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wfmj8" for this suite.
Jan 15 23:06:16.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:06:17.021: INFO: namespace: e2e-tests-projected-wfmj8, resource: bindings, ignored listing per whitelist
Jan 15 23:06:17.030: INFO: namespace e2e-tests-projected-wfmj8 deletion completed in 6.109726527s

• [SLOW TEST:10.416 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:06:17.034: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-vd7qj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-vd7qj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 23:06:17.228: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 23:06:47.358: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.9.5:8080/dial?request=hostName&protocol=udp&host=40.0.9.2&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vd7qj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:06:47.359: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:06:47.484: INFO: Waiting for endpoints: map[]
Jan 15 23:06:47.487: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.9.5:8080/dial?request=hostName&protocol=udp&host=40.0.9.3&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vd7qj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:06:47.487: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:06:47.602: INFO: Waiting for endpoints: map[]
Jan 15 23:06:47.606: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.9.5:8080/dial?request=hostName&protocol=udp&host=40.0.9.4&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-vd7qj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:06:47.606: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:06:47.721: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:06:47.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-vd7qj" for this suite.
Jan 15 23:07:09.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:07:09.834: INFO: namespace: e2e-tests-pod-network-test-vd7qj, resource: bindings, ignored listing per whitelist
Jan 15 23:07:09.834: INFO: namespace e2e-tests-pod-network-test-vd7qj deletion completed in 22.106264108s

• [SLOW TEST:52.801 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:07:09.836: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-t86br
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-t86br
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-t86br
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-t86br
Jan 15 23:07:10.060: INFO: Found 0 stateful pods, waiting for 1
Jan 15 23:07:20.066: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 15 23:07:20.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-t86br ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 23:07:20.303: INFO: stderr: ""
Jan 15 23:07:20.303: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 23:07:20.303: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 23:07:20.307: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 15 23:07:30.311: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 23:07:30.311: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 23:07:30.331: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:30.331: INFO: ss-0  16f34f29-58df-43ef-838e-06a19f186c15  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  }]
Jan 15 23:07:30.331: INFO: ss-1                                        Pending         []
Jan 15 23:07:30.331: INFO: 
Jan 15 23:07:30.331: INFO: StatefulSet ss has not reached scale 3, at 2
Jan 15 23:07:31.337: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992984795s
Jan 15 23:07:32.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987650848s
Jan 15 23:07:33.345: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983227897s
Jan 15 23:07:34.350: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979088582s
Jan 15 23:07:35.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974490657s
Jan 15 23:07:36.366: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.9631166s
Jan 15 23:07:37.370: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958619778s
Jan 15 23:07:38.375: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95409023s
Jan 15 23:07:39.380: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.368823ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-t86br
Jan 15 23:07:40.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-t86br ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 23:07:40.619: INFO: stderr: ""
Jan 15 23:07:40.619: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 23:07:40.619: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 23:07:40.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-t86br ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 23:07:40.833: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 15 23:07:40.833: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 23:07:40.833: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 23:07:40.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-t86br ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 15 23:07:41.115: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 15 23:07:41.115: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 15 23:07:41.115: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 15 23:07:41.120: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:07:41.120: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:07:41.120: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 15 23:07:41.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-t86br ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 23:07:41.337: INFO: stderr: ""
Jan 15 23:07:41.337: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 23:07:41.337: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 23:07:41.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-t86br ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 23:07:41.539: INFO: stderr: ""
Jan 15 23:07:41.539: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 23:07:41.539: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 23:07:41.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 exec --namespace=e2e-tests-statefulset-t86br ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 15 23:07:41.799: INFO: stderr: ""
Jan 15 23:07:41.799: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 15 23:07:41.799: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 15 23:07:41.799: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 23:07:41.803: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 15 23:07:51.811: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 23:07:51.811: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 23:07:51.811: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 15 23:07:51.824: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:51.824: INFO: ss-0  16f34f29-58df-43ef-838e-06a19f186c15  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  }]
Jan 15 23:07:51.824: INFO: ss-1  b660f798-38a0-4e83-a501-5381799304ec  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:51.825: INFO: ss-2  77857714-16e9-437d-8ce8-445ba965630c  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:51.825: INFO: 
Jan 15 23:07:51.825: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 23:07:52.830: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:52.830: INFO: ss-0  16f34f29-58df-43ef-838e-06a19f186c15  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  }]
Jan 15 23:07:52.830: INFO: ss-1  b660f798-38a0-4e83-a501-5381799304ec  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:52.830: INFO: ss-2  77857714-16e9-437d-8ce8-445ba965630c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:52.830: INFO: 
Jan 15 23:07:52.830: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 23:07:53.834: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:53.834: INFO: ss-0  16f34f29-58df-43ef-838e-06a19f186c15  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:10 +0000 UTC  }]
Jan 15 23:07:53.834: INFO: ss-1  b660f798-38a0-4e83-a501-5381799304ec  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:53.834: INFO: ss-2  77857714-16e9-437d-8ce8-445ba965630c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:53.834: INFO: 
Jan 15 23:07:53.834: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 15 23:07:54.838: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:54.839: INFO: ss-1  b660f798-38a0-4e83-a501-5381799304ec  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:54.839: INFO: ss-2  77857714-16e9-437d-8ce8-445ba965630c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:54.839: INFO: 
Jan 15 23:07:54.839: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 15 23:07:55.845: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:55.845: INFO: ss-1  b660f798-38a0-4e83-a501-5381799304ec  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:55.845: INFO: ss-2  77857714-16e9-437d-8ce8-445ba965630c  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:55.845: INFO: 
Jan 15 23:07:55.845: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 15 23:07:56.850: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:56.850: INFO: ss-1  b660f798-38a0-4e83-a501-5381799304ec  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:56.850: INFO: 
Jan 15 23:07:56.850: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 15 23:07:57.854: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan 15 23:07:57.854: INFO: ss-1  b660f798-38a0-4e83-a501-5381799304ec  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:07:30 +0000 UTC  }]
Jan 15 23:07:57.854: INFO: 
Jan 15 23:07:57.854: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 15 23:07:58.858: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.965509607s
Jan 15 23:07:59.862: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.961563022s
Jan 15 23:08:00.867: INFO: Verifying statefulset ss doesn't scale past 0 for another 958.001744ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-t86br
Jan 15 23:08:01.872: INFO: Scaling statefulset ss to 0
Jan 15 23:08:01.883: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 23:08:01.886: INFO: Deleting all statefulset in ns e2e-tests-statefulset-t86br
Jan 15 23:08:01.889: INFO: Scaling statefulset ss to 0
Jan 15 23:08:01.898: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 23:08:01.900: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:08:02.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-t86br" for this suite.
Jan 15 23:08:08.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:08:08.093: INFO: namespace: e2e-tests-statefulset-t86br, resource: bindings, ignored listing per whitelist
Jan 15 23:08:08.129: INFO: namespace e2e-tests-statefulset-t86br deletion completed in 6.11452742s

• [SLOW TEST:58.294 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:08:08.132: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-xzzzt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-6c00ccf5-191a-11e9-993a-025056003018
Jan 15 23:08:08.370: INFO: Pod name my-hostname-basic-6c00ccf5-191a-11e9-993a-025056003018: Found 1 pods out of 1
Jan 15 23:08:08.370: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-6c00ccf5-191a-11e9-993a-025056003018" are running
Jan 15 23:08:12.390: INFO: Pod "my-hostname-basic-6c00ccf5-191a-11e9-993a-025056003018-txts4" is running (conditions: [])
Jan 15 23:08:12.390: INFO: Trying to dial the pod
Jan 15 23:08:17.408: INFO: Controller my-hostname-basic-6c00ccf5-191a-11e9-993a-025056003018: Got expected result from replica 1 [my-hostname-basic-6c00ccf5-191a-11e9-993a-025056003018-txts4]: "my-hostname-basic-6c00ccf5-191a-11e9-993a-025056003018-txts4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:08:17.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-xzzzt" for this suite.
Jan 15 23:08:23.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:08:23.511: INFO: namespace: e2e-tests-replication-controller-xzzzt, resource: bindings, ignored listing per whitelist
Jan 15 23:08:23.517: INFO: namespace e2e-tests-replication-controller-xzzzt deletion completed in 6.103063792s

• [SLOW TEST:15.385 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:08:23.519: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-2478w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:08:23.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2478w" for this suite.
Jan 15 23:08:45.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:08:45.835: INFO: namespace: e2e-tests-pods-2478w, resource: bindings, ignored listing per whitelist
Jan 15 23:08:45.908: INFO: namespace e2e-tests-pods-2478w deletion completed in 22.130944244s

• [SLOW TEST:22.389 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:08:45.914: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-7qqh9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7qqh9
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-7qqh9
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-7qqh9
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-7qqh9
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-7qqh9
Jan 15 23:08:50.210: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-7qqh9, name: ss-0, uid: 829e1bcd-191a-11e9-8273-005056af1926, status phase: Pending. Waiting for statefulset controller to delete.
Jan 15 23:08:56.176: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-7qqh9, name: ss-0, uid: 829e1bcd-191a-11e9-8273-005056af1926, status phase: Failed. Waiting for statefulset controller to delete.
Jan 15 23:08:56.186: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-7qqh9, name: ss-0, uid: 829e1bcd-191a-11e9-8273-005056af1926, status phase: Failed. Waiting for statefulset controller to delete.
Jan 15 23:08:56.199: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-7qqh9
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-7qqh9
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-7qqh9 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 23:09:10.290: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7qqh9
Jan 15 23:09:10.293: INFO: Scaling statefulset ss to 0
Jan 15 23:09:20.313: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 23:09:20.318: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:09:20.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7qqh9" for this suite.
Jan 15 23:09:26.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:09:26.415: INFO: namespace: e2e-tests-statefulset-7qqh9, resource: bindings, ignored listing per whitelist
Jan 15 23:09:26.484: INFO: namespace e2e-tests-statefulset-7qqh9 deletion completed in 6.126192296s

• [SLOW TEST:40.570 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:09:26.486: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-5n8ft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 23:09:26.703: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:09:31.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-5n8ft" for this suite.
Jan 15 23:09:37.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:09:37.747: INFO: namespace: e2e-tests-init-container-5n8ft, resource: bindings, ignored listing per whitelist
Jan 15 23:09:37.786: INFO: namespace e2e-tests-init-container-5n8ft deletion completed in 6.100952809s

• [SLOW TEST:11.300 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:09:37.788: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fwxvm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0115 23:09:44.028892      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 23:09:44.029: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:09:44.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fwxvm" for this suite.
Jan 15 23:09:50.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:09:50.096: INFO: namespace: e2e-tests-gc-fwxvm, resource: bindings, ignored listing per whitelist
Jan 15 23:09:50.173: INFO: namespace e2e-tests-gc-fwxvm deletion completed in 6.13982737s

• [SLOW TEST:12.384 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:09:50.174: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-4xfnb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:09:50.383: INFO: Creating deployment "test-recreate-deployment"
Jan 15 23:09:50.393: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 15 23:09:50.401: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan 15 23:09:52.408: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 15 23:09:52.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683190590, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683190590, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683190590, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683190590, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 23:09:54.415: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 15 23:09:54.424: INFO: Updating deployment test-recreate-deployment
Jan 15 23:09:54.424: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 23:09:54.531: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-4xfnb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4xfnb/deployments/test-recreate-deployment,UID:a8d5035f-191a-11e9-8273-005056af1926,ResourceVersion:23366,Generation:2,CreationTimestamp:2019-01-15 23:09:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-15 23:09:54 +0000 UTC 2019-01-15 23:09:54 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-15 23:09:54 +0000 UTC 2019-01-15 23:09:50 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 15 23:09:54.539: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-4xfnb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4xfnb/replicasets/test-recreate-deployment-7cf749666b,UID:ab44a71f-191a-11e9-8273-005056af1926,ResourceVersion:23365,Generation:1,CreationTimestamp:2019-01-15 23:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a8d5035f-191a-11e9-8273-005056af1926 0xc4228fceb7 0xc4228fceb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 23:09:54.539: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 15 23:09:54.539: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-4xfnb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4xfnb/replicasets/test-recreate-deployment-79f694ff59,UID:a8d7be69-191a-11e9-8273-005056af1926,ResourceVersion:23356,Generation:2,CreationTimestamp:2019-01-15 23:09:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment a8d5035f-191a-11e9-8273-005056af1926 0xc4228fc837 0xc4228fc838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 23:09:54.547: INFO: Pod "test-recreate-deployment-7cf749666b-8k6bc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-8k6bc,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-4xfnb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4xfnb/pods/test-recreate-deployment-7cf749666b-8k6bc,UID:ab464e6a-191a-11e9-8273-005056af1926,ResourceVersion:23367,Generation:0,CreationTimestamp:2019-01-15 23:09:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b ab44a71f-191a-11e9-8273-005056af1926 0xc421d47357 0xc421d47358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l9k4h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l9k4h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l9k4h true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d473c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d473e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:09:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:09:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:09:54 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-15 23:09:54 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:09:54.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4xfnb" for this suite.
Jan 15 23:10:00.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:10:00.688: INFO: namespace: e2e-tests-deployment-4xfnb, resource: bindings, ignored listing per whitelist
Jan 15 23:10:00.735: INFO: namespace e2e-tests-deployment-4xfnb deletion completed in 6.183503674s

• [SLOW TEST:10.562 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:10:00.736: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xg69r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-af23d13d-191a-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:10:01.218: INFO: Waiting up to 5m0s for pod "pod-configmaps-af27129b-191a-11e9-993a-025056003018" in namespace "e2e-tests-configmap-xg69r" to be "success or failure"
Jan 15 23:10:01.254: INFO: Pod "pod-configmaps-af27129b-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 35.861488ms
Jan 15 23:10:03.259: INFO: Pod "pod-configmaps-af27129b-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041219428s
Jan 15 23:10:05.267: INFO: Pod "pod-configmaps-af27129b-191a-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048904645s
STEP: Saw pod success
Jan 15 23:10:05.267: INFO: Pod "pod-configmaps-af27129b-191a-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:10:05.272: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-af27129b-191a-11e9-993a-025056003018 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 23:10:05.314: INFO: Waiting for pod pod-configmaps-af27129b-191a-11e9-993a-025056003018 to disappear
Jan 15 23:10:05.325: INFO: Pod pod-configmaps-af27129b-191a-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:10:05.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xg69r" for this suite.
Jan 15 23:10:11.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:10:11.381: INFO: namespace: e2e-tests-configmap-xg69r, resource: bindings, ignored listing per whitelist
Jan 15 23:10:11.450: INFO: namespace e2e-tests-configmap-xg69r deletion completed in 6.114308717s

• [SLOW TEST:10.714 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:10:11.450: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-h5kfq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b5802b7e-191a-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:10:11.656: INFO: Waiting up to 5m0s for pod "pod-secrets-b580f1bd-191a-11e9-993a-025056003018" in namespace "e2e-tests-secrets-h5kfq" to be "success or failure"
Jan 15 23:10:11.669: INFO: Pod "pod-secrets-b580f1bd-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 12.820206ms
Jan 15 23:10:13.672: INFO: Pod "pod-secrets-b580f1bd-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015972506s
Jan 15 23:10:15.677: INFO: Pod "pod-secrets-b580f1bd-191a-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020744339s
STEP: Saw pod success
Jan 15 23:10:15.677: INFO: Pod "pod-secrets-b580f1bd-191a-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:10:15.681: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-b580f1bd-191a-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:10:15.715: INFO: Waiting for pod pod-secrets-b580f1bd-191a-11e9-993a-025056003018 to disappear
Jan 15 23:10:15.719: INFO: Pod pod-secrets-b580f1bd-191a-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:10:15.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-h5kfq" for this suite.
Jan 15 23:10:21.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:10:21.749: INFO: namespace: e2e-tests-secrets-h5kfq, resource: bindings, ignored listing per whitelist
Jan 15 23:10:21.885: INFO: namespace e2e-tests-secrets-h5kfq deletion completed in 6.159856642s

• [SLOW TEST:10.435 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:10:21.887: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gn2nz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 23:10:22.123: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018" in namespace "e2e-tests-projected-gn2nz" to be "success or failure"
Jan 15 23:10:22.145: INFO: Pod "downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 21.121767ms
Jan 15 23:10:24.152: INFO: Pod "downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028503898s
Jan 15 23:10:26.158: INFO: Pod "downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03439453s
STEP: Saw pod success
Jan 15 23:10:26.158: INFO: Pod "downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:10:26.161: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 23:10:26.185: INFO: Waiting for pod downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018 to disappear
Jan 15 23:10:26.188: INFO: Pod downwardapi-volume-bbbcc36c-191a-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:10:26.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gn2nz" for this suite.
Jan 15 23:10:32.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:10:32.253: INFO: namespace: e2e-tests-projected-gn2nz, resource: bindings, ignored listing per whitelist
Jan 15 23:10:32.304: INFO: namespace e2e-tests-projected-gn2nz deletion completed in 6.111543083s

• [SLOW TEST:10.418 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:10:32.305: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-k9whm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 15 23:10:32.514: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k9whm,SelfLink:/api/v1/namespaces/e2e-tests-watch-k9whm/configmaps/e2e-watch-test-watch-closed,UID:c1eef876-191a-11e9-8273-005056af1926,ResourceVersion:23532,Generation:0,CreationTimestamp:2019-01-15 23:10:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 23:10:32.514: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k9whm,SelfLink:/api/v1/namespaces/e2e-tests-watch-k9whm/configmaps/e2e-watch-test-watch-closed,UID:c1eef876-191a-11e9-8273-005056af1926,ResourceVersion:23533,Generation:0,CreationTimestamp:2019-01-15 23:10:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 15 23:10:32.532: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k9whm,SelfLink:/api/v1/namespaces/e2e-tests-watch-k9whm/configmaps/e2e-watch-test-watch-closed,UID:c1eef876-191a-11e9-8273-005056af1926,ResourceVersion:23534,Generation:0,CreationTimestamp:2019-01-15 23:10:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 23:10:32.532: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k9whm,SelfLink:/api/v1/namespaces/e2e-tests-watch-k9whm/configmaps/e2e-watch-test-watch-closed,UID:c1eef876-191a-11e9-8273-005056af1926,ResourceVersion:23535,Generation:0,CreationTimestamp:2019-01-15 23:10:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:10:32.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-k9whm" for this suite.
Jan 15 23:10:38.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:10:38.586: INFO: namespace: e2e-tests-watch-k9whm, resource: bindings, ignored listing per whitelist
Jan 15 23:10:38.637: INFO: namespace e2e-tests-watch-k9whm deletion completed in 6.099820407s

• [SLOW TEST:6.332 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:10:38.638: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9s95q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 15 23:10:38.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:39.146: INFO: stderr: ""
Jan 15 23:10:39.147: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 23:10:39.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:39.266: INFO: stderr: ""
Jan 15 23:10:39.266: INFO: stdout: "update-demo-nautilus-9pjlw update-demo-nautilus-nq7qs "
Jan 15 23:10:39.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-9pjlw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:39.369: INFO: stderr: ""
Jan 15 23:10:39.369: INFO: stdout: ""
Jan 15 23:10:39.369: INFO: update-demo-nautilus-9pjlw is created but not running
Jan 15 23:10:44.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:44.487: INFO: stderr: ""
Jan 15 23:10:44.487: INFO: stdout: "update-demo-nautilus-9pjlw update-demo-nautilus-nq7qs "
Jan 15 23:10:44.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-9pjlw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:44.605: INFO: stderr: ""
Jan 15 23:10:44.605: INFO: stdout: "true"
Jan 15 23:10:44.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-9pjlw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:44.725: INFO: stderr: ""
Jan 15 23:10:44.725: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:10:44.725: INFO: validating pod update-demo-nautilus-9pjlw
Jan 15 23:10:44.732: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:10:44.733: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:10:44.733: INFO: update-demo-nautilus-9pjlw is verified up and running
Jan 15 23:10:44.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-nq7qs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:44.846: INFO: stderr: ""
Jan 15 23:10:44.846: INFO: stdout: "true"
Jan 15 23:10:44.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-nq7qs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:44.989: INFO: stderr: ""
Jan 15 23:10:44.989: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:10:44.989: INFO: validating pod update-demo-nautilus-nq7qs
Jan 15 23:10:45.001: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:10:45.001: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:10:45.001: INFO: update-demo-nautilus-nq7qs is verified up and running
STEP: using delete to clean up resources
Jan 15 23:10:45.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:45.148: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:10:45.148: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 15 23:10:45.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-9s95q'
Jan 15 23:10:45.350: INFO: stderr: "No resources found.\n"
Jan 15 23:10:45.350: INFO: stdout: ""
Jan 15 23:10:45.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -l name=update-demo --namespace=e2e-tests-kubectl-9s95q -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 15 23:10:45.576: INFO: stderr: ""
Jan 15 23:10:45.576: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:10:45.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9s95q" for this suite.
Jan 15 23:11:07.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:11:07.650: INFO: namespace: e2e-tests-kubectl-9s95q, resource: bindings, ignored listing per whitelist
Jan 15 23:11:07.685: INFO: namespace e2e-tests-kubectl-9s95q deletion completed in 22.102220825s

• [SLOW TEST:29.047 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:11:07.685: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-dwv7d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dwv7d
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 15 23:11:07.906: INFO: Found 0 stateful pods, waiting for 3
Jan 15 23:11:17.911: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:11:17.912: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:11:17.912: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 15 23:11:17.961: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 15 23:11:28.030: INFO: Updating stateful set ss2
Jan 15 23:11:28.037: INFO: Waiting for Pod e2e-tests-statefulset-dwv7d/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 15 23:11:38.047: INFO: Waiting for Pod e2e-tests-statefulset-dwv7d/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 15 23:11:48.145: INFO: Found 2 stateful pods, waiting for 3
Jan 15 23:11:58.149: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:11:58.149: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:11:58.149: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Jan 15 23:12:08.150: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:12:08.151: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 15 23:12:08.151: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 15 23:12:08.185: INFO: Updating stateful set ss2
Jan 15 23:12:08.201: INFO: Waiting for Pod e2e-tests-statefulset-dwv7d/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 15 23:12:18.233: INFO: Updating stateful set ss2
Jan 15 23:12:18.245: INFO: Waiting for StatefulSet e2e-tests-statefulset-dwv7d/ss2 to complete update
Jan 15 23:12:18.246: INFO: Waiting for Pod e2e-tests-statefulset-dwv7d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 15 23:12:28.253: INFO: Waiting for StatefulSet e2e-tests-statefulset-dwv7d/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 15 23:12:38.253: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dwv7d
Jan 15 23:12:38.261: INFO: Scaling statefulset ss2 to 0
Jan 15 23:12:58.277: INFO: Waiting for statefulset status.replicas updated to 0
Jan 15 23:12:58.280: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:12:58.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dwv7d" for this suite.
Jan 15 23:13:04.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:13:04.411: INFO: namespace: e2e-tests-statefulset-dwv7d, resource: bindings, ignored listing per whitelist
Jan 15 23:13:04.438: INFO: namespace e2e-tests-statefulset-dwv7d deletion completed in 6.122975454s

• [SLOW TEST:116.753 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:13:04.439: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-p59pr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1c9f4970-191b-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:13:04.663: INFO: Waiting up to 5m0s for pod "pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018" in namespace "e2e-tests-configmap-p59pr" to be "success or failure"
Jan 15 23:13:04.677: INFO: Pod "pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 14.285806ms
Jan 15 23:13:06.683: INFO: Pod "pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019751995s
Jan 15 23:13:08.687: INFO: Pod "pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023680386s
STEP: Saw pod success
Jan 15 23:13:08.687: INFO: Pod "pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:13:08.690: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 23:13:08.721: INFO: Waiting for pod pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018 to disappear
Jan 15 23:13:08.731: INFO: Pod pod-configmaps-1c9ff00c-191b-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:13:08.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p59pr" for this suite.
Jan 15 23:13:14.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:13:14.813: INFO: namespace: e2e-tests-configmap-p59pr, resource: bindings, ignored listing per whitelist
Jan 15 23:13:14.844: INFO: namespace e2e-tests-configmap-p59pr deletion completed in 6.10795381s

• [SLOW TEST:10.405 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:13:14.845: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-zzk74
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:13:15.080: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 23:13:15.107: INFO: Number of nodes with available pods: 0
Jan 15 23:13:15.107: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:13:16.115: INFO: Number of nodes with available pods: 0
Jan 15 23:13:16.115: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:13:17.114: INFO: Number of nodes with available pods: 0
Jan 15 23:13:17.114: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:13:18.117: INFO: Number of nodes with available pods: 1
Jan 15 23:13:18.117: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:13:19.116: INFO: Number of nodes with available pods: 1
Jan 15 23:13:19.116: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:13:20.116: INFO: Number of nodes with available pods: 1
Jan 15 23:13:20.116: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:13:21.115: INFO: Number of nodes with available pods: 1
Jan 15 23:13:21.115: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:13:22.115: INFO: Number of nodes with available pods: 1
Jan 15 23:13:22.116: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:13:23.116: INFO: Number of nodes with available pods: 1
Jan 15 23:13:23.117: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:13:24.115: INFO: Number of nodes with available pods: 1
Jan 15 23:13:24.115: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:13:25.115: INFO: Number of nodes with available pods: 3
Jan 15 23:13:25.115: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 15 23:13:25.138: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:25.138: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:25.138: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:26.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:26.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:26.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:27.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:27.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:27.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:28.158: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:28.158: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:28.158: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:29.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:29.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:29.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:30.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:30.149: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:30.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:31.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:31.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:31.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:32.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:32.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:32.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:33.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:33.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:33.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:34.155: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:34.155: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:34.155: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:35.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:35.149: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:35.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:36.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:36.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:36.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:37.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:37.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:37.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:38.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:38.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:38.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:39.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:39.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:39.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:40.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:40.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:40.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:41.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:41.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:41.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:42.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:42.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:42.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:43.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:43.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:43.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:44.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:44.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:44.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:45.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:45.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:45.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:46.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:46.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:46.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:47.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:47.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:47.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:48.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:48.149: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:48.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:49.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:49.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:49.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:50.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:50.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:50.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:51.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:51.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:51.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:52.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:52.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:52.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:53.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:53.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:53.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:54.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:54.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:54.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:55.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:55.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:55.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:56.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:56.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:56.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:57.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:57.148: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:57.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:58.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:58.147: INFO: Wrong image for pod: daemon-set-9t2dq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:58.147: INFO: Pod daemon-set-9t2dq is not available
Jan 15 23:13:58.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:59.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:13:59.147: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:13:59.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:00.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:00.148: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:14:00.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:01.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:01.148: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:14:01.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:02.150: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:02.150: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:14:02.150: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:03.150: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:03.150: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:14:03.150: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:04.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:04.148: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:14:04.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:05.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:05.148: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:14:05.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:06.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:06.148: INFO: Pod daemon-set-fhb27 is not available
Jan 15 23:14:06.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:07.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:07.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:08.151: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:08.151: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:09.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:09.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:10.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:10.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:11.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:11.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:12.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:12.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:13.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:13.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:14.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:14.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:15.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:15.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:16.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:16.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:17.152: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:17.152: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:18.151: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:18.151: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:19.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:19.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:20.147: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:20.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:21.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:21.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:22.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:22.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:23.150: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:23.150: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:24.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:24.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:25.151: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:25.151: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:26.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:26.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:27.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:27.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:28.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:28.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:29.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:29.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:30.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:30.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:31.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:31.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:32.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:32.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:33.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:33.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:34.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:34.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:35.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:35.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:36.149: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:36.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:37.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:37.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:38.148: INFO: Wrong image for pod: daemon-set-7gpsh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:38.149: INFO: Pod daemon-set-7gpsh is not available
Jan 15 23:14:38.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:39.149: INFO: Pod daemon-set-26v4h is not available
Jan 15 23:14:39.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:40.148: INFO: Pod daemon-set-26v4h is not available
Jan 15 23:14:40.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:41.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:42.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:43.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:44.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:45.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:46.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:47.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:48.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:49.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:50.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:51.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:52.150: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:53.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:54.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:55.152: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:56.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:57.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:58.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:14:59.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:00.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:01.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:02.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:03.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:04.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:05.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:06.152: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:07.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:08.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:09.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:10.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:11.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:12.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:12.150: INFO: Pod daemon-set-vjbpp is not available
Jan 15 23:15:13.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:13.148: INFO: Pod daemon-set-vjbpp is not available
Jan 15 23:15:14.148: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:14.148: INFO: Pod daemon-set-vjbpp is not available
Jan 15 23:15:15.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:15.149: INFO: Pod daemon-set-vjbpp is not available
Jan 15 23:15:16.157: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:16.157: INFO: Pod daemon-set-vjbpp is not available
Jan 15 23:15:17.149: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:17.149: INFO: Pod daemon-set-vjbpp is not available
Jan 15 23:15:18.147: INFO: Wrong image for pod: daemon-set-vjbpp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 15 23:15:18.147: INFO: Pod daemon-set-vjbpp is not available
Jan 15 23:15:19.149: INFO: Pod daemon-set-jj4hb is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 15 23:15:19.159: INFO: Number of nodes with available pods: 2
Jan 15 23:15:19.159: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:15:20.179: INFO: Number of nodes with available pods: 2
Jan 15 23:15:20.179: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:15:21.167: INFO: Number of nodes with available pods: 2
Jan 15 23:15:21.167: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:15:22.169: INFO: Number of nodes with available pods: 3
Jan 15 23:15:22.169: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-zzk74, will wait for the garbage collector to delete the pods
Jan 15 23:15:22.263: INFO: Deleting {extensions DaemonSet} daemon-set took: 17.155237ms
Jan 15 23:15:22.363: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.364873ms
Jan 15 23:15:28.466: INFO: Number of nodes with available pods: 0
Jan 15 23:15:28.466: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 23:15:28.469: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zzk74/daemonsets","resourceVersion":"24414"},"items":null}

Jan 15 23:15:28.471: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zzk74/pods","resourceVersion":"24414"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:15:28.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zzk74" for this suite.
Jan 15 23:15:34.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:15:34.537: INFO: namespace: e2e-tests-daemonsets-zzk74, resource: bindings, ignored listing per whitelist
Jan 15 23:15:34.593: INFO: namespace e2e-tests-daemonsets-zzk74 deletion completed in 6.102207766s

• [SLOW TEST:139.748 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:15:34.594: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9nbj6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-761af704-191b-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:15:34.808: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-761bb125-191b-11e9-993a-025056003018" in namespace "e2e-tests-projected-9nbj6" to be "success or failure"
Jan 15 23:15:34.813: INFO: Pod "pod-projected-secrets-761bb125-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137746ms
Jan 15 23:15:36.817: INFO: Pod "pod-projected-secrets-761bb125-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00814s
Jan 15 23:15:38.820: INFO: Pod "pod-projected-secrets-761bb125-191b-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011985877s
STEP: Saw pod success
Jan 15 23:15:38.820: INFO: Pod "pod-projected-secrets-761bb125-191b-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:15:38.823: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-secrets-761bb125-191b-11e9-993a-025056003018 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:15:38.854: INFO: Waiting for pod pod-projected-secrets-761bb125-191b-11e9-993a-025056003018 to disappear
Jan 15 23:15:38.861: INFO: Pod pod-projected-secrets-761bb125-191b-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:15:38.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9nbj6" for this suite.
Jan 15 23:15:44.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:15:44.924: INFO: namespace: e2e-tests-projected-9nbj6, resource: bindings, ignored listing per whitelist
Jan 15 23:15:44.999: INFO: namespace e2e-tests-projected-9nbj6 deletion completed in 6.133773308s

• [SLOW TEST:10.406 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:15:45.003: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-kqzsf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kqzsf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 23:15:45.206: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 23:16:07.369: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.10.5:8080/dial?request=hostName&protocol=http&host=40.0.10.2&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kqzsf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:16:07.369: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:16:07.529: INFO: Waiting for endpoints: map[]
Jan 15 23:16:07.532: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.10.5:8080/dial?request=hostName&protocol=http&host=40.0.10.3&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kqzsf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:16:07.533: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:16:07.670: INFO: Waiting for endpoints: map[]
Jan 15 23:16:07.674: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.10.5:8080/dial?request=hostName&protocol=http&host=40.0.10.4&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-kqzsf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:16:07.674: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:16:07.808: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:16:07.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kqzsf" for this suite.
Jan 15 23:16:29.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:16:29.919: INFO: namespace: e2e-tests-pod-network-test-kqzsf, resource: bindings, ignored listing per whitelist
Jan 15 23:16:29.919: INFO: namespace e2e-tests-pod-network-test-kqzsf deletion completed in 22.105245567s

• [SLOW TEST:44.917 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:16:29.922: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-cp26r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-cp26r;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-cp26r;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-cp26r.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-cp26r.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cp26r.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 14.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.14_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 14.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.14_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-cp26r;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-cp26r;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-cp26r.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-cp26r.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-cp26r.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-cp26r.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-cp26r.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-cp26r.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 14.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.14_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 14.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.14_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 23:17:02.457: INFO: DNS probes using e2e-tests-dns-cp26r/dns-test-9727473b-191b-11e9-993a-025056003018 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:17:02.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-cp26r" for this suite.
Jan 15 23:17:08.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:17:08.641: INFO: namespace: e2e-tests-dns-cp26r, resource: bindings, ignored listing per whitelist
Jan 15 23:17:08.677: INFO: namespace e2e-tests-dns-cp26r deletion completed in 6.120767376s

• [SLOW TEST:38.755 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:17:08.679: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jbkwj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-ae31e45f-191b-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:17:08.902: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018" in namespace "e2e-tests-projected-jbkwj" to be "success or failure"
Jan 15 23:17:08.912: INFO: Pod "pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 10.123304ms
Jan 15 23:17:10.919: INFO: Pod "pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017356639s
Jan 15 23:17:12.929: INFO: Pod "pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027120041s
STEP: Saw pod success
Jan 15 23:17:12.929: INFO: Pod "pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:17:12.933: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:17:12.970: INFO: Waiting for pod pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018 to disappear
Jan 15 23:17:12.976: INFO: Pod pod-projected-secrets-ae32708c-191b-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:17:12.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jbkwj" for this suite.
Jan 15 23:17:18.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:17:19.055: INFO: namespace: e2e-tests-projected-jbkwj, resource: bindings, ignored listing per whitelist
Jan 15 23:17:19.100: INFO: namespace e2e-tests-projected-jbkwj deletion completed in 6.118673341s

• [SLOW TEST:10.421 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:17:19.101: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s24xf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b469ce53-191b-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:17:19.328: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018" in namespace "e2e-tests-projected-s24xf" to be "success or failure"
Jan 15 23:17:19.338: INFO: Pod "pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 10.54489ms
Jan 15 23:17:21.342: INFO: Pod "pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014433255s
Jan 15 23:17:23.347: INFO: Pod "pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019149818s
STEP: Saw pod success
Jan 15 23:17:23.347: INFO: Pod "pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:17:23.350: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:17:23.375: INFO: Waiting for pod pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018 to disappear
Jan 15 23:17:23.382: INFO: Pod pod-projected-secrets-b46a68f7-191b-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:17:23.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s24xf" for this suite.
Jan 15 23:17:29.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:17:29.488: INFO: namespace: e2e-tests-projected-s24xf, resource: bindings, ignored listing per whitelist
Jan 15 23:17:29.500: INFO: namespace e2e-tests-projected-s24xf deletion completed in 6.111267526s

• [SLOW TEST:10.399 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:17:29.502: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9p8dl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ba9b3e4c-191b-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:17:29.717: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba9bda57-191b-11e9-993a-025056003018" in namespace "e2e-tests-configmap-9p8dl" to be "success or failure"
Jan 15 23:17:29.751: INFO: Pod "pod-configmaps-ba9bda57-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 33.57709ms
Jan 15 23:17:31.755: INFO: Pod "pod-configmaps-ba9bda57-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038169329s
Jan 15 23:17:33.759: INFO: Pod "pod-configmaps-ba9bda57-191b-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041800517s
STEP: Saw pod success
Jan 15 23:17:33.759: INFO: Pod "pod-configmaps-ba9bda57-191b-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:17:33.762: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-ba9bda57-191b-11e9-993a-025056003018 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 23:17:33.778: INFO: Waiting for pod pod-configmaps-ba9bda57-191b-11e9-993a-025056003018 to disappear
Jan 15 23:17:33.784: INFO: Pod pod-configmaps-ba9bda57-191b-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:17:33.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9p8dl" for this suite.
Jan 15 23:17:39.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:17:39.850: INFO: namespace: e2e-tests-configmap-9p8dl, resource: bindings, ignored listing per whitelist
Jan 15 23:17:39.915: INFO: namespace e2e-tests-configmap-9p8dl deletion completed in 6.124245643s

• [SLOW TEST:10.414 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:17:39.918: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-5t9jp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5t9jp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 23:17:40.138: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 23:17:58.253: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.9.2 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5t9jp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:17:58.253: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:17:59.394: INFO: Found all expected endpoints: [netserver-0]
Jan 15 23:17:59.398: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.9.3 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5t9jp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:17:59.398: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:18:00.505: INFO: Found all expected endpoints: [netserver-1]
Jan 15 23:18:00.508: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.9.4 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5t9jp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:18:00.509: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:18:01.616: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:18:01.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5t9jp" for this suite.
Jan 15 23:18:23.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:18:23.658: INFO: namespace: e2e-tests-pod-network-test-5t9jp, resource: bindings, ignored listing per whitelist
Jan 15 23:18:23.731: INFO: namespace e2e-tests-pod-network-test-5t9jp deletion completed in 22.108898645s

• [SLOW TEST:43.814 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:18:23.734: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lz5bd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lz5bd/configmap-test-daed6c8d-191b-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:18:23.942: INFO: Waiting up to 5m0s for pod "pod-configmaps-daee31ec-191b-11e9-993a-025056003018" in namespace "e2e-tests-configmap-lz5bd" to be "success or failure"
Jan 15 23:18:23.947: INFO: Pod "pod-configmaps-daee31ec-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.379218ms
Jan 15 23:18:25.951: INFO: Pod "pod-configmaps-daee31ec-191b-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008661986s
Jan 15 23:18:27.955: INFO: Pod "pod-configmaps-daee31ec-191b-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012802711s
STEP: Saw pod success
Jan 15 23:18:27.956: INFO: Pod "pod-configmaps-daee31ec-191b-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:18:27.959: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-daee31ec-191b-11e9-993a-025056003018 container env-test: <nil>
STEP: delete the pod
Jan 15 23:18:27.993: INFO: Waiting for pod pod-configmaps-daee31ec-191b-11e9-993a-025056003018 to disappear
Jan 15 23:18:27.997: INFO: Pod pod-configmaps-daee31ec-191b-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:18:27.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lz5bd" for this suite.
Jan 15 23:18:34.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:18:34.108: INFO: namespace: e2e-tests-configmap-lz5bd, resource: bindings, ignored listing per whitelist
Jan 15 23:18:34.123: INFO: namespace e2e-tests-configmap-lz5bd deletion completed in 6.121992065s

• [SLOW TEST:10.390 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:18:34.125: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-m7qdm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 23:18:34.358: INFO: Number of nodes with available pods: 0
Jan 15 23:18:34.358: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:18:35.948: INFO: Number of nodes with available pods: 0
Jan 15 23:18:35.948: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:18:36.366: INFO: Number of nodes with available pods: 0
Jan 15 23:18:36.366: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:18:37.369: INFO: Number of nodes with available pods: 2
Jan 15 23:18:37.369: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:18:38.368: INFO: Number of nodes with available pods: 2
Jan 15 23:18:38.368: INFO: Node 77857714-16e9-437d-8ce8-445ba965630c is running more than one daemon pod
Jan 15 23:18:39.368: INFO: Number of nodes with available pods: 3
Jan 15 23:18:39.368: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 15 23:18:39.393: INFO: Number of nodes with available pods: 2
Jan 15 23:18:39.394: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:40.403: INFO: Number of nodes with available pods: 2
Jan 15 23:18:40.403: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:41.403: INFO: Number of nodes with available pods: 2
Jan 15 23:18:41.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:42.405: INFO: Number of nodes with available pods: 2
Jan 15 23:18:42.405: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:43.404: INFO: Number of nodes with available pods: 2
Jan 15 23:18:43.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:44.402: INFO: Number of nodes with available pods: 2
Jan 15 23:18:44.402: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:45.403: INFO: Number of nodes with available pods: 2
Jan 15 23:18:45.403: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:46.404: INFO: Number of nodes with available pods: 2
Jan 15 23:18:46.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:47.405: INFO: Number of nodes with available pods: 2
Jan 15 23:18:47.405: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:48.402: INFO: Number of nodes with available pods: 2
Jan 15 23:18:48.402: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:49.403: INFO: Number of nodes with available pods: 2
Jan 15 23:18:49.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:50.406: INFO: Number of nodes with available pods: 2
Jan 15 23:18:50.406: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:51.404: INFO: Number of nodes with available pods: 2
Jan 15 23:18:51.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:52.410: INFO: Number of nodes with available pods: 2
Jan 15 23:18:52.410: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:53.404: INFO: Number of nodes with available pods: 2
Jan 15 23:18:53.405: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:54.403: INFO: Number of nodes with available pods: 2
Jan 15 23:18:54.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:55.403: INFO: Number of nodes with available pods: 2
Jan 15 23:18:55.403: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:56.406: INFO: Number of nodes with available pods: 2
Jan 15 23:18:56.406: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:57.409: INFO: Number of nodes with available pods: 2
Jan 15 23:18:57.409: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:58.403: INFO: Number of nodes with available pods: 2
Jan 15 23:18:58.403: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:18:59.402: INFO: Number of nodes with available pods: 2
Jan 15 23:18:59.402: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:00.402: INFO: Number of nodes with available pods: 2
Jan 15 23:19:00.402: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:01.402: INFO: Number of nodes with available pods: 2
Jan 15 23:19:01.402: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:02.404: INFO: Number of nodes with available pods: 2
Jan 15 23:19:02.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:03.404: INFO: Number of nodes with available pods: 2
Jan 15 23:19:03.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:04.404: INFO: Number of nodes with available pods: 2
Jan 15 23:19:04.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:05.402: INFO: Number of nodes with available pods: 2
Jan 15 23:19:05.402: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:06.406: INFO: Number of nodes with available pods: 2
Jan 15 23:19:06.406: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:07.404: INFO: Number of nodes with available pods: 2
Jan 15 23:19:07.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:08.403: INFO: Number of nodes with available pods: 2
Jan 15 23:19:08.403: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:09.404: INFO: Number of nodes with available pods: 2
Jan 15 23:19:09.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:10.409: INFO: Number of nodes with available pods: 2
Jan 15 23:19:10.409: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:11.408: INFO: Number of nodes with available pods: 2
Jan 15 23:19:11.408: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:12.409: INFO: Number of nodes with available pods: 2
Jan 15 23:19:12.409: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:13.402: INFO: Number of nodes with available pods: 2
Jan 15 23:19:13.402: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:14.417: INFO: Number of nodes with available pods: 2
Jan 15 23:19:14.417: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:15.403: INFO: Number of nodes with available pods: 2
Jan 15 23:19:15.403: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:16.404: INFO: Number of nodes with available pods: 2
Jan 15 23:19:16.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:17.403: INFO: Number of nodes with available pods: 2
Jan 15 23:19:17.403: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:18.404: INFO: Number of nodes with available pods: 2
Jan 15 23:19:18.404: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:19.405: INFO: Number of nodes with available pods: 2
Jan 15 23:19:19.405: INFO: Node b660f798-38a0-4e83-a501-5381799304ec is running more than one daemon pod
Jan 15 23:19:20.404: INFO: Number of nodes with available pods: 3
Jan 15 23:19:20.404: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-m7qdm, will wait for the garbage collector to delete the pods
Jan 15 23:19:20.469: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.315304ms
Jan 15 23:19:20.570: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.855106ms
Jan 15 23:19:54.774: INFO: Number of nodes with available pods: 0
Jan 15 23:19:54.774: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 23:19:54.777: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-m7qdm/daemonsets","resourceVersion":"25275"},"items":null}

Jan 15 23:19:54.780: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-m7qdm/pods","resourceVersion":"25275"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:19:54.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-m7qdm" for this suite.
Jan 15 23:20:00.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:20:00.903: INFO: namespace: e2e-tests-daemonsets-m7qdm, resource: bindings, ignored listing per whitelist
Jan 15 23:20:01.012: INFO: namespace e2e-tests-daemonsets-m7qdm deletion completed in 6.21516357s

• [SLOW TEST:86.887 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:20:01.014: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-k75s4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 15 23:20:01.232: INFO: Waiting up to 5m0s for pod "pod-14eb4b2e-191c-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-k75s4" to be "success or failure"
Jan 15 23:20:01.236: INFO: Pod "pod-14eb4b2e-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 3.763787ms
Jan 15 23:20:03.240: INFO: Pod "pod-14eb4b2e-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007339345s
Jan 15 23:20:05.244: INFO: Pod "pod-14eb4b2e-191c-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011722044s
STEP: Saw pod success
Jan 15 23:20:05.244: INFO: Pod "pod-14eb4b2e-191c-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:20:05.247: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-14eb4b2e-191c-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 23:20:05.270: INFO: Waiting for pod pod-14eb4b2e-191c-11e9-993a-025056003018 to disappear
Jan 15 23:20:05.274: INFO: Pod pod-14eb4b2e-191c-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:20:05.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-k75s4" for this suite.
Jan 15 23:20:11.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:20:11.328: INFO: namespace: e2e-tests-emptydir-k75s4, resource: bindings, ignored listing per whitelist
Jan 15 23:20:11.407: INFO: namespace e2e-tests-emptydir-k75s4 deletion completed in 6.123908313s

• [SLOW TEST:10.393 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:20:11.408: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wqs45
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 23:20:11.636: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-wqs45" to be "success or failure"
Jan 15 23:20:11.651: INFO: Pod "downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 15.787176ms
Jan 15 23:20:13.656: INFO: Pod "downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020688385s
Jan 15 23:20:15.660: INFO: Pod "downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024681899s
STEP: Saw pod success
Jan 15 23:20:15.660: INFO: Pod "downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:20:15.663: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 23:20:15.701: INFO: Waiting for pod downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018 to disappear
Jan 15 23:20:15.704: INFO: Pod downwardapi-volume-1b1cb462-191c-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:20:15.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wqs45" for this suite.
Jan 15 23:20:21.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:20:21.754: INFO: namespace: e2e-tests-downward-api-wqs45, resource: bindings, ignored listing per whitelist
Jan 15 23:20:21.844: INFO: namespace e2e-tests-downward-api-wqs45 deletion completed in 6.13282369s

• [SLOW TEST:10.436 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:20:21.845: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-69s4h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-69s4h.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-69s4h.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-69s4h.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-69s4h.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-69s4h.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-69s4h.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 15 23:20:36.328: INFO: DNS probes using e2e-tests-dns-69s4h/dns-test-21569127-191c-11e9-993a-025056003018 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:20:36.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-69s4h" for this suite.
Jan 15 23:20:42.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:20:42.478: INFO: namespace: e2e-tests-dns-69s4h, resource: bindings, ignored listing per whitelist
Jan 15 23:20:42.494: INFO: namespace e2e-tests-dns-69s4h deletion completed in 6.134867545s

• [SLOW TEST:20.650 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:20:42.496: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-l6lv8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2da54548-191c-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:20:42.727: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018" in namespace "e2e-tests-projected-l6lv8" to be "success or failure"
Jan 15 23:20:42.742: INFO: Pod "pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 14.384923ms
Jan 15 23:20:44.746: INFO: Pod "pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018246763s
Jan 15 23:20:46.750: INFO: Pod "pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02193301s
STEP: Saw pod success
Jan 15 23:20:46.750: INFO: Pod "pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:20:46.753: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 23:20:46.783: INFO: Waiting for pod pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018 to disappear
Jan 15 23:20:46.786: INFO: Pod pod-projected-configmaps-2da63732-191c-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:20:46.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l6lv8" for this suite.
Jan 15 23:20:52.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:20:52.871: INFO: namespace: e2e-tests-projected-l6lv8, resource: bindings, ignored listing per whitelist
Jan 15 23:20:52.906: INFO: namespace e2e-tests-projected-l6lv8 deletion completed in 6.116982117s

• [SLOW TEST:10.410 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:20:52.908: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5ddk5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-33daa49c-191c-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:20:53.151: INFO: Waiting up to 5m0s for pod "pod-secrets-33dbd883-191c-11e9-993a-025056003018" in namespace "e2e-tests-secrets-5ddk5" to be "success or failure"
Jan 15 23:20:53.181: INFO: Pod "pod-secrets-33dbd883-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 29.37428ms
Jan 15 23:20:55.193: INFO: Pod "pod-secrets-33dbd883-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04136901s
Jan 15 23:20:57.196: INFO: Pod "pod-secrets-33dbd883-191c-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045312281s
STEP: Saw pod success
Jan 15 23:20:57.197: INFO: Pod "pod-secrets-33dbd883-191c-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:20:57.201: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-33dbd883-191c-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:20:57.225: INFO: Waiting for pod pod-secrets-33dbd883-191c-11e9-993a-025056003018 to disappear
Jan 15 23:20:57.229: INFO: Pod pod-secrets-33dbd883-191c-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:20:57.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5ddk5" for this suite.
Jan 15 23:21:03.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:21:03.304: INFO: namespace: e2e-tests-secrets-5ddk5, resource: bindings, ignored listing per whitelist
Jan 15 23:21:03.363: INFO: namespace e2e-tests-secrets-5ddk5 deletion completed in 6.128975941s

• [SLOW TEST:10.455 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:21:03.364: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d5wxr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:21:03.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 version'
Jan 15 23:21:03.665: INFO: stderr: ""
Jan 15 23:21:03.665: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.4\", GitCommit:\"f49fa022dbe63faafd0da106ef7e05a29721d3f1\", GitTreeState:\"clean\", BuildDate:\"2018-12-14T06:59:37Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:21:03.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d5wxr" for this suite.
Jan 15 23:21:09.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:21:09.729: INFO: namespace: e2e-tests-kubectl-d5wxr, resource: bindings, ignored listing per whitelist
Jan 15 23:21:09.795: INFO: namespace e2e-tests-kubectl-d5wxr deletion completed in 6.122537775s

• [SLOW TEST:6.431 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:21:09.795: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-vnnms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vnnms
Jan 15 23:21:14.106: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vnnms
STEP: checking the pod's current state and verifying that restartCount is present
Jan 15 23:21:14.112: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:25:14.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vnnms" for this suite.
Jan 15 23:25:20.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:25:20.854: INFO: namespace: e2e-tests-container-probe-vnnms, resource: bindings, ignored listing per whitelist
Jan 15 23:25:20.861: INFO: namespace e2e-tests-container-probe-vnnms deletion completed in 6.116664349s

• [SLOW TEST:251.066 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:25:20.862: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-646wd
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:25:21.073: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:25:22.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-646wd" for this suite.
Jan 15 23:25:28.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:25:28.249: INFO: namespace: e2e-tests-custom-resource-definition-646wd, resource: bindings, ignored listing per whitelist
Jan 15 23:25:28.299: INFO: namespace e2e-tests-custom-resource-definition-646wd deletion completed in 6.123970903s

• [SLOW TEST:7.438 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:25:28.304: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-x48sk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 23:25:28.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-x48sk'
Jan 15 23:25:29.329: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 15 23:25:29.329: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Jan 15 23:25:29.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-x48sk'
Jan 15 23:25:29.510: INFO: stderr: ""
Jan 15 23:25:29.510: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:25:29.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x48sk" for this suite.
Jan 15 23:25:51.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:25:51.559: INFO: namespace: e2e-tests-kubectl-x48sk, resource: bindings, ignored listing per whitelist
Jan 15 23:25:51.624: INFO: namespace e2e-tests-kubectl-x48sk deletion completed in 22.108302756s

• [SLOW TEST:23.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:25:51.625: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8x5zv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 23:25:51.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-8x5zv'
Jan 15 23:25:51.999: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 15 23:25:51.999: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Jan 15 23:25:52.006: INFO: scanned /root for discovery docs: <nil>
Jan 15 23:25:52.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-8x5zv'
Jan 15 23:26:07.865: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 15 23:26:07.865: INFO: stdout: "Created e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52\nScaling up e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 15 23:26:07.865: INFO: stdout: "Created e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52\nScaling up e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 15 23:26:07.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8x5zv'
Jan 15 23:26:07.955: INFO: stderr: ""
Jan 15 23:26:07.955: INFO: stdout: "e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52-5dr2h "
Jan 15 23:26:07.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52-5dr2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8x5zv'
Jan 15 23:26:08.059: INFO: stderr: ""
Jan 15 23:26:08.059: INFO: stdout: "true"
Jan 15 23:26:08.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52-5dr2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8x5zv'
Jan 15 23:26:08.160: INFO: stderr: ""
Jan 15 23:26:08.160: INFO: stdout: "nginx:1.14-alpine"
Jan 15 23:26:08.160: INFO: e2e-test-nginx-rc-021b68ca141d15b1cfab47bef7f2ed52-5dr2h is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Jan 15 23:26:08.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-8x5zv'
Jan 15 23:26:08.301: INFO: stderr: ""
Jan 15 23:26:08.302: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:26:08.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8x5zv" for this suite.
Jan 15 23:26:30.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:26:30.345: INFO: namespace: e2e-tests-kubectl-8x5zv, resource: bindings, ignored listing per whitelist
Jan 15 23:26:30.424: INFO: namespace e2e-tests-kubectl-8x5zv deletion completed in 22.11735197s

• [SLOW TEST:38.800 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:26:30.427: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-bc54f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 15 23:26:30.660: INFO: Waiting up to 5m0s for pod "var-expansion-fd08d1d4-191c-11e9-993a-025056003018" in namespace "e2e-tests-var-expansion-bc54f" to be "success or failure"
Jan 15 23:26:30.665: INFO: Pod "var-expansion-fd08d1d4-191c-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.837271ms
Jan 15 23:26:32.670: INFO: Pod "var-expansion-fd08d1d4-191c-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00945329s
STEP: Saw pod success
Jan 15 23:26:32.670: INFO: Pod "var-expansion-fd08d1d4-191c-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:26:32.672: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod var-expansion-fd08d1d4-191c-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 23:26:32.702: INFO: Waiting for pod var-expansion-fd08d1d4-191c-11e9-993a-025056003018 to disappear
Jan 15 23:26:32.710: INFO: Pod var-expansion-fd08d1d4-191c-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:26:32.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bc54f" for this suite.
Jan 15 23:26:38.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:26:38.755: INFO: namespace: e2e-tests-var-expansion-bc54f, resource: bindings, ignored listing per whitelist
Jan 15 23:26:38.864: INFO: namespace e2e-tests-var-expansion-bc54f deletion completed in 6.148717363s

• [SLOW TEST:8.437 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:26:38.864: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-r22j2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:26:39.110: INFO: (0) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.711259ms)
Jan 15 23:26:39.118: INFO: (1) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.31027ms)
Jan 15 23:26:39.122: INFO: (2) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.804887ms)
Jan 15 23:26:39.131: INFO: (3) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.994863ms)
Jan 15 23:26:39.135: INFO: (4) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.159283ms)
Jan 15 23:26:39.139: INFO: (5) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.071437ms)
Jan 15 23:26:39.147: INFO: (6) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.968698ms)
Jan 15 23:26:39.154: INFO: (7) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.110202ms)
Jan 15 23:26:39.165: INFO: (8) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 10.423221ms)
Jan 15 23:26:39.174: INFO: (9) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.1115ms)
Jan 15 23:26:39.179: INFO: (10) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.880433ms)
Jan 15 23:26:39.183: INFO: (11) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.435865ms)
Jan 15 23:26:39.187: INFO: (12) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.996975ms)
Jan 15 23:26:39.191: INFO: (13) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.922538ms)
Jan 15 23:26:39.195: INFO: (14) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.434669ms)
Jan 15 23:26:39.199: INFO: (15) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.898607ms)
Jan 15 23:26:39.203: INFO: (16) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.127133ms)
Jan 15 23:26:39.206: INFO: (17) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.999186ms)
Jan 15 23:26:39.209: INFO: (18) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.051669ms)
Jan 15 23:26:39.212: INFO: (19) /api/v1/nodes/16f34f29-58df-43ef-838e-06a19f186c15/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.071635ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:26:39.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-r22j2" for this suite.
Jan 15 23:26:45.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:26:45.280: INFO: namespace: e2e-tests-proxy-r22j2, resource: bindings, ignored listing per whitelist
Jan 15 23:26:45.313: INFO: namespace e2e-tests-proxy-r22j2 deletion completed in 6.097645259s

• [SLOW TEST:6.449 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:26:45.316: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-pjkzf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 15 23:26:45.511: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:26:49.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pjkzf" for this suite.
Jan 15 23:27:11.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:27:11.776: INFO: namespace: e2e-tests-init-container-pjkzf, resource: bindings, ignored listing per whitelist
Jan 15 23:27:11.846: INFO: namespace e2e-tests-init-container-pjkzf deletion completed in 22.110186326s

• [SLOW TEST:26.530 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:27:11.847: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-87zq8
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 15 23:27:12.070: INFO: Waiting up to 5m0s for pod "pod-15b6f780-191d-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-87zq8" to be "success or failure"
Jan 15 23:27:12.084: INFO: Pod "pod-15b6f780-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 13.953399ms
Jan 15 23:27:14.089: INFO: Pod "pod-15b6f780-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018688694s
Jan 15 23:27:16.092: INFO: Pod "pod-15b6f780-191d-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02226051s
STEP: Saw pod success
Jan 15 23:27:16.092: INFO: Pod "pod-15b6f780-191d-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:27:16.095: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-15b6f780-191d-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 23:27:16.120: INFO: Waiting for pod pod-15b6f780-191d-11e9-993a-025056003018 to disappear
Jan 15 23:27:16.125: INFO: Pod pod-15b6f780-191d-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:27:16.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-87zq8" for this suite.
Jan 15 23:27:22.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:27:22.270: INFO: namespace: e2e-tests-emptydir-87zq8, resource: bindings, ignored listing per whitelist
Jan 15 23:27:22.304: INFO: namespace e2e-tests-emptydir-87zq8 deletion completed in 6.17448195s

• [SLOW TEST:10.457 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:27:22.308: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-gfswp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 15 23:27:22.569: INFO: Number of nodes with available pods: 0
Jan 15 23:27:22.569: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:27:23.583: INFO: Number of nodes with available pods: 0
Jan 15 23:27:23.583: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:27:24.582: INFO: Number of nodes with available pods: 1
Jan 15 23:27:24.582: INFO: Node 16f34f29-58df-43ef-838e-06a19f186c15 is running more than one daemon pod
Jan 15 23:27:25.579: INFO: Number of nodes with available pods: 3
Jan 15 23:27:25.579: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 15 23:27:25.613: INFO: Number of nodes with available pods: 3
Jan 15 23:27:25.614: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-gfswp, will wait for the garbage collector to delete the pods
Jan 15 23:27:26.699: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.33531ms
Jan 15 23:27:26.799: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.279207ms
Jan 15 23:28:06.203: INFO: Number of nodes with available pods: 0
Jan 15 23:28:06.203: INFO: Number of running nodes: 0, number of available pods: 0
Jan 15 23:28:06.205: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gfswp/daemonsets","resourceVersion":"26535"},"items":null}

Jan 15 23:28:06.208: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gfswp/pods","resourceVersion":"26535"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:28:06.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gfswp" for this suite.
Jan 15 23:28:12.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:28:12.306: INFO: namespace: e2e-tests-daemonsets-gfswp, resource: bindings, ignored listing per whitelist
Jan 15 23:28:12.327: INFO: namespace e2e-tests-daemonsets-gfswp deletion completed in 6.101492924s

• [SLOW TEST:50.019 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:28:12.329: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hnxqr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 23:28:12.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hnxqr'
Jan 15 23:28:12.655: INFO: stderr: ""
Jan 15 23:28:12.655: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Jan 15 23:28:12.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-hnxqr'
Jan 15 23:28:16.193: INFO: stderr: ""
Jan 15 23:28:16.193: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:28:16.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hnxqr" for this suite.
Jan 15 23:28:22.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:28:22.285: INFO: namespace: e2e-tests-kubectl-hnxqr, resource: bindings, ignored listing per whitelist
Jan 15 23:28:22.320: INFO: namespace e2e-tests-kubectl-hnxqr deletion completed in 6.11788161s

• [SLOW TEST:9.992 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:28:22.321: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wkwcd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 23:28:22.528: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3fb64307-191d-11e9-993a-025056003018" in namespace "e2e-tests-projected-wkwcd" to be "success or failure"
Jan 15 23:28:22.557: INFO: Pod "downwardapi-volume-3fb64307-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 28.302883ms
Jan 15 23:28:24.561: INFO: Pod "downwardapi-volume-3fb64307-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033033234s
Jan 15 23:28:26.566: INFO: Pod "downwardapi-volume-3fb64307-191d-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03819895s
STEP: Saw pod success
Jan 15 23:28:26.567: INFO: Pod "downwardapi-volume-3fb64307-191d-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:28:26.569: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-3fb64307-191d-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 23:28:26.603: INFO: Waiting for pod downwardapi-volume-3fb64307-191d-11e9-993a-025056003018 to disappear
Jan 15 23:28:26.606: INFO: Pod downwardapi-volume-3fb64307-191d-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:28:26.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wkwcd" for this suite.
Jan 15 23:28:32.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:28:32.679: INFO: namespace: e2e-tests-projected-wkwcd, resource: bindings, ignored listing per whitelist
Jan 15 23:28:32.714: INFO: namespace e2e-tests-projected-wkwcd deletion completed in 6.103823683s

• [SLOW TEST:10.393 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:28:32.715: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-d6tfm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:28:32.940: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 15 23:28:37.944: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 23:28:37.944: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 23:28:37.966: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-d6tfm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d6tfm/deployments/test-cleanup-deployment,UID:48e930a7-191d-11e9-8273-005056af1926,ResourceVersion:26677,Generation:1,CreationTimestamp:2019-01-15 23:28:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 15 23:28:37.970: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan 15 23:28:37.970: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 15 23:28:37.971: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-d6tfm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-d6tfm/replicasets/test-cleanup-controller,UID:45eb55bb-191d-11e9-8273-005056af1926,ResourceVersion:26678,Generation:1,CreationTimestamp:2019-01-15 23:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 48e930a7-191d-11e9-8273-005056af1926 0xc422aa2437 0xc422aa2438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 23:28:37.976: INFO: Pod "test-cleanup-controller-7gxwt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-7gxwt,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-d6tfm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-d6tfm/pods/test-cleanup-controller-7gxwt,UID:45ee43b7-191d-11e9-8273-005056af1926,ResourceVersion:26671,Generation:0,CreationTimestamp:2019-01-15 23:28:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 45eb55bb-191d-11e9-8273-005056af1926 0xc422aa2d57 0xc422aa2d58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4v7wv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4v7wv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4v7wv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422aa2dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422aa2de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:28:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:28:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:28:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:28:32 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.9.2,StartTime:2019-01-15 23:28:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:28:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://27021ecb59fdf22b98d596be2f019e78b17209fe7f0ea3995b5bacfb49d08943}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:28:37.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-d6tfm" for this suite.
Jan 15 23:28:44.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:28:44.105: INFO: namespace: e2e-tests-deployment-d6tfm, resource: bindings, ignored listing per whitelist
Jan 15 23:28:44.203: INFO: namespace e2e-tests-deployment-d6tfm deletion completed in 6.183351414s

• [SLOW TEST:11.489 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:28:44.206: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jpjcr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 23:28:44.447: INFO: Waiting up to 5m0s for pod "downward-api-4cc6c13c-191d-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-jpjcr" to be "success or failure"
Jan 15 23:28:44.479: INFO: Pod "downward-api-4cc6c13c-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 32.516221ms
Jan 15 23:28:46.483: INFO: Pod "downward-api-4cc6c13c-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036776689s
Jan 15 23:28:48.487: INFO: Pod "downward-api-4cc6c13c-191d-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040210029s
STEP: Saw pod success
Jan 15 23:28:48.487: INFO: Pod "downward-api-4cc6c13c-191d-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:28:48.490: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downward-api-4cc6c13c-191d-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 23:28:48.521: INFO: Waiting for pod downward-api-4cc6c13c-191d-11e9-993a-025056003018 to disappear
Jan 15 23:28:48.525: INFO: Pod downward-api-4cc6c13c-191d-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:28:48.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jpjcr" for this suite.
Jan 15 23:28:54.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:28:54.626: INFO: namespace: e2e-tests-downward-api-jpjcr, resource: bindings, ignored listing per whitelist
Jan 15 23:28:54.636: INFO: namespace e2e-tests-downward-api-jpjcr deletion completed in 6.105433399s

• [SLOW TEST:10.430 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:28:54.638: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-s7m28
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:28:54.897: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"52fff51e-191d-11e9-8273-005056af1926", Controller:(*bool)(0xc420f25e82), BlockOwnerDeletion:(*bool)(0xc420f25e83)}}
Jan 15 23:28:54.967: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"52f8e469-191d-11e9-8273-005056af1926", Controller:(*bool)(0xc421cba4e2), BlockOwnerDeletion:(*bool)(0xc421cba4e3)}}
Jan 15 23:28:54.973: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"52fa2117-191d-11e9-8273-005056af1926", Controller:(*bool)(0xc421cbab16), BlockOwnerDeletion:(*bool)(0xc421cbab17)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:28:59.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-s7m28" for this suite.
Jan 15 23:29:06.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:29:06.093: INFO: namespace: e2e-tests-gc-s7m28, resource: bindings, ignored listing per whitelist
Jan 15 23:29:06.158: INFO: namespace e2e-tests-gc-s7m28 deletion completed in 6.160567397s

• [SLOW TEST:11.520 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:29:06.158: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-bj9wd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 15 23:29:06.373: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26835,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 23:29:06.373: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26835,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 15 23:29:16.383: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26850,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 15 23:29:16.383: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26850,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 15 23:29:26.398: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26865,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 23:29:26.399: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26865,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 15 23:29:36.406: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26879,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 23:29:36.406: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-a,UID:59d9c5b0-191d-11e9-8273-005056af1926,ResourceVersion:26879,Generation:0,CreationTimestamp:2019-01-15 23:29:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 15 23:29:46.414: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-b,UID:71b726ff-191d-11e9-8273-005056af1926,ResourceVersion:26894,Generation:0,CreationTimestamp:2019-01-15 23:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 23:29:46.414: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-b,UID:71b726ff-191d-11e9-8273-005056af1926,ResourceVersion:26894,Generation:0,CreationTimestamp:2019-01-15 23:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 15 23:29:56.420: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-b,UID:71b726ff-191d-11e9-8273-005056af1926,ResourceVersion:26909,Generation:0,CreationTimestamp:2019-01-15 23:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 23:29:56.420: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-bj9wd,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj9wd/configmaps/e2e-watch-test-configmap-b,UID:71b726ff-191d-11e9-8273-005056af1926,ResourceVersion:26909,Generation:0,CreationTimestamp:2019-01-15 23:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:30:06.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bj9wd" for this suite.
Jan 15 23:30:12.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:30:12.487: INFO: namespace: e2e-tests-watch-bj9wd, resource: bindings, ignored listing per whitelist
Jan 15 23:30:12.546: INFO: namespace e2e-tests-watch-bj9wd deletion completed in 6.118337612s

• [SLOW TEST:66.388 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:30:12.549: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6gd7v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8170bbe1-191d-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:30:12.809: INFO: Waiting up to 5m0s for pod "pod-secrets-81717f44-191d-11e9-993a-025056003018" in namespace "e2e-tests-secrets-6gd7v" to be "success or failure"
Jan 15 23:30:12.826: INFO: Pod "pod-secrets-81717f44-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 16.769191ms
Jan 15 23:30:14.831: INFO: Pod "pod-secrets-81717f44-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02219205s
Jan 15 23:30:16.846: INFO: Pod "pod-secrets-81717f44-191d-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037586057s
STEP: Saw pod success
Jan 15 23:30:16.847: INFO: Pod "pod-secrets-81717f44-191d-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:30:16.850: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-81717f44-191d-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:30:16.875: INFO: Waiting for pod pod-secrets-81717f44-191d-11e9-993a-025056003018 to disappear
Jan 15 23:30:16.879: INFO: Pod pod-secrets-81717f44-191d-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:30:16.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6gd7v" for this suite.
Jan 15 23:30:22.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:30:22.910: INFO: namespace: e2e-tests-secrets-6gd7v, resource: bindings, ignored listing per whitelist
Jan 15 23:30:22.984: INFO: namespace e2e-tests-secrets-6gd7v deletion completed in 6.09974267s

• [SLOW TEST:10.435 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:30:22.985: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-nhvfr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-nhvfr
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-nhvfr
STEP: Deleting pre-stop pod
Jan 15 23:30:40.256: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:30:40.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-nhvfr" for this suite.
Jan 15 23:31:18.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:31:18.360: INFO: namespace: e2e-tests-prestop-nhvfr, resource: bindings, ignored listing per whitelist
Jan 15 23:31:18.384: INFO: namespace e2e-tests-prestop-nhvfr deletion completed in 38.114675182s

• [SLOW TEST:55.399 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:31:18.384: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8hjqm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 23:31:18.582: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8a68250-191d-11e9-993a-025056003018" in namespace "e2e-tests-projected-8hjqm" to be "success or failure"
Jan 15 23:31:18.593: INFO: Pod "downwardapi-volume-a8a68250-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 10.692031ms
Jan 15 23:31:20.599: INFO: Pod "downwardapi-volume-a8a68250-191d-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016993993s
Jan 15 23:31:22.603: INFO: Pod "downwardapi-volume-a8a68250-191d-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020947952s
STEP: Saw pod success
Jan 15 23:31:22.603: INFO: Pod "downwardapi-volume-a8a68250-191d-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:31:22.606: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-a8a68250-191d-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 23:31:22.629: INFO: Waiting for pod downwardapi-volume-a8a68250-191d-11e9-993a-025056003018 to disappear
Jan 15 23:31:22.634: INFO: Pod downwardapi-volume-a8a68250-191d-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:31:22.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8hjqm" for this suite.
Jan 15 23:31:28.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:31:28.754: INFO: namespace: e2e-tests-projected-8hjqm, resource: bindings, ignored listing per whitelist
Jan 15 23:31:28.760: INFO: namespace e2e-tests-projected-8hjqm deletion completed in 6.121182959s

• [SLOW TEST:10.376 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:31:28.761: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rtsdh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 23:31:28.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-rtsdh'
Jan 15 23:31:29.118: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 15 23:31:29.118: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Jan 15 23:31:31.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-rtsdh'
Jan 15 23:31:31.239: INFO: stderr: ""
Jan 15 23:31:31.239: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:31:31.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rtsdh" for this suite.
Jan 15 23:31:37.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:31:37.331: INFO: namespace: e2e-tests-kubectl-rtsdh, resource: bindings, ignored listing per whitelist
Jan 15 23:31:37.381: INFO: namespace e2e-tests-kubectl-rtsdh deletion completed in 6.13570518s

• [SLOW TEST:8.620 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:31:37.383: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-lccrb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-nt5gz in namespace e2e-tests-proxy-lccrb
I0115 23:31:37.643583      15 runners.go:180] Created replication controller with name: proxy-service-nt5gz, namespace: e2e-tests-proxy-lccrb, replica count: 1
I0115 23:31:38.694011      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 23:31:39.694281      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 23:31:40.694463      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 23:31:41.695250      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0115 23:31:42.695566      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 23:31:43.696009      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 23:31:44.696429      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 23:31:45.696741      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 23:31:46.696970      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0115 23:31:47.697226      15 runners.go:180] proxy-service-nt5gz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 15 23:31:47.701: INFO: setup took 10.078939937s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 15 23:31:47.712: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 10.758018ms)
Jan 15 23:31:47.724: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 22.439279ms)
Jan 15 23:31:47.729: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 27.11522ms)
Jan 15 23:31:47.729: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 27.196369ms)
Jan 15 23:31:47.729: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 27.067652ms)
Jan 15 23:31:47.729: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 27.361115ms)
Jan 15 23:31:47.729: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 27.392654ms)
Jan 15 23:31:47.730: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 27.697178ms)
Jan 15 23:31:47.731: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 29.016052ms)
Jan 15 23:31:47.731: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 28.738264ms)
Jan 15 23:31:47.731: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 28.545661ms)
Jan 15 23:31:47.732: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 29.606711ms)
Jan 15 23:31:47.733: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 31.005189ms)
Jan 15 23:31:47.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 33.026229ms)
Jan 15 23:31:47.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 33.041595ms)
Jan 15 23:31:47.738: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 36.434727ms)
Jan 15 23:31:47.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 17.221661ms)
Jan 15 23:31:47.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 17.581994ms)
Jan 15 23:31:47.756: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 17.770691ms)
Jan 15 23:31:47.757: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 18.838671ms)
Jan 15 23:31:47.757: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 18.564207ms)
Jan 15 23:31:47.758: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 18.910882ms)
Jan 15 23:31:47.758: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 18.946893ms)
Jan 15 23:31:47.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 19.68957ms)
Jan 15 23:31:47.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 19.902436ms)
Jan 15 23:31:47.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 19.735786ms)
Jan 15 23:31:47.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 19.772737ms)
Jan 15 23:31:47.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 20.009431ms)
Jan 15 23:31:47.759: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 20.704101ms)
Jan 15 23:31:47.760: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 21.206895ms)
Jan 15 23:31:47.761: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 22.178638ms)
Jan 15 23:31:47.761: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 22.438304ms)
Jan 15 23:31:47.776: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 13.671882ms)
Jan 15 23:31:47.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 14.688032ms)
Jan 15 23:31:47.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 14.45847ms)
Jan 15 23:31:47.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 15.106611ms)
Jan 15 23:31:47.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 15.100914ms)
Jan 15 23:31:47.777: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 15.597822ms)
Jan 15 23:31:47.778: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 14.830653ms)
Jan 15 23:31:47.778: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 15.073672ms)
Jan 15 23:31:47.786: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 22.317546ms)
Jan 15 23:31:47.786: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 23.183006ms)
Jan 15 23:31:47.786: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 23.317212ms)
Jan 15 23:31:47.786: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 24.765705ms)
Jan 15 23:31:47.786: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 23.54959ms)
Jan 15 23:31:47.787: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 24.376044ms)
Jan 15 23:31:47.787: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 24.18786ms)
Jan 15 23:31:47.787: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 24.311318ms)
Jan 15 23:31:47.798: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 10.355163ms)
Jan 15 23:31:47.801: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 13.366124ms)
Jan 15 23:31:47.801: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 13.062777ms)
Jan 15 23:31:47.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 13.803528ms)
Jan 15 23:31:47.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 13.748982ms)
Jan 15 23:31:47.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 14.018295ms)
Jan 15 23:31:47.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 13.975317ms)
Jan 15 23:31:47.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 14.304431ms)
Jan 15 23:31:47.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 14.766121ms)
Jan 15 23:31:47.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 15.240362ms)
Jan 15 23:31:47.804: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 15.905805ms)
Jan 15 23:31:47.805: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 17.480675ms)
Jan 15 23:31:47.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 20.76449ms)
Jan 15 23:31:47.809: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 21.602659ms)
Jan 15 23:31:47.811: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 22.762202ms)
Jan 15 23:31:47.812: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 24.106874ms)
Jan 15 23:31:47.819: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 7.204989ms)
Jan 15 23:31:47.826: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 13.233068ms)
Jan 15 23:31:47.827: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 13.517364ms)
Jan 15 23:31:47.829: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 16.612607ms)
Jan 15 23:31:47.831: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 18.22141ms)
Jan 15 23:31:47.831: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 18.108603ms)
Jan 15 23:31:47.833: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 20.648316ms)
Jan 15 23:31:47.834: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 20.556519ms)
Jan 15 23:31:47.834: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 21.031667ms)
Jan 15 23:31:47.835: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 22.15416ms)
Jan 15 23:31:47.835: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 22.358846ms)
Jan 15 23:31:47.837: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 24.970966ms)
Jan 15 23:31:47.838: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 26.298854ms)
Jan 15 23:31:47.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 26.513241ms)
Jan 15 23:31:47.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 26.080093ms)
Jan 15 23:31:47.845: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 32.568729ms)
Jan 15 23:31:47.857: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 11.733791ms)
Jan 15 23:31:47.858: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 11.897856ms)
Jan 15 23:31:47.859: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 11.880126ms)
Jan 15 23:31:47.859: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 13.677321ms)
Jan 15 23:31:47.859: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 13.756101ms)
Jan 15 23:31:47.860: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 14.898355ms)
Jan 15 23:31:47.860: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 14.359135ms)
Jan 15 23:31:47.860: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 13.508054ms)
Jan 15 23:31:47.860: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 15.029176ms)
Jan 15 23:31:47.860: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 14.945412ms)
Jan 15 23:31:47.863: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 16.180094ms)
Jan 15 23:31:47.863: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 18.246478ms)
Jan 15 23:31:47.864: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 17.110382ms)
Jan 15 23:31:47.864: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 17.354862ms)
Jan 15 23:31:47.864: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 18.182152ms)
Jan 15 23:31:47.864: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 18.665354ms)
Jan 15 23:31:47.871: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 7.061323ms)
Jan 15 23:31:47.879: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 13.639683ms)
Jan 15 23:31:47.881: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 16.312384ms)
Jan 15 23:31:47.881: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 16.788401ms)
Jan 15 23:31:47.881: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 16.67754ms)
Jan 15 23:31:47.881: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 16.857668ms)
Jan 15 23:31:47.881: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 16.759892ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 16.27439ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 17.066508ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 16.790867ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 17.073375ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 17.299066ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 17.359255ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 17.115301ms)
Jan 15 23:31:47.882: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 17.864653ms)
Jan 15 23:31:47.883: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 17.831041ms)
Jan 15 23:31:47.895: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 11.063893ms)
Jan 15 23:31:47.897: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 12.944746ms)
Jan 15 23:31:47.897: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 14.204185ms)
Jan 15 23:31:47.898: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 13.656682ms)
Jan 15 23:31:47.899: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 15.708761ms)
Jan 15 23:31:47.900: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 15.230846ms)
Jan 15 23:31:47.900: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 17.339237ms)
Jan 15 23:31:47.900: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 16.649516ms)
Jan 15 23:31:47.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 17.52761ms)
Jan 15 23:31:47.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 17.569176ms)
Jan 15 23:31:47.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 17.68698ms)
Jan 15 23:31:47.901: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 17.661925ms)
Jan 15 23:31:47.902: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 17.943285ms)
Jan 15 23:31:47.902: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 19.319631ms)
Jan 15 23:31:47.902: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 18.309884ms)
Jan 15 23:31:47.903: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 18.884302ms)
Jan 15 23:31:47.910: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 7.00621ms)
Jan 15 23:31:47.915: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 10.15329ms)
Jan 15 23:31:47.915: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 10.074239ms)
Jan 15 23:31:47.916: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 12.258712ms)
Jan 15 23:31:47.917: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 12.99476ms)
Jan 15 23:31:47.917: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 12.488656ms)
Jan 15 23:31:47.918: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 12.471196ms)
Jan 15 23:31:47.918: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 14.218291ms)
Jan 15 23:31:47.918: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 12.210998ms)
Jan 15 23:31:47.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 14.477689ms)
Jan 15 23:31:47.921: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 15.771166ms)
Jan 15 23:31:47.922: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 16.369986ms)
Jan 15 23:31:47.924: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 20.319352ms)
Jan 15 23:31:47.924: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 20.898356ms)
Jan 15 23:31:47.924: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 18.971398ms)
Jan 15 23:31:47.925: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 18.76851ms)
Jan 15 23:31:47.930: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 4.91341ms)
Jan 15 23:31:47.930: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 4.966595ms)
Jan 15 23:31:47.937: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 11.875649ms)
Jan 15 23:31:47.937: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 12.647395ms)
Jan 15 23:31:47.938: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 12.223385ms)
Jan 15 23:31:47.938: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 12.436921ms)
Jan 15 23:31:47.940: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 15.11393ms)
Jan 15 23:31:47.941: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 15.436124ms)
Jan 15 23:31:47.941: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 15.643268ms)
Jan 15 23:31:47.941: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 15.918597ms)
Jan 15 23:31:47.941: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 15.883632ms)
Jan 15 23:31:47.942: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 16.46761ms)
Jan 15 23:31:47.942: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 16.708303ms)
Jan 15 23:31:47.943: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 17.58187ms)
Jan 15 23:31:47.952: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 26.889343ms)
Jan 15 23:31:47.952: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 26.875823ms)
Jan 15 23:31:47.960: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 7.014465ms)
Jan 15 23:31:47.960: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 6.863862ms)
Jan 15 23:31:47.964: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 10.815896ms)
Jan 15 23:31:47.967: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 13.748033ms)
Jan 15 23:31:47.968: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 14.274697ms)
Jan 15 23:31:47.968: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 14.189274ms)
Jan 15 23:31:47.968: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 14.806183ms)
Jan 15 23:31:47.969: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 15.86988ms)
Jan 15 23:31:47.969: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 16.011107ms)
Jan 15 23:31:47.969: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 15.878911ms)
Jan 15 23:31:47.970: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 16.557192ms)
Jan 15 23:31:47.970: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 16.465202ms)
Jan 15 23:31:47.970: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 17.847911ms)
Jan 15 23:31:47.975: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 21.523689ms)
Jan 15 23:31:47.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 22.235596ms)
Jan 15 23:31:47.976: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 22.696741ms)
Jan 15 23:31:47.984: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 7.216761ms)
Jan 15 23:31:47.990: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 12.345372ms)
Jan 15 23:31:47.993: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 15.020943ms)
Jan 15 23:31:47.993: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 15.423453ms)
Jan 15 23:31:47.993: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 16.324267ms)
Jan 15 23:31:47.996: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 18.134886ms)
Jan 15 23:31:47.996: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 19.456881ms)
Jan 15 23:31:47.998: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 21.683027ms)
Jan 15 23:31:47.999: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 21.250182ms)
Jan 15 23:31:47.999: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 22.287663ms)
Jan 15 23:31:48.001: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 23.58026ms)
Jan 15 23:31:48.002: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 24.724234ms)
Jan 15 23:31:48.002: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 24.730214ms)
Jan 15 23:31:48.003: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 26.385949ms)
Jan 15 23:31:48.003: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 25.765592ms)
Jan 15 23:31:48.003: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 25.873196ms)
Jan 15 23:31:48.010: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 5.747259ms)
Jan 15 23:31:48.010: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 5.871124ms)
Jan 15 23:31:48.010: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 6.177659ms)
Jan 15 23:31:48.016: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 11.552296ms)
Jan 15 23:31:48.017: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 12.636172ms)
Jan 15 23:31:48.017: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 12.411139ms)
Jan 15 23:31:48.017: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 12.874973ms)
Jan 15 23:31:48.017: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 13.191519ms)
Jan 15 23:31:48.019: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 14.751912ms)
Jan 15 23:31:48.020: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 15.490399ms)
Jan 15 23:31:48.023: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 18.899074ms)
Jan 15 23:31:48.027: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 22.745595ms)
Jan 15 23:31:48.029: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 24.649816ms)
Jan 15 23:31:48.029: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 24.857068ms)
Jan 15 23:31:48.029: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 25.158751ms)
Jan 15 23:31:48.030: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 25.288274ms)
Jan 15 23:31:48.047: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 16.813382ms)
Jan 15 23:31:48.047: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 16.948385ms)
Jan 15 23:31:48.053: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 23.11187ms)
Jan 15 23:31:48.057: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 27.043083ms)
Jan 15 23:31:48.059: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 28.392341ms)
Jan 15 23:31:48.059: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 28.611921ms)
Jan 15 23:31:48.059: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 28.688481ms)
Jan 15 23:31:48.059: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 28.875893ms)
Jan 15 23:31:48.060: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 29.878409ms)
Jan 15 23:31:48.060: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 29.44644ms)
Jan 15 23:31:48.062: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 31.314337ms)
Jan 15 23:31:48.062: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 31.528623ms)
Jan 15 23:31:48.062: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 31.444714ms)
Jan 15 23:31:48.062: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 31.915611ms)
Jan 15 23:31:48.062: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 31.802251ms)
Jan 15 23:31:48.062: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 32.212628ms)
Jan 15 23:31:48.069: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 6.108866ms)
Jan 15 23:31:48.072: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 9.142626ms)
Jan 15 23:31:48.075: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 12.194752ms)
Jan 15 23:31:48.078: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 14.811393ms)
Jan 15 23:31:48.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 18.448908ms)
Jan 15 23:31:48.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 18.407516ms)
Jan 15 23:31:48.081: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 18.434729ms)
Jan 15 23:31:48.082: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 19.326506ms)
Jan 15 23:31:48.084: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 20.661791ms)
Jan 15 23:31:48.084: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 21.077925ms)
Jan 15 23:31:48.085: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 22.246619ms)
Jan 15 23:31:48.086: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 23.038749ms)
Jan 15 23:31:48.087: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 24.228746ms)
Jan 15 23:31:48.087: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 23.17459ms)
Jan 15 23:31:48.087: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 23.820826ms)
Jan 15 23:31:48.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 24.771814ms)
Jan 15 23:31:48.096: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 8.110758ms)
Jan 15 23:31:48.110: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 22.349699ms)
Jan 15 23:31:48.111: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 23.24257ms)
Jan 15 23:31:48.113: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 25.287201ms)
Jan 15 23:31:48.113: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 25.109544ms)
Jan 15 23:31:48.113: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 25.033075ms)
Jan 15 23:31:48.113: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 25.106264ms)
Jan 15 23:31:48.113: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 25.23661ms)
Jan 15 23:31:48.113: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 25.089984ms)
Jan 15 23:31:48.114: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 25.898983ms)
Jan 15 23:31:48.114: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 26.293893ms)
Jan 15 23:31:48.115: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 26.699773ms)
Jan 15 23:31:48.115: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 26.949198ms)
Jan 15 23:31:48.115: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 27.499073ms)
Jan 15 23:31:48.116: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 28.348738ms)
Jan 15 23:31:48.116: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 28.303142ms)
Jan 15 23:31:48.127: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 9.911096ms)
Jan 15 23:31:48.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 11.398493ms)
Jan 15 23:31:48.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 10.946092ms)
Jan 15 23:31:48.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 10.925945ms)
Jan 15 23:31:48.128: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 11.113965ms)
Jan 15 23:31:48.131: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 13.772269ms)
Jan 15 23:31:48.132: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 14.916313ms)
Jan 15 23:31:48.132: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 15.652699ms)
Jan 15 23:31:48.137: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 19.76387ms)
Jan 15 23:31:48.137: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 21.087223ms)
Jan 15 23:31:48.138: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 21.382641ms)
Jan 15 23:31:48.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 21.42481ms)
Jan 15 23:31:48.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 22.790514ms)
Jan 15 23:31:48.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 21.586675ms)
Jan 15 23:31:48.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 22.444815ms)
Jan 15 23:31:48.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 22.686657ms)
Jan 15 23:31:48.148: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 7.586366ms)
Jan 15 23:31:48.149: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 7.83439ms)
Jan 15 23:31:48.150: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 9.301352ms)
Jan 15 23:31:48.151: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 9.552993ms)
Jan 15 23:31:48.151: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 9.334763ms)
Jan 15 23:31:48.154: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 12.895872ms)
Jan 15 23:31:48.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 16.511346ms)
Jan 15 23:31:48.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 17.111611ms)
Jan 15 23:31:48.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 17.116946ms)
Jan 15 23:31:48.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 17.735768ms)
Jan 15 23:31:48.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 16.445484ms)
Jan 15 23:31:48.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 17.203998ms)
Jan 15 23:31:48.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 17.097309ms)
Jan 15 23:31:48.159: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 17.160656ms)
Jan 15 23:31:48.159: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 17.474953ms)
Jan 15 23:31:48.159: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 17.23545ms)
Jan 15 23:31:48.166: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 6.418543ms)
Jan 15 23:31:48.172: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 12.367708ms)
Jan 15 23:31:48.180: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 21.087889ms)
Jan 15 23:31:48.180: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 21.072788ms)
Jan 15 23:31:48.186: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 26.830443ms)
Jan 15 23:31:48.201: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 40.771305ms)
Jan 15 23:31:48.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 44.1745ms)
Jan 15 23:31:48.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 44.570021ms)
Jan 15 23:31:48.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 44.581636ms)
Jan 15 23:31:48.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 43.852005ms)
Jan 15 23:31:48.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 44.255242ms)
Jan 15 23:31:48.204: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 44.640124ms)
Jan 15 23:31:48.205: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 44.59118ms)
Jan 15 23:31:48.205: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 44.935672ms)
Jan 15 23:31:48.205: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 45.42729ms)
Jan 15 23:31:48.205: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 45.652779ms)
Jan 15 23:31:48.212: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:162/proxy/: bar (200; 5.878245ms)
Jan 15 23:31:48.213: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:162/proxy/: bar (200; 7.754601ms)
Jan 15 23:31:48.220: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:443/proxy/... (200; 13.561419ms)
Jan 15 23:31:48.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:462/proxy/: tls qux (200; 15.387803ms)
Jan 15 23:31:48.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname2/proxy/: bar (200; 15.536355ms)
Jan 15 23:31:48.221: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646/proxy/rewriteme"... (200; 15.389209ms)
Jan 15 23:31:48.223: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:1080/proxy/rewri... (200; 17.060736ms)
Jan 15 23:31:48.224: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname2/proxy/: tls qux (200; 17.943584ms)
Jan 15 23:31:48.224: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:1080/proxy/... (200; 17.868548ms)
Jan 15 23:31:48.225: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/https:proxy-service-nt5gz-6x646:460/proxy/: tls baz (200; 18.945107ms)
Jan 15 23:31:48.225: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/https:proxy-service-nt5gz:tlsportname1/proxy/: tls baz (200; 18.969623ms)
Jan 15 23:31:48.225: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/proxy-service-nt5gz-6x646:160/proxy/: foo (200; 18.70042ms)
Jan 15 23:31:48.226: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/pods/http:proxy-service-nt5gz-6x646:160/proxy/: foo (200; 19.445135ms)
Jan 15 23:31:48.226: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname2/proxy/: bar (200; 19.742313ms)
Jan 15 23:31:48.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/http:proxy-service-nt5gz:portname1/proxy/: foo (200; 20.244059ms)
Jan 15 23:31:48.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-lccrb/services/proxy-service-nt5gz:portname1/proxy/: foo (200; 21.25739ms)
STEP: deleting { ReplicationController} proxy-service-nt5gz in namespace e2e-tests-proxy-lccrb, will wait for the garbage collector to delete the pods
Jan 15 23:31:48.293: INFO: Deleting { ReplicationController} proxy-service-nt5gz took: 11.104933ms
Jan 15 23:31:48.393: INFO: Terminating { ReplicationController} proxy-service-nt5gz pods took: 100.231425ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:31:50.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-lccrb" for this suite.
Jan 15 23:31:56.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:31:56.348: INFO: namespace: e2e-tests-proxy-lccrb, resource: bindings, ignored listing per whitelist
Jan 15 23:31:56.421: INFO: namespace e2e-tests-proxy-lccrb deletion completed in 6.122125484s

• [SLOW TEST:19.039 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:31:56.422: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-z4st4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 15 23:31:57.157: INFO: created pod pod-service-account-defaultsa
Jan 15 23:31:57.157: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 15 23:31:57.172: INFO: created pod pod-service-account-mountsa
Jan 15 23:31:57.173: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 15 23:31:57.183: INFO: created pod pod-service-account-nomountsa
Jan 15 23:31:57.183: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 15 23:31:57.190: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 15 23:31:57.190: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 15 23:31:57.205: INFO: created pod pod-service-account-mountsa-mountspec
Jan 15 23:31:57.205: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 15 23:31:57.227: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 15 23:31:57.227: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 15 23:31:57.237: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 15 23:31:57.237: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 15 23:31:57.249: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 15 23:31:57.249: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 15 23:31:57.257: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 15 23:31:57.257: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:31:57.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-z4st4" for this suite.
Jan 15 23:32:03.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:32:03.381: INFO: namespace: e2e-tests-svcaccounts-z4st4, resource: bindings, ignored listing per whitelist
Jan 15 23:32:03.446: INFO: namespace e2e-tests-svcaccounts-z4st4 deletion completed in 6.171295078s

• [SLOW TEST:7.024 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:32:03.449: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-72xqn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 15 23:32:03.725: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 15 23:32:03.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:04.263: INFO: stderr: ""
Jan 15 23:32:04.263: INFO: stdout: "service/redis-slave created\n"
Jan 15 23:32:04.263: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 15 23:32:04.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:04.549: INFO: stderr: ""
Jan 15 23:32:04.549: INFO: stdout: "service/redis-master created\n"
Jan 15 23:32:04.549: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 15 23:32:04.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:04.814: INFO: stderr: ""
Jan 15 23:32:04.815: INFO: stdout: "service/frontend created\n"
Jan 15 23:32:04.818: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 15 23:32:04.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:05.158: INFO: stderr: ""
Jan 15 23:32:05.158: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 15 23:32:05.159: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 15 23:32:05.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:05.415: INFO: stderr: ""
Jan 15 23:32:05.416: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 15 23:32:05.416: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 15 23:32:05.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:05.701: INFO: stderr: ""
Jan 15 23:32:05.701: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 15 23:32:05.701: INFO: Waiting for all frontend pods to be Running.
Jan 15 23:32:35.754: INFO: Waiting for frontend to serve content.
Jan 15 23:32:35.779: INFO: Trying to add a new entry to the guestbook.
Jan 15 23:32:35.797: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan 15 23:32:35.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:35.962: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:32:35.962: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 23:32:35.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:36.139: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:32:36.139: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 23:32:36.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:36.272: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:32:36.272: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 23:32:36.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:36.414: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:32:36.414: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 23:32:36.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:36.565: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:32:36.565: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 15 23:32:36.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-72xqn'
Jan 15 23:32:36.754: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 15 23:32:36.754: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:32:36.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-72xqn" for this suite.
Jan 15 23:33:14.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:33:14.860: INFO: namespace: e2e-tests-kubectl-72xqn, resource: bindings, ignored listing per whitelist
Jan 15 23:33:14.897: INFO: namespace e2e-tests-kubectl-72xqn deletion completed in 38.125174674s

• [SLOW TEST:71.449 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:33:14.905: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-9w5gb
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ee1bcbb0-191d-11e9-993a-025056003018
STEP: Creating secret with name s-test-opt-upd-ee1bcbfc-191d-11e9-993a-025056003018
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ee1bcbb0-191d-11e9-993a-025056003018
STEP: Updating secret s-test-opt-upd-ee1bcbfc-191d-11e9-993a-025056003018
STEP: Creating secret with name s-test-opt-create-ee1bcc14-191d-11e9-993a-025056003018
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:33:23.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9w5gb" for this suite.
Jan 15 23:33:45.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:33:45.357: INFO: namespace: e2e-tests-secrets-9w5gb, resource: bindings, ignored listing per whitelist
Jan 15 23:33:45.364: INFO: namespace e2e-tests-secrets-9w5gb deletion completed in 22.107737944s

• [SLOW TEST:30.460 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:33:45.364: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-m86kh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:33:45.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 version --client'
Jan 15 23:33:45.640: INFO: stderr: ""
Jan 15 23:33:45.641: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 15 23:33:45.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-m86kh'
Jan 15 23:33:45.902: INFO: stderr: ""
Jan 15 23:33:45.902: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 15 23:33:45.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-m86kh'
Jan 15 23:33:46.195: INFO: stderr: ""
Jan 15 23:33:46.195: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 15 23:33:47.200: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 23:33:47.200: INFO: Found 0 / 1
Jan 15 23:33:48.201: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 23:33:48.201: INFO: Found 1 / 1
Jan 15 23:33:48.201: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 15 23:33:48.205: INFO: Selector matched 1 pods for map[app:redis]
Jan 15 23:33:48.205: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 15 23:33:48.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 describe pod redis-master-92j72 --namespace=e2e-tests-kubectl-m86kh'
Jan 15 23:33:48.312: INFO: stderr: ""
Jan 15 23:33:48.312: INFO: stdout: "Name:               redis-master-92j72\nNamespace:          e2e-tests-kubectl-m86kh\nPriority:           0\nPriorityClassName:  <none>\nNode:               16f34f29-58df-43ef-838e-06a19f186c15/30.0.3.3\nStart Time:         Tue, 15 Jan 2019 23:33:45 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 40.0.9.2\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://450017d7a78863d4ab7727b6aa9af51aa87f4f6f19c08d042d4daccf67bbab78\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 15 Jan 2019 23:33:47 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-j6sjp (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-j6sjp:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-j6sjp\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                           Message\n  ----    ------     ----  ----                                           -------\n  Normal  Scheduled  3s    default-scheduler                              Successfully assigned e2e-tests-kubectl-m86kh/redis-master-92j72 to 16f34f29-58df-43ef-838e-06a19f186c15\n  Normal  Pulled     1s    kubelet, 16f34f29-58df-43ef-838e-06a19f186c15  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 16f34f29-58df-43ef-838e-06a19f186c15  Created container\n  Normal  Started    1s    kubelet, 16f34f29-58df-43ef-838e-06a19f186c15  Started container\n"
Jan 15 23:33:48.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 describe rc redis-master --namespace=e2e-tests-kubectl-m86kh'
Jan 15 23:33:48.428: INFO: stderr: ""
Jan 15 23:33:48.428: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-m86kh\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-92j72\n"
Jan 15 23:33:48.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 describe service redis-master --namespace=e2e-tests-kubectl-m86kh'
Jan 15 23:33:48.538: INFO: stderr: ""
Jan 15 23:33:48.538: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-m86kh\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.200.217\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         40.0.9.2:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 15 23:33:48.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 describe node 16f34f29-58df-43ef-838e-06a19f186c15'
Jan 15 23:33:48.684: INFO: stderr: ""
Jan 15 23:33:48.684: INFO: stdout: "Name:               16f34f29-58df-43ef-838e-06a19f186c15\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    bosh.id=ccbedf22-8474-4242-b3ea-4817f20e076b\n                    bosh.zone=az-1\n                    failure-domain.beta.kubernetes.io/zone=az-1\n                    kubernetes.io/hostname=30.0.3.3\n                    spec.ip=30.0.3.3\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 15 Jan 2019 19:55:36 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Tue, 15 Jan 2019 23:33:46 +0000   Tue, 15 Jan 2019 19:55:22 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Tue, 15 Jan 2019 23:33:46 +0000   Tue, 15 Jan 2019 19:55:22 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 15 Jan 2019 23:33:46 +0000   Tue, 15 Jan 2019 19:55:22 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 15 Jan 2019 23:33:46 +0000   Tue, 15 Jan 2019 19:55:22 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 15 Jan 2019 23:33:46 +0000   Tue, 15 Jan 2019 19:55:22 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  30.0.3.3\n  InternalIP:  30.0.3.3\n  Hostname:    30.0.3.3\nCapacity:\n cpu:                2\n ephemeral-storage:  3030944Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8168820Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  2793317986\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8066420Ki\n pods:               110\nSystem Info:\n Machine ID:                 6db40ea29d4363ade6a737337df95111\n System UUID:                422FE326-125E-ABB0-D5E2-28B6C629739D\n Boot ID:                    93366803-5476-46a1-a529-cc63404249ab\n Kernel Version:             4.15.0-42-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.4\n Kube-Proxy Version:         v1.12.4\nProviderID:                  vsphere://422fe326-125e-abb0-d5e2-28b6c629739d\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-m86kh    redis-master-92j72                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-5ffc402244cc475a-m6gxg    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-dns-7559c96fc4-fmw6c                                  260m (13%)    0 (0%)      110Mi (1%)       170Mi (2%)\n  pks-system                 fluent-bit-xszkh                                           0 (0%)        0 (0%)      100Mi (1%)       100Mi (1%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       260m (13%)  0 (0%)\n  memory    210Mi (2%)  270Mi (3%)\nEvents:     <none>\n"
Jan 15 23:33:48.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 describe namespace e2e-tests-kubectl-m86kh'
Jan 15 23:33:48.802: INFO: stderr: ""
Jan 15 23:33:48.803: INFO: stdout: "Name:         e2e-tests-kubectl-m86kh\nLabels:       e2e-framework=kubectl\n              e2e-run=0aedfe7f-1914-11e9-993a-025056003018\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:33:48.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m86kh" for this suite.
Jan 15 23:34:10.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:34:10.846: INFO: namespace: e2e-tests-kubectl-m86kh, resource: bindings, ignored listing per whitelist
Jan 15 23:34:10.929: INFO: namespace e2e-tests-kubectl-m86kh deletion completed in 22.119190893s

• [SLOW TEST:25.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:34:10.930: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vxdrc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 15 23:34:11.166: INFO: Waiting up to 5m0s for pod "pod-0f8221e4-191e-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-vxdrc" to be "success or failure"
Jan 15 23:34:11.173: INFO: Pod "pod-0f8221e4-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 6.967435ms
Jan 15 23:34:13.177: INFO: Pod "pod-0f8221e4-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010577598s
Jan 15 23:34:15.181: INFO: Pod "pod-0f8221e4-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014622937s
STEP: Saw pod success
Jan 15 23:34:15.181: INFO: Pod "pod-0f8221e4-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:34:15.186: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-0f8221e4-191e-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 23:34:15.212: INFO: Waiting for pod pod-0f8221e4-191e-11e9-993a-025056003018 to disappear
Jan 15 23:34:15.215: INFO: Pod pod-0f8221e4-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:34:15.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vxdrc" for this suite.
Jan 15 23:34:21.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:34:21.324: INFO: namespace: e2e-tests-emptydir-vxdrc, resource: bindings, ignored listing per whitelist
Jan 15 23:34:21.364: INFO: namespace e2e-tests-emptydir-vxdrc deletion completed in 6.145456464s

• [SLOW TEST:10.434 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:34:21.365: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-d8894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 15 23:34:21.579: INFO: Waiting up to 5m0s for pod "downward-api-15b9ce64-191e-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-d8894" to be "success or failure"
Jan 15 23:34:21.628: INFO: Pod "downward-api-15b9ce64-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 48.726513ms
Jan 15 23:34:23.632: INFO: Pod "downward-api-15b9ce64-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052482357s
Jan 15 23:34:25.635: INFO: Pod "downward-api-15b9ce64-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056200293s
STEP: Saw pod success
Jan 15 23:34:25.636: INFO: Pod "downward-api-15b9ce64-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:34:25.639: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downward-api-15b9ce64-191e-11e9-993a-025056003018 container dapi-container: <nil>
STEP: delete the pod
Jan 15 23:34:25.691: INFO: Waiting for pod downward-api-15b9ce64-191e-11e9-993a-025056003018 to disappear
Jan 15 23:34:25.699: INFO: Pod downward-api-15b9ce64-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:34:25.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d8894" for this suite.
Jan 15 23:34:31.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:34:31.834: INFO: namespace: e2e-tests-downward-api-d8894, resource: bindings, ignored listing per whitelist
Jan 15 23:34:31.849: INFO: namespace e2e-tests-downward-api-d8894 deletion completed in 6.144153155s

• [SLOW TEST:10.484 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:34:31.849: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-f4mwb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1bfb1a75-191e-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:34:32.087: INFO: Waiting up to 5m0s for pod "pod-secrets-1bfcbba7-191e-11e9-993a-025056003018" in namespace "e2e-tests-secrets-f4mwb" to be "success or failure"
Jan 15 23:34:32.093: INFO: Pod "pod-secrets-1bfcbba7-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 6.506425ms
Jan 15 23:34:34.097: INFO: Pod "pod-secrets-1bfcbba7-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010252342s
STEP: Saw pod success
Jan 15 23:34:34.097: INFO: Pod "pod-secrets-1bfcbba7-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:34:34.103: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-1bfcbba7-191e-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:34:34.125: INFO: Waiting for pod pod-secrets-1bfcbba7-191e-11e9-993a-025056003018 to disappear
Jan 15 23:34:34.137: INFO: Pod pod-secrets-1bfcbba7-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:34:34.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f4mwb" for this suite.
Jan 15 23:34:40.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:34:40.209: INFO: namespace: e2e-tests-secrets-f4mwb, resource: bindings, ignored listing per whitelist
Jan 15 23:34:40.248: INFO: namespace e2e-tests-secrets-f4mwb deletion completed in 6.106153847s

• [SLOW TEST:8.400 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:34:40.249: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-rd8kk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:34:40.439: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 15 23:34:40.454: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 15 23:34:45.458: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 15 23:34:45.458: INFO: Creating deployment "test-rolling-update-deployment"
Jan 15 23:34:45.465: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 15 23:34:45.474: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 15 23:34:47.494: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 15 23:34:47.511: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683192085, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683192085, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683192087, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683192085, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 15 23:34:49.515: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 23:34:49.523: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-rd8kk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rd8kk/deployments/test-rolling-update-deployment,UID:23f6ae59-191e-11e9-8273-005056af1926,ResourceVersion:28027,Generation:1,CreationTimestamp:2019-01-15 23:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-15 23:34:45 +0000 UTC 2019-01-15 23:34:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-15 23:34:47 +0000 UTC 2019-01-15 23:34:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 15 23:34:49.527: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-rd8kk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rd8kk/replicasets/test-rolling-update-deployment-65b7695dcf,UID:23f9c993-191e-11e9-8273-005056af1926,ResourceVersion:28018,Generation:1,CreationTimestamp:2019-01-15 23:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 23f6ae59-191e-11e9-8273-005056af1926 0xc421f51e97 0xc421f51e98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 15 23:34:49.527: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 15 23:34:49.527: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-rd8kk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rd8kk/replicasets/test-rolling-update-controller,UID:20f8f1d3-191e-11e9-8273-005056af1926,ResourceVersion:28026,Generation:2,CreationTimestamp:2019-01-15 23:34:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 23f6ae59-191e-11e9-8273-005056af1926 0xc421f51dbe 0xc421f51dbf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 23:34:49.530: INFO: Pod "test-rolling-update-deployment-65b7695dcf-gqs54" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-gqs54,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-rd8kk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rd8kk/pods/test-rolling-update-deployment-65b7695dcf-gqs54,UID:23fa6575-191e-11e9-8273-005056af1926,ResourceVersion:28017,Generation:0,CreationTimestamp:2019-01-15 23:34:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 23f9c993-191e-11e9-8273-005056af1926 0xc421c89477 0xc421c89478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7j2nm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7j2nm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-7j2nm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c89570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c896b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:34:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:34:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:34:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:34:45 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.9.3,StartTime:2019-01-15 23:34:45 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-15 23:34:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1a61e4a8d4e05754393d17f383d4644c920a40a3b700be56304698dfe693b5ae}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:34:49.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rd8kk" for this suite.
Jan 15 23:34:55.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:34:55.605: INFO: namespace: e2e-tests-deployment-rd8kk, resource: bindings, ignored listing per whitelist
Jan 15 23:34:55.654: INFO: namespace e2e-tests-deployment-rd8kk deletion completed in 6.119007872s

• [SLOW TEST:15.405 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:34:55.654: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-2llfb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 15 23:34:55.881: INFO: Waiting up to 5m0s for pod "client-containers-2a2b21a6-191e-11e9-993a-025056003018" in namespace "e2e-tests-containers-2llfb" to be "success or failure"
Jan 15 23:34:55.893: INFO: Pod "client-containers-2a2b21a6-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 11.595491ms
Jan 15 23:34:57.897: INFO: Pod "client-containers-2a2b21a6-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015691872s
Jan 15 23:34:59.901: INFO: Pod "client-containers-2a2b21a6-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019364277s
STEP: Saw pod success
Jan 15 23:34:59.901: INFO: Pod "client-containers-2a2b21a6-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:34:59.904: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod client-containers-2a2b21a6-191e-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 23:34:59.932: INFO: Waiting for pod client-containers-2a2b21a6-191e-11e9-993a-025056003018 to disappear
Jan 15 23:34:59.940: INFO: Pod client-containers-2a2b21a6-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:34:59.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2llfb" for this suite.
Jan 15 23:35:05.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:35:06.063: INFO: namespace: e2e-tests-containers-2llfb, resource: bindings, ignored listing per whitelist
Jan 15 23:35:06.096: INFO: namespace e2e-tests-containers-2llfb deletion completed in 6.150644581s

• [SLOW TEST:10.442 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:35:06.097: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mqqsk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 23:35:06.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-mqqsk'
Jan 15 23:35:06.414: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 15 23:35:06.415: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Jan 15 23:35:10.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-mqqsk'
Jan 15 23:35:10.562: INFO: stderr: ""
Jan 15 23:35:10.562: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:35:10.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mqqsk" for this suite.
Jan 15 23:35:16.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:35:16.672: INFO: namespace: e2e-tests-kubectl-mqqsk, resource: bindings, ignored listing per whitelist
Jan 15 23:35:16.716: INFO: namespace e2e-tests-kubectl-mqqsk deletion completed in 6.148390093s

• [SLOW TEST:10.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:35:16.718: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-mwzzv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:35:16.939: INFO: Creating deployment "nginx-deployment"
Jan 15 23:35:16.946: INFO: Waiting for observed generation 1
Jan 15 23:35:18.953: INFO: Waiting for all required pods to come up
Jan 15 23:35:18.959: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 15 23:35:22.988: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 15 23:35:22.992: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 15 23:35:23.003: INFO: Updating deployment nginx-deployment
Jan 15 23:35:23.003: INFO: Waiting for observed generation 2
Jan 15 23:35:25.018: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 15 23:35:25.021: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 15 23:35:25.024: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 15 23:35:25.030: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 15 23:35:25.031: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 15 23:35:25.034: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 15 23:35:25.038: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 15 23:35:25.038: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 15 23:35:25.048: INFO: Updating deployment nginx-deployment
Jan 15 23:35:25.048: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 15 23:35:25.072: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 15 23:35:25.087: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 15 23:35:25.105: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mwzzv/deployments/nginx-deployment,UID:36ba5b1b-191e-11e9-8273-005056af1926,ResourceVersion:28354,Generation:3,CreationTimestamp:2019-01-15 23:35:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-01-15 23:35:21 +0000 UTC 2019-01-15 23:35:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-15 23:35:23 +0000 UTC 2019-01-15 23:35:16 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan 15 23:35:25.131: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mwzzv/replicasets/nginx-deployment-7dc8f79789,UID:3a5787d5-191e-11e9-8273-005056af1926,ResourceVersion:28358,Generation:3,CreationTimestamp:2019-01-15 23:35:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 36ba5b1b-191e-11e9-8273-005056af1926 0xc422c12b77 0xc422c12b78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 15 23:35:25.131: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 15 23:35:25.131: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-mwzzv/replicasets/nginx-deployment-7f9675fb8b,UID:36bc2401-191e-11e9-8273-005056af1926,ResourceVersion:28355,Generation:3,CreationTimestamp:2019-01-15 23:35:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 36ba5b1b-191e-11e9-8273-005056af1926 0xc422c12c47 0xc422c12c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan 15 23:35:25.175: INFO: Pod "nginx-deployment-7dc8f79789-744r6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-744r6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-744r6,UID:3a6cb97c-191e-11e9-8273-005056af1926,ResourceVersion:28346,Generation:0,CreationTimestamp:2019-01-15 23:35:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc422c13a87 0xc422c13a88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:77857714-16e9-437d-8ce8-445ba965630c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c13af0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c13b10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:,StartTime:2019-01-15 23:35:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.175: INFO: Pod "nginx-deployment-7dc8f79789-b7qff" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-b7qff,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-b7qff,UID:3b9936ef-191e-11e9-8273-005056af1926,ResourceVersion:28376,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc422c13d10 0xc422c13d11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:b660f798-38a0-4e83-a501-5381799304ec,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c13d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c13da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.175: INFO: Pod "nginx-deployment-7dc8f79789-dvx96" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dvx96,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-dvx96,UID:3a5c553c-191e-11e9-8273-005056af1926,ResourceVersion:28328,Generation:0,CreationTimestamp:2019-01-15 23:35:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc422c13e90 0xc422c13e91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:77857714-16e9-437d-8ce8-445ba965630c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c13f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c13f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:,StartTime:2019-01-15 23:35:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.175: INFO: Pod "nginx-deployment-7dc8f79789-hwzvs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hwzvs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-hwzvs,UID:3a69bd67-191e-11e9-8273-005056af1926,ResourceVersion:28344,Generation:0,CreationTimestamp:2019-01-15 23:35:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc421e56a70 0xc421e56a71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e56ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e56b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-15 23:35:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.175: INFO: Pod "nginx-deployment-7dc8f79789-mg225" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-mg225,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-mg225,UID:3a594186-191e-11e9-8273-005056af1926,ResourceVersion:28322,Generation:0,CreationTimestamp:2019-01-15 23:35:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc421e56ca0 0xc421e56ca1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e56d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e56d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-15 23:35:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7dc8f79789-rk7t8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rk7t8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-rk7t8,UID:3a5c2dc6-191e-11e9-8273-005056af1926,ResourceVersion:28325,Generation:0,CreationTimestamp:2019-01-15 23:35:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc421e57130 0xc421e57131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:b660f798-38a0-4e83-a501-5381799304ec,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e571a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e571c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:23 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:,StartTime:2019-01-15 23:35:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7dc8f79789-xmmfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xmmfj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-xmmfj,UID:3b9dbf70-191e-11e9-8273-005056af1926,ResourceVersion:28379,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc421e57290 0xc421e57291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e575c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e575e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7dc8f79789-zr2qr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zr2qr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7dc8f79789-zr2qr,UID:3b9da485-191e-11e9-8273-005056af1926,ResourceVersion:28378,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 3a5787d5-191e-11e9-8273-005056af1926 0xc421e57637 0xc421e57638}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e576b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e57870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7f9675fb8b-2q24m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-2q24m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-2q24m,UID:36c4b4fb-191e-11e9-8273-005056af1926,ResourceVersion:28291,Generation:0,CreationTimestamp:2019-01-15 23:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421e578c7 0xc421e578c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:77857714-16e9-437d-8ce8-445ba965630c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e57930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e57950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.10.7,StartTime:2019-01-15 23:35:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://1e735259a0c0fbf4ee4d6df033d4079e9db8470fdba13ed61255f03b04fbc95e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7f9675fb8b-5j7cf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5j7cf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-5j7cf,UID:36c47118-191e-11e9-8273-005056af1926,ResourceVersion:28285,Generation:0,CreationTimestamp:2019-01-15 23:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421e57a50 0xc421e57a51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e57ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e57ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.10.8,StartTime:2019-01-15 23:35:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://966f5eb595acf922f3b82b8163ec0431f7821c9dfa7221ca25bd0455933da59f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7f9675fb8b-6ht9q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6ht9q,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-6ht9q,UID:36c05ade-191e-11e9-8273-005056af1926,ResourceVersion:28263,Generation:0,CreationTimestamp:2019-01-15 23:35:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421e57bd0 0xc421e57bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:77857714-16e9-437d-8ce8-445ba965630c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e57c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e57c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.10.4,StartTime:2019-01-15 23:35:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://18289689ed63a5a10306a9f45e356843396c5361019727bd3561df6daf410cdd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7f9675fb8b-78dfd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-78dfd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-78dfd,UID:36c47e32-191e-11e9-8273-005056af1926,ResourceVersion:28268,Generation:0,CreationTimestamp:2019-01-15 23:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421e57dc0 0xc421e57dc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:b660f798-38a0-4e83-a501-5381799304ec,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e57e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e57e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.10.6,StartTime:2019-01-15 23:35:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://b0f44e1deb704f79f6f7e6b9d1076bd62e1a946ad1358f6b35f932db0cd37693}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7f9675fb8b-h95dc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h95dc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-h95dc,UID:3b9b4da9-191e-11e9-8273-005056af1926,ResourceVersion:28373,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421e57f80 0xc421e57f81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e57fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.176: INFO: Pod "nginx-deployment-7f9675fb8b-lvr9p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lvr9p,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-lvr9p,UID:3b907f98-191e-11e9-8273-005056af1926,ResourceVersion:28365,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421230057 0xc421230058}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:77857714-16e9-437d-8ce8-445ba965630c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4212301b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:,StartTime:2019-01-15 23:35:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-m7g66" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m7g66,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-m7g66,UID:3b968c36-191e-11e9-8273-005056af1926,ResourceVersion:28366,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421230270 0xc421230271}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-q98cv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-q98cv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-q98cv,UID:36beb938-191e-11e9-8273-005056af1926,ResourceVersion:28257,Generation:0,CreationTimestamp:2019-01-15 23:35:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421230400 0xc421230401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:16 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.10.2,StartTime:2019-01-15 23:35:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://5b8ed4560e32b2f5c2f2e12f04ff78de40ad6eaeeaaa60a69197eefdff03316f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-qtb6x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qtb6x,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-qtb6x,UID:3b9a6004-191e-11e9-8273-005056af1926,ResourceVersion:28377,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc4212305c0 0xc4212305c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:77857714-16e9-437d-8ce8-445ba965630c,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-sbqk2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sbqk2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-sbqk2,UID:36c61c7c-191e-11e9-8273-005056af1926,ResourceVersion:28294,Generation:0,CreationTimestamp:2019-01-15 23:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc4212306d0 0xc4212306d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:b660f798-38a0-4e83-a501-5381799304ec,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.10.10,StartTime:2019-01-15 23:35:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://840a5ab4288f1252d48cad033efe54d3c2122901501f2af9af476e93185b10d1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-skvbv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-skvbv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-skvbv,UID:3b96def2-191e-11e9-8273-005056af1926,ResourceVersion:28372,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421230810 0xc421230811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:b660f798-38a0-4e83-a501-5381799304ec,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:25 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-sl622" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sl622,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-sl622,UID:3b9b99b9-191e-11e9-8273-005056af1926,ResourceVersion:28375,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421230900 0xc421230901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-szmdt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-szmdt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-szmdt,UID:3b9b8272-191e-11e9-8273-005056af1926,ResourceVersion:28374,Generation:0,CreationTimestamp:2019-01-15 23:35:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc4212309d7 0xc4212309d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230a40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230a60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-t2zxk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-t2zxk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-t2zxk,UID:36c45fad-191e-11e9-8273-005056af1926,ResourceVersion:28260,Generation:0,CreationTimestamp:2019-01-15 23:35:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421230ab7 0xc421230ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:16f34f29-58df-43ef-838e-06a19f186c15,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.10.5,StartTime:2019-01-15 23:35:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://93e72f9c404ba5bb02bc68d5e27aa288a2976770f08f68c72e11d72442b6995f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 15 23:35:25.177: INFO: Pod "nginx-deployment-7f9675fb8b-wt7nb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wt7nb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-mwzzv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-mwzzv/pods/nginx-deployment-7f9675fb8b-wt7nb,UID:36c07ff7-191e-11e9-8273-005056af1926,ResourceVersion:28243,Generation:0,CreationTimestamp:2019-01-15 23:35:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 36bc2401-191e-11e9-8273-005056af1926 0xc421230c10 0xc421230c11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dtvqt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dtvqt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dtvqt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:b660f798-38a0-4e83-a501-5381799304ec,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421230c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421230c90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-15 23:35:17 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.10.3,StartTime:2019-01-15 23:35:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-15 23:35:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://e2238e750a356d25bdc7b6208572a069a9649c9be573bca719ac73519de96101}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:35:25.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-mwzzv" for this suite.
Jan 15 23:35:33.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:35:33.402: INFO: namespace: e2e-tests-deployment-mwzzv, resource: bindings, ignored listing per whitelist
Jan 15 23:35:33.453: INFO: namespace e2e-tests-deployment-mwzzv deletion completed in 8.231198222s

• [SLOW TEST:16.736 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:35:33.454: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bmxtj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-40b1e902-191e-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:35:33.685: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-40b29110-191e-11e9-993a-025056003018" in namespace "e2e-tests-projected-bmxtj" to be "success or failure"
Jan 15 23:35:33.688: INFO: Pod "pod-projected-secrets-40b29110-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.741373ms
Jan 15 23:35:35.693: INFO: Pod "pod-projected-secrets-40b29110-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007262084s
Jan 15 23:35:37.697: INFO: Pod "pod-projected-secrets-40b29110-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011679079s
STEP: Saw pod success
Jan 15 23:35:37.698: INFO: Pod "pod-projected-secrets-40b29110-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:35:37.702: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-secrets-40b29110-191e-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:35:37.729: INFO: Waiting for pod pod-projected-secrets-40b29110-191e-11e9-993a-025056003018 to disappear
Jan 15 23:35:37.733: INFO: Pod pod-projected-secrets-40b29110-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:35:37.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bmxtj" for this suite.
Jan 15 23:35:43.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:35:43.777: INFO: namespace: e2e-tests-projected-bmxtj, resource: bindings, ignored listing per whitelist
Jan 15 23:35:43.853: INFO: namespace e2e-tests-projected-bmxtj deletion completed in 6.115393177s

• [SLOW TEST:10.399 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:35:43.854: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-k27fb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 23:35:44.069: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46e4b695-191e-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-k27fb" to be "success or failure"
Jan 15 23:35:44.081: INFO: Pod "downwardapi-volume-46e4b695-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 12.492058ms
Jan 15 23:35:46.086: INFO: Pod "downwardapi-volume-46e4b695-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017397643s
Jan 15 23:35:48.091: INFO: Pod "downwardapi-volume-46e4b695-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021845368s
STEP: Saw pod success
Jan 15 23:35:48.091: INFO: Pod "downwardapi-volume-46e4b695-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:35:48.093: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-46e4b695-191e-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 23:35:48.118: INFO: Waiting for pod downwardapi-volume-46e4b695-191e-11e9-993a-025056003018 to disappear
Jan 15 23:35:48.128: INFO: Pod downwardapi-volume-46e4b695-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:35:48.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k27fb" for this suite.
Jan 15 23:35:54.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:35:54.191: INFO: namespace: e2e-tests-downward-api-k27fb, resource: bindings, ignored listing per whitelist
Jan 15 23:35:54.246: INFO: namespace e2e-tests-downward-api-k27fb deletion completed in 6.114023673s

• [SLOW TEST:10.393 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:35:54.247: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-psj8p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-cdfg
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 23:35:54.468: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-cdfg" in namespace "e2e-tests-subpath-psj8p" to be "success or failure"
Jan 15 23:35:54.472: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.348005ms
Jan 15 23:35:56.476: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007935462s
Jan 15 23:35:58.481: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 4.012499768s
Jan 15 23:36:00.490: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 6.021633299s
Jan 15 23:36:02.494: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 8.026089066s
Jan 15 23:36:04.502: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 10.033728121s
Jan 15 23:36:06.506: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 12.03766027s
Jan 15 23:36:08.509: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 14.041330388s
Jan 15 23:36:10.517: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 16.049305023s
Jan 15 23:36:12.522: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 18.053710912s
Jan 15 23:36:14.527: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 20.058830906s
Jan 15 23:36:16.531: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Running", Reason="", readiness=false. Elapsed: 22.062757047s
Jan 15 23:36:18.547: INFO: Pod "pod-subpath-test-secret-cdfg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.078547591s
STEP: Saw pod success
Jan 15 23:36:18.547: INFO: Pod "pod-subpath-test-secret-cdfg" satisfied condition "success or failure"
Jan 15 23:36:18.549: INFO: Trying to get logs from node b660f798-38a0-4e83-a501-5381799304ec pod pod-subpath-test-secret-cdfg container test-container-subpath-secret-cdfg: <nil>
STEP: delete the pod
Jan 15 23:36:18.587: INFO: Waiting for pod pod-subpath-test-secret-cdfg to disappear
Jan 15 23:36:18.589: INFO: Pod pod-subpath-test-secret-cdfg no longer exists
STEP: Deleting pod pod-subpath-test-secret-cdfg
Jan 15 23:36:18.589: INFO: Deleting pod "pod-subpath-test-secret-cdfg" in namespace "e2e-tests-subpath-psj8p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:36:18.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-psj8p" for this suite.
Jan 15 23:36:24.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:36:24.685: INFO: namespace: e2e-tests-subpath-psj8p, resource: bindings, ignored listing per whitelist
Jan 15 23:36:24.696: INFO: namespace e2e-tests-subpath-psj8p deletion completed in 6.100504706s

• [SLOW TEST:30.449 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:36:24.696: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-br4k8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 15 23:36:24.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 create -f - --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:25.829: INFO: stderr: ""
Jan 15 23:36:25.829: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 23:36:25.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:25.956: INFO: stderr: ""
Jan 15 23:36:25.956: INFO: stdout: "update-demo-nautilus-btpmt update-demo-nautilus-ssbmn "
Jan 15 23:36:25.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-btpmt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:26.052: INFO: stderr: ""
Jan 15 23:36:26.052: INFO: stdout: ""
Jan 15 23:36:26.052: INFO: update-demo-nautilus-btpmt is created but not running
Jan 15 23:36:31.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:31.204: INFO: stderr: ""
Jan 15 23:36:31.205: INFO: stdout: "update-demo-nautilus-btpmt update-demo-nautilus-ssbmn "
Jan 15 23:36:31.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-btpmt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:31.313: INFO: stderr: ""
Jan 15 23:36:31.313: INFO: stdout: "true"
Jan 15 23:36:31.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-btpmt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:31.416: INFO: stderr: ""
Jan 15 23:36:31.416: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:36:31.416: INFO: validating pod update-demo-nautilus-btpmt
Jan 15 23:36:31.424: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:36:31.424: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:36:31.424: INFO: update-demo-nautilus-btpmt is verified up and running
Jan 15 23:36:31.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-ssbmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:31.530: INFO: stderr: ""
Jan 15 23:36:31.530: INFO: stdout: "true"
Jan 15 23:36:31.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-nautilus-ssbmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:31.649: INFO: stderr: ""
Jan 15 23:36:31.649: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 15 23:36:31.649: INFO: validating pod update-demo-nautilus-ssbmn
Jan 15 23:36:31.655: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 15 23:36:31.655: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 15 23:36:31.655: INFO: update-demo-nautilus-ssbmn is verified up and running
STEP: rolling-update to new replication controller
Jan 15 23:36:31.657: INFO: scanned /root for discovery docs: <nil>
Jan 15 23:36:31.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:58.205: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 15 23:36:58.205: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 15 23:36:58.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:58.311: INFO: stderr: ""
Jan 15 23:36:58.311: INFO: stdout: "update-demo-kitten-kp9gd update-demo-kitten-m8cm8 "
Jan 15 23:36:58.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-kitten-kp9gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:58.408: INFO: stderr: ""
Jan 15 23:36:58.408: INFO: stdout: "true"
Jan 15 23:36:58.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-kitten-kp9gd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:58.514: INFO: stderr: ""
Jan 15 23:36:58.514: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 15 23:36:58.514: INFO: validating pod update-demo-kitten-kp9gd
Jan 15 23:36:58.519: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 15 23:36:58.520: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 15 23:36:58.520: INFO: update-demo-kitten-kp9gd is verified up and running
Jan 15 23:36:58.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-kitten-m8cm8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:58.624: INFO: stderr: ""
Jan 15 23:36:58.624: INFO: stdout: "true"
Jan 15 23:36:58.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pods update-demo-kitten-m8cm8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br4k8'
Jan 15 23:36:58.730: INFO: stderr: ""
Jan 15 23:36:58.730: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 15 23:36:58.730: INFO: validating pod update-demo-kitten-m8cm8
Jan 15 23:36:58.737: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 15 23:36:58.737: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 15 23:36:58.737: INFO: update-demo-kitten-m8cm8 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:36:58.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-br4k8" for this suite.
Jan 15 23:37:20.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:37:20.770: INFO: namespace: e2e-tests-kubectl-br4k8, resource: bindings, ignored listing per whitelist
Jan 15 23:37:20.839: INFO: namespace e2e-tests-kubectl-br4k8 deletion completed in 22.097476346s

• [SLOW TEST:56.143 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:37:20.839: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-phkrx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 15 23:37:21.036: INFO: Waiting up to 5m0s for pod "pod-80afafa8-191e-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-phkrx" to be "success or failure"
Jan 15 23:37:21.045: INFO: Pod "pod-80afafa8-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 8.917045ms
Jan 15 23:37:23.058: INFO: Pod "pod-80afafa8-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021755087s
Jan 15 23:37:25.061: INFO: Pod "pod-80afafa8-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025574936s
STEP: Saw pod success
Jan 15 23:37:25.061: INFO: Pod "pod-80afafa8-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:37:25.064: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-80afafa8-191e-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 23:37:25.104: INFO: Waiting for pod pod-80afafa8-191e-11e9-993a-025056003018 to disappear
Jan 15 23:37:25.108: INFO: Pod pod-80afafa8-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:37:25.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-phkrx" for this suite.
Jan 15 23:37:31.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:37:31.160: INFO: namespace: e2e-tests-emptydir-phkrx, resource: bindings, ignored listing per whitelist
Jan 15 23:37:31.235: INFO: namespace e2e-tests-emptydir-phkrx deletion completed in 6.122170473s

• [SLOW TEST:10.396 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:37:31.236: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-q5qdq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-86e53f07-191e-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:37:31.455: INFO: Waiting up to 5m0s for pod "pod-configmaps-86e5e565-191e-11e9-993a-025056003018" in namespace "e2e-tests-configmap-q5qdq" to be "success or failure"
Jan 15 23:37:31.480: INFO: Pod "pod-configmaps-86e5e565-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 25.285092ms
Jan 15 23:37:33.489: INFO: Pod "pod-configmaps-86e5e565-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033681777s
STEP: Saw pod success
Jan 15 23:37:33.489: INFO: Pod "pod-configmaps-86e5e565-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:37:33.493: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-configmaps-86e5e565-191e-11e9-993a-025056003018 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 23:37:33.547: INFO: Waiting for pod pod-configmaps-86e5e565-191e-11e9-993a-025056003018 to disappear
Jan 15 23:37:33.552: INFO: Pod pod-configmaps-86e5e565-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:37:33.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q5qdq" for this suite.
Jan 15 23:37:39.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:37:39.587: INFO: namespace: e2e-tests-configmap-q5qdq, resource: bindings, ignored listing per whitelist
Jan 15 23:37:39.655: INFO: namespace e2e-tests-configmap-q5qdq deletion completed in 6.099870981s

• [SLOW TEST:8.420 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:37:39.656: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-m7fnl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 15 23:37:39.911: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018" in namespace "e2e-tests-downward-api-m7fnl" to be "success or failure"
Jan 15 23:37:39.933: INFO: Pod "downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 21.17532ms
Jan 15 23:37:41.939: INFO: Pod "downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027499545s
Jan 15 23:37:43.944: INFO: Pod "downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032258544s
STEP: Saw pod success
Jan 15 23:37:43.944: INFO: Pod "downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:37:43.946: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018 container client-container: <nil>
STEP: delete the pod
Jan 15 23:37:43.988: INFO: Waiting for pod downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018 to disappear
Jan 15 23:37:43.993: INFO: Pod downwardapi-volume-8bf0b108-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:37:43.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m7fnl" for this suite.
Jan 15 23:37:50.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:37:50.080: INFO: namespace: e2e-tests-downward-api-m7fnl, resource: bindings, ignored listing per whitelist
Jan 15 23:37:50.114: INFO: namespace e2e-tests-downward-api-m7fnl deletion completed in 6.116751142s

• [SLOW TEST:10.459 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:37:50.114: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-cwlh7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:38:50.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cwlh7" for this suite.
Jan 15 23:39:12.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:39:12.412: INFO: namespace: e2e-tests-container-probe-cwlh7, resource: bindings, ignored listing per whitelist
Jan 15 23:39:12.465: INFO: namespace e2e-tests-container-probe-cwlh7 deletion completed in 22.1054998s

• [SLOW TEST:82.351 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:39:12.466: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-9sfj2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-9sfj2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9sfj2 to expose endpoints map[]
Jan 15 23:39:12.694: INFO: Get endpoints failed (4.136834ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 15 23:39:13.698: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9sfj2 exposes endpoints map[] (1.00803211s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9sfj2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9sfj2 to expose endpoints map[pod1:[80]]
Jan 15 23:39:16.757: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9sfj2 exposes endpoints map[pod1:[80]] (3.046422551s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9sfj2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9sfj2 to expose endpoints map[pod1:[80] pod2:[80]]
Jan 15 23:39:19.847: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9sfj2 exposes endpoints map[pod1:[80] pod2:[80]] (3.078457335s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9sfj2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9sfj2 to expose endpoints map[pod2:[80]]
Jan 15 23:39:19.870: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9sfj2 exposes endpoints map[pod2:[80]] (12.773542ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9sfj2
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9sfj2 to expose endpoints map[]
Jan 15 23:39:19.891: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9sfj2 exposes endpoints map[] (12.778504ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:39:19.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9sfj2" for this suite.
Jan 15 23:39:41.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:39:41.976: INFO: namespace: e2e-tests-services-9sfj2, resource: bindings, ignored listing per whitelist
Jan 15 23:39:42.035: INFO: namespace e2e-tests-services-9sfj2 deletion completed in 22.116011936s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.570 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:39:42.039: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7jlcn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d4e4f106-191e-11e9-993a-025056003018
STEP: Creating a pod to test consume configMaps
Jan 15 23:39:42.313: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018" in namespace "e2e-tests-projected-7jlcn" to be "success or failure"
Jan 15 23:39:42.319: INFO: Pod "pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 5.36119ms
Jan 15 23:39:44.324: INFO: Pod "pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010512117s
Jan 15 23:39:46.328: INFO: Pod "pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014178753s
STEP: Saw pod success
Jan 15 23:39:46.328: INFO: Pod "pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:39:46.330: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 15 23:39:46.355: INFO: Waiting for pod pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018 to disappear
Jan 15 23:39:46.362: INFO: Pod pod-projected-configmaps-d4e5ded7-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:39:46.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7jlcn" for this suite.
Jan 15 23:39:52.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:39:52.424: INFO: namespace: e2e-tests-projected-7jlcn, resource: bindings, ignored listing per whitelist
Jan 15 23:39:52.499: INFO: namespace e2e-tests-projected-7jlcn deletion completed in 6.131909801s

• [SLOW TEST:10.461 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:39:52.499: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rmhsc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 15 23:40:18.747: INFO: Container started at 2019-01-15 23:39:55 +0000 UTC, pod became ready at 2019-01-15 23:40:17 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:40:18.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rmhsc" for this suite.
Jan 15 23:40:40.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:40:40.858: INFO: namespace: e2e-tests-container-probe-rmhsc, resource: bindings, ignored listing per whitelist
Jan 15 23:40:40.864: INFO: namespace e2e-tests-container-probe-rmhsc deletion completed in 22.111986254s

• [SLOW TEST:48.365 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:40:40.865: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-czvcx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 15 23:40:41.079: INFO: Waiting up to 5m0s for pod "pod-f7ec1ad3-191e-11e9-993a-025056003018" in namespace "e2e-tests-emptydir-czvcx" to be "success or failure"
Jan 15 23:40:41.084: INFO: Pod "pod-f7ec1ad3-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 4.708164ms
Jan 15 23:40:43.103: INFO: Pod "pod-f7ec1ad3-191e-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024437889s
Jan 15 23:40:45.107: INFO: Pod "pod-f7ec1ad3-191e-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02833832s
STEP: Saw pod success
Jan 15 23:40:45.107: INFO: Pod "pod-f7ec1ad3-191e-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:40:45.111: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-f7ec1ad3-191e-11e9-993a-025056003018 container test-container: <nil>
STEP: delete the pod
Jan 15 23:40:45.133: INFO: Waiting for pod pod-f7ec1ad3-191e-11e9-993a-025056003018 to disappear
Jan 15 23:40:45.135: INFO: Pod pod-f7ec1ad3-191e-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:40:45.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-czvcx" for this suite.
Jan 15 23:40:51.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:40:51.166: INFO: namespace: e2e-tests-emptydir-czvcx, resource: bindings, ignored listing per whitelist
Jan 15 23:40:51.241: INFO: namespace e2e-tests-emptydir-czvcx deletion completed in 6.101637441s

• [SLOW TEST:10.376 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:40:51.241: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-x997b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 15 23:40:51.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x997b'
Jan 15 23:40:51.562: INFO: stderr: ""
Jan 15 23:40:51.563: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 15 23:40:56.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x997b -o json'
Jan 15 23:40:56.715: INFO: stderr: ""
Jan 15 23:40:56.715: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-15T23:40:51Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-x997b\",\n        \"resourceVersion\": \"29604\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-x997b/pods/e2e-test-nginx-pod\",\n        \"uid\": \"fe2c264e-191e-11e9-8273-005056af1926\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-sq4sm\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"16f34f29-58df-43ef-838e-06a19f186c15\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-sq4sm\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-sq4sm\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-15T23:40:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-15T23:40:53Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-15T23:40:53Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-15T23:40:51Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://ecb60f980a5c123f6279530580176ff25f7efdc4dd371de2a27175ae8ce3d6a1\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-15T23:40:53Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"30.0.3.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"40.0.9.2\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-15T23:40:51Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 15 23:40:56.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 replace -f - --namespace=e2e-tests-kubectl-x997b'
Jan 15 23:40:57.034: INFO: stderr: ""
Jan 15 23:40:57.034: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Jan 15 23:40:57.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-x997b'
Jan 15 23:41:06.202: INFO: stderr: ""
Jan 15 23:41:06.202: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:41:06.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-x997b" for this suite.
Jan 15 23:41:12.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:41:12.273: INFO: namespace: e2e-tests-kubectl-x997b, resource: bindings, ignored listing per whitelist
Jan 15 23:41:12.324: INFO: namespace e2e-tests-kubectl-x997b deletion completed in 6.11288302s

• [SLOW TEST:21.082 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:41:12.325: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ccmqw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0aad20ed-191f-11e9-993a-025056003018
STEP: Creating a pod to test consume secrets
Jan 15 23:41:12.560: INFO: Waiting up to 5m0s for pod "pod-secrets-0aaf400b-191f-11e9-993a-025056003018" in namespace "e2e-tests-secrets-ccmqw" to be "success or failure"
Jan 15 23:41:12.573: INFO: Pod "pod-secrets-0aaf400b-191f-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 13.511498ms
Jan 15 23:41:14.577: INFO: Pod "pod-secrets-0aaf400b-191f-11e9-993a-025056003018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017466927s
Jan 15 23:41:16.582: INFO: Pod "pod-secrets-0aaf400b-191f-11e9-993a-025056003018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022312836s
STEP: Saw pod success
Jan 15 23:41:16.582: INFO: Pod "pod-secrets-0aaf400b-191f-11e9-993a-025056003018" satisfied condition "success or failure"
Jan 15 23:41:16.586: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-secrets-0aaf400b-191f-11e9-993a-025056003018 container secret-volume-test: <nil>
STEP: delete the pod
Jan 15 23:41:16.618: INFO: Waiting for pod pod-secrets-0aaf400b-191f-11e9-993a-025056003018 to disappear
Jan 15 23:41:16.623: INFO: Pod pod-secrets-0aaf400b-191f-11e9-993a-025056003018 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:41:16.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ccmqw" for this suite.
Jan 15 23:41:22.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:41:22.733: INFO: namespace: e2e-tests-secrets-ccmqw, resource: bindings, ignored listing per whitelist
Jan 15 23:41:22.739: INFO: namespace e2e-tests-secrets-ccmqw deletion completed in 6.111180912s

• [SLOW TEST:10.415 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:41:22.741: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-7fhdg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 15 23:41:22.950: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-7fhdg,SelfLink:/api/v1/namespaces/e2e-tests-watch-7fhdg/configmaps/e2e-watch-test-resource-version,UID:10df7279-191f-11e9-8273-005056af1926,ResourceVersion:29710,Generation:0,CreationTimestamp:2019-01-15 23:41:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 23:41:22.950: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-7fhdg,SelfLink:/api/v1/namespaces/e2e-tests-watch-7fhdg/configmaps/e2e-watch-test-resource-version,UID:10df7279-191f-11e9-8273-005056af1926,ResourceVersion:29711,Generation:0,CreationTimestamp:2019-01-15 23:41:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:41:22.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7fhdg" for this suite.
Jan 15 23:41:28.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:41:29.065: INFO: namespace: e2e-tests-watch-7fhdg, resource: bindings, ignored listing per whitelist
Jan 15 23:41:29.070: INFO: namespace e2e-tests-watch-7fhdg deletion completed in 6.110960791s

• [SLOW TEST:6.330 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:41:29.073: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tvl68
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-14ac82c5-191f-11e9-993a-025056003018
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:41:33.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tvl68" for this suite.
Jan 15 23:41:55.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:41:55.452: INFO: namespace: e2e-tests-configmap-tvl68, resource: bindings, ignored listing per whitelist
Jan 15 23:41:55.479: INFO: namespace e2e-tests-configmap-tvl68 deletion completed in 22.110152543s

• [SLOW TEST:26.406 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:41:55.479: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-w84n2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0115 23:42:05.783880      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 15 23:42:05.784: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:42:05.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w84n2" for this suite.
Jan 15 23:42:11.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:42:11.879: INFO: namespace: e2e-tests-gc-w84n2, resource: bindings, ignored listing per whitelist
Jan 15 23:42:11.916: INFO: namespace e2e-tests-gc-w84n2 deletion completed in 6.128570394s

• [SLOW TEST:16.437 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:42:11.920: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-h5pp9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 15 23:42:12.175: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-h5pp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-h5pp9/configmaps/e2e-watch-test-label-changed,UID:2e360310-191f-11e9-8273-005056af1926,ResourceVersion:30046,Generation:0,CreationTimestamp:2019-01-15 23:42:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 15 23:42:12.176: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-h5pp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-h5pp9/configmaps/e2e-watch-test-label-changed,UID:2e360310-191f-11e9-8273-005056af1926,ResourceVersion:30047,Generation:0,CreationTimestamp:2019-01-15 23:42:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 15 23:42:12.176: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-h5pp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-h5pp9/configmaps/e2e-watch-test-label-changed,UID:2e360310-191f-11e9-8273-005056af1926,ResourceVersion:30048,Generation:0,CreationTimestamp:2019-01-15 23:42:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 15 23:42:22.217: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-h5pp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-h5pp9/configmaps/e2e-watch-test-label-changed,UID:2e360310-191f-11e9-8273-005056af1926,ResourceVersion:30064,Generation:0,CreationTimestamp:2019-01-15 23:42:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 15 23:42:22.217: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-h5pp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-h5pp9/configmaps/e2e-watch-test-label-changed,UID:2e360310-191f-11e9-8273-005056af1926,ResourceVersion:30065,Generation:0,CreationTimestamp:2019-01-15 23:42:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 15 23:42:22.217: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-h5pp9,SelfLink:/api/v1/namespaces/e2e-tests-watch-h5pp9/configmaps/e2e-watch-test-label-changed,UID:2e360310-191f-11e9-8273-005056af1926,ResourceVersion:30066,Generation:0,CreationTimestamp:2019-01-15 23:42:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:42:22.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-h5pp9" for this suite.
Jan 15 23:42:28.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:42:28.271: INFO: namespace: e2e-tests-watch-h5pp9, resource: bindings, ignored listing per whitelist
Jan 15 23:42:28.334: INFO: namespace e2e-tests-watch-h5pp9 deletion completed in 6.107663329s

• [SLOW TEST:16.415 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:42:28.338: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-rqbdq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-7xxw
STEP: Creating a pod to test atomic-volume-subpath
Jan 15 23:42:28.547: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7xxw" in namespace "e2e-tests-subpath-rqbdq" to be "success or failure"
Jan 15 23:42:28.562: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Pending", Reason="", readiness=false. Elapsed: 15.006188ms
Jan 15 23:42:30.568: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020439025s
Jan 15 23:42:32.571: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 4.024106592s
Jan 15 23:42:34.577: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 6.029862213s
Jan 15 23:42:36.584: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 8.036620637s
Jan 15 23:42:38.598: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 10.051083546s
Jan 15 23:42:40.603: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 12.056035051s
Jan 15 23:42:42.608: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 14.061163277s
Jan 15 23:42:44.613: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 16.065696939s
Jan 15 23:42:46.618: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 18.070383684s
Jan 15 23:42:48.622: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 20.074395957s
Jan 15 23:42:50.626: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Running", Reason="", readiness=false. Elapsed: 22.078416682s
Jan 15 23:42:52.630: INFO: Pod "pod-subpath-test-projected-7xxw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.082750969s
STEP: Saw pod success
Jan 15 23:42:52.630: INFO: Pod "pod-subpath-test-projected-7xxw" satisfied condition "success or failure"
Jan 15 23:42:52.634: INFO: Trying to get logs from node 16f34f29-58df-43ef-838e-06a19f186c15 pod pod-subpath-test-projected-7xxw container test-container-subpath-projected-7xxw: <nil>
STEP: delete the pod
Jan 15 23:42:52.653: INFO: Waiting for pod pod-subpath-test-projected-7xxw to disappear
Jan 15 23:42:52.662: INFO: Pod pod-subpath-test-projected-7xxw no longer exists
STEP: Deleting pod pod-subpath-test-projected-7xxw
Jan 15 23:42:52.662: INFO: Deleting pod "pod-subpath-test-projected-7xxw" in namespace "e2e-tests-subpath-rqbdq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:42:52.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rqbdq" for this suite.
Jan 15 23:42:58.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:42:58.723: INFO: namespace: e2e-tests-subpath-rqbdq, resource: bindings, ignored listing per whitelist
Jan 15 23:42:58.780: INFO: namespace e2e-tests-subpath-rqbdq deletion completed in 6.1090349s

• [SLOW TEST:30.442 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:42:58.780: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-tbwds
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 15 23:43:05.084: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.084: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:05.214: INFO: Exec stderr: ""
Jan 15 23:43:05.214: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.214: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:05.343: INFO: Exec stderr: ""
Jan 15 23:43:05.343: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.343: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:05.460: INFO: Exec stderr: ""
Jan 15 23:43:05.460: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.460: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:05.555: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 15 23:43:05.555: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.555: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:05.679: INFO: Exec stderr: ""
Jan 15 23:43:05.679: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.679: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:05.797: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 15 23:43:05.797: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.797: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:05.921: INFO: Exec stderr: ""
Jan 15 23:43:05.921: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:05.921: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:06.004: INFO: Exec stderr: ""
Jan 15 23:43:06.004: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:06.004: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:06.102: INFO: Exec stderr: ""
Jan 15 23:43:06.102: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-tbwds PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:43:06.102: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:43:06.198: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:43:06.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-tbwds" for this suite.
Jan 15 23:43:52.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:43:52.245: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-tbwds, resource: bindings, ignored listing per whitelist
Jan 15 23:43:52.333: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-tbwds deletion completed in 46.129778462s

• [SLOW TEST:53.553 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:43:52.335: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rkp8l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 15 23:43:57.131: INFO: Successfully updated pod "labelsupdate6a0c86bc-191f-11e9-993a-025056003018"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:43:59.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rkp8l" for this suite.
Jan 15 23:44:21.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:44:21.273: INFO: namespace: e2e-tests-downward-api-rkp8l, resource: bindings, ignored listing per whitelist
Jan 15 23:44:21.280: INFO: namespace e2e-tests-downward-api-rkp8l deletion completed in 22.118242595s

• [SLOW TEST:28.946 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:44:21.282: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-44zzt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 15 23:44:26.017: INFO: Successfully updated pod "pod-update-7b4c7f9b-191f-11e9-993a-025056003018"
STEP: verifying the updated pod is in kubernetes
Jan 15 23:44:26.035: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:44:26.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-44zzt" for this suite.
Jan 15 23:44:48.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:44:48.117: INFO: namespace: e2e-tests-pods-44zzt, resource: bindings, ignored listing per whitelist
Jan 15 23:44:48.154: INFO: namespace e2e-tests-pods-44zzt deletion completed in 22.105726413s

• [SLOW TEST:26.873 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:44:48.155: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-wc4z4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wc4z4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 15 23:44:48.347: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 15 23:45:14.460: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.9.2:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wc4z4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:45:14.460: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:45:14.609: INFO: Found all expected endpoints: [netserver-0]
Jan 15 23:45:14.616: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.9.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wc4z4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:45:14.616: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:45:14.722: INFO: Found all expected endpoints: [netserver-1]
Jan 15 23:45:14.726: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.9.4:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-wc4z4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 15 23:45:14.726: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
Jan 15 23:45:14.841: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:45:14.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wc4z4" for this suite.
Jan 15 23:45:36.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:45:36.883: INFO: namespace: e2e-tests-pod-network-test-wc4z4, resource: bindings, ignored listing per whitelist
Jan 15 23:45:36.952: INFO: namespace e2e-tests-pod-network-test-wc4z4 deletion completed in 22.101091765s

• [SLOW TEST:48.798 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 15 23:45:36.954: INFO: >>> kubeConfig: /tmp/kubeconfig-736916119
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d62p6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 15 23:45:37.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-736916119 --namespace=e2e-tests-kubectl-d62p6 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 15 23:45:40.576: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 15 23:45:40.576: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 15 23:45:42.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d62p6" for this suite.
Jan 15 23:45:48.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 15 23:45:48.687: INFO: namespace: e2e-tests-kubectl-d62p6, resource: bindings, ignored listing per whitelist
Jan 15 23:45:48.687: INFO: namespace e2e-tests-kubectl-d62p6 deletion completed in 6.100427132s

• [SLOW TEST:11.733 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSJan 15 23:45:48.687: INFO: Running AfterSuite actions on all node
Jan 15 23:45:48.688: INFO: Running AfterSuite actions on node 1
Jan 15 23:45:48.688: INFO: Skipping dumping logs from cluster


Summarizing 1 Failure:

[Fail] [sig-apps] ReplicaSet [BeforeEach] should serve a basic image on each replica with a public image  [Conformance] 
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/psp_util.go:144

Ran 187 of 1814 Specs in 4999.440 seconds
FAIL! -- 186 Passed | 1 Failed | 0 Pending | 1627 Skipped --- FAIL: TestE2E (4999.59s)
FAIL

Ginkgo ran 1 suite in 1h23m20.385119802s
Test Suite Failed
